import os
import torch
import gradio as gr
import shutil
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment

# тЪб рдЯрд░реНрдмреЛ рдЗрдВрдЬрди рд╕реЗрдЯрдЕрдк [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ЁЯУе рд╣рдЧрд┐рдВрдЧ рдлреЗрд╕ рдореЙрдбрд▓
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth"
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

def apply_shriram_final_touch(file_path, weight, amp):
    """рдЖрд╡рд╛реЫ рдХреЛ рднрд╛рд░реА рдФрд░ рдкрд╛рд╡рд░рдлреБрд▓ рдмрдирд╛рдирд╛"""
    sound = AudioSegment.from_wav(file_path)
    sound = sound + amp 
    if weight > 0:
        new_sample_rate = int(sound.frame_rate * (1.0 - (weight / 85)))
        sound = sound._spawn(sound.raw_data, overrides={'frame_rate': new_sample_rate})
        sound = sound.set_frame_rate(44100)
    final_path = "shriram_hindi_pure.wav"
    sound.export(final_path, format="wav")
    return final_path

def generate_voice(text, voice_sample, speed, human_feel, weight, amp):
    if not text or not voice_sample:
        raise gr.Error("рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдФрд░ рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓ рджреЗрдВред") 

    # ЁЯЪй рднрд╛рд╖рд╛ рдкрд░ рд▓рдЧрд╛рдо рд▓рдЧрд╛рдиреЗ рдХреЗ рд▓рд┐рдП рд╡рд┐рд╢реЗрд╖ рд╕реЗрдЯрд┐рдВрдЧ
    # 'language="hi"' рдХреЛ рдХреЬрд╛рдИ рд╕реЗ рд▓рд╛рдЧреВ рдХрд░рдирд╛
    temp_file = "temp_pure.wav"
    
    tts.tts_to_file(
        text=text,
        speaker_wav=voice_sample,
        language="hi",             # рд╢реБрджреНрдз рд╣рд┐рдВрджреА [cite: 2025-11-23]
        file_path=temp_file,
        speed=speed,
        repetition_penalty=18.0,   # рджреВрд╕рд░реА рднрд╛рд╖рд╛ рдХреЗ рд╢рдмреНрджреЛрдВ рдХреЗ рдЬреБреЬрд╛рд╡ рдХреЛ рд░реЛрдХрдиреЗ рдХреЗ рд▓рд┐рдП рдмреЭрд╛рдпрд╛ рдЧрдпрд╛
        temperature=human_feel,    
        top_p=0.80,                # рд╢реБрджреНрдзрддрд╛ рдХреЗ рд▓рд┐рдП рдереЛреЬрд╛ рдХрдо рд░рдЦрд╛ рдЧрдпрд╛ рддрд╛рдХрд┐ рдореЙрдбрд▓ рднрдЯрдХреЗ рдирд╣реАрдВ
        gpt_cond_len=6,            # рд╕реИрдВрдкрд▓ рдХреЛ рдЧрд╣рд░рд╛рдИ рд╕реЗ рд╕рдордЭрдиреЗ рдХреЗ рд▓рд┐рдП рдмреЭрд╛рдпрд╛ рдЧрдпрд╛
        enable_text_splitting=True 
    )
    
    return apply_shriram_final_touch(temp_file, weight, amp)

# ЁЯОи 100% рд╢реБрджреНрдз рд╣рд┐рдВрджреА рдорд╛рд╕реНрдЯрд░ рд╕реНрдЯреВрдбрд┐рдпреЛ
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# ЁЯЪй рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА - 100% рд╢реБрджреНрдз рд╣рд┐рдВрджреА AI (No Language Drift)")
    gr.Markdown("### рджреВрд╕рд░реА рднрд╛рд╖рд╛ рдХреЗ рдЙрдЪреНрдЪрд╛рд░рдг рдкрд░ рдкреВрд░реА рддрд░рд╣ рд▓рдЧрд╛рдо")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="рд╕рд┐рд░реНрдл рд╣рд┐рдВрджреА рд╕реНрдХреНрд░рд┐рдкреНрдЯ рд▓рд┐рдЦреЗрдВ", lines=12, placeholder="рдпрд╣рд╛рдБ рд╣рд┐рдВрджреА рд▓рд┐рдЦреЗрдВ...")
        with gr.Column(scale=1):
            ref = gr.Audio(label="рд╣рд┐рдВрджреА рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓", type="filepath")
            
            with gr.Accordion("ЁЯЫбя╕П рд▓рдЧрд╛рдо рдХрдВрдЯреНрд░реЛрд▓ (Pure Hindi)", open=True):
                speed_s = gr.Slider(label="рд╕реНрдкреАрдб", minimum=0.8, maximum=1.1, value=0.95)
                human_s = gr.Slider(label="рд╣реНрдпреВрдорди рдЗрдореЛрд╢рди", minimum=0.5, maximum=0.9, value=0.75) # рднрдЯрдХрд╛рд╡ рд░реЛрдХрдиреЗ рдХреЗ рд▓рд┐рдП рдЗрд╕реЗ 0.75 рдкрд░ рдлрд┐рдХреНрд╕ рдХрд┐рдпрд╛
                weight_s = gr.Slider(label="рдЧрд╣рд░рд╛ рднрд╛рд░реА рд╡рдЬрди", minimum=0, maximum=10, value=4)
                amp_s = gr.Slider(label="рдПрдордкреНрд▓реАрдлрд╛рдпрд░", minimum=-5, maximum=10, value=2)
            
            btn = gr.Button("ЁЯЪА рд╢реБрджреНрдз рд╣рд┐рдВрджреА рдЬрдирд░реЗрдЯ рдХрд░реЗрдВ", variant="primary")
            
    out = gr.Audio(label="100% рд╢реБрджреНрдз рд╣рд┐рдВрджреА рдЖрдЙрдЯрдкреБрдЯ", type="filepath", autoplay=True)
    btn.click(generate_voice, [txt, ref, speed_s, human_s, weight_s, amp_s], out)

demo.launch(share=True)
