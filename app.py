import os
import torch
import gradio as gr
from TTS.api import TTS
from pydub import AudioSegment
from pydub.silence import split_on_silence

# рдЯрд░реНрдмреЛ рд▓реЛрдб XTTS-v2
device = "cuda" if torch.cuda.is_available() else "cpu"
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

def generate_voice(text, voice_sample, remove_silence):
    output_path = "output.wav"
    
    # рд╕реБрдзрд╛рд░ 1: рднрд╛рд╖рд╛ рдХреЛ 'hi' рдкрд░ рд▓реЙрдХ рдХрд░рдирд╛ рдФрд░ 'Speed' рдмреЭрд╛рдирд╛
    tts.tts_to_file(
        text=text, 
        speaker_wav=voice_sample, 
        language="hi",              # рд╣рд┐рдВрджреА рдкрд░ рд╕рдЦреНрдд рдирд┐рдпрдВрддреНрд░рдг
        file_path=output_path,
        split_sentences=True        # рд╡рд╛рдХреНрдпреЛрдВ рдХреЛ рддреЛреЬрдХрд░ рдкреЭрдирд╛ рддрд╛рдХрд┐ рднрд╛рд╖рд╛ рди рднрдЯрдХреЗ
    )
    
    # рд╕реБрдзрд╛рд░ 2: рд╕рд╛рдЗрд▓реЗрдВрд╕ рд░рд┐рдореВрд╡рд░ (рдЖрдкрдХреА рдорд╛рдВрдЧ рдХреЗ рдЕрдиреБрд╕рд╛рд░)
    if remove_silence:
        sound = AudioSegment.from_file(output_path)
        chunks = split_on_silence(sound, min_silence_len=400, silence_thresh=-45)
        combined = AudioSegment.empty()
        for chunk in chunks:
            combined += chunk
        output_path = "clean_turbo_output.wav"
        combined.export(output_path, format="wav")
    
    return output_path

# --- рдЗрдВрдЯрд░рдлрд╝реЗрд╕ ---
with gr.Blocks() as demo:
    gr.Markdown("# ЁЯОЩя╕П AI Voice Box - Perfect Hindi Fix")
    input_text = gr.Textbox(label="рд╕рд┐рд░реНрдл рд╣рд┐рдВрджреА рдЯреЗрдХреНрд╕реНрдЯ рд▓рд┐рдЦреЗрдВ", value="рдирдорд╕реНрддреЗ, рдореИрдВ рдЕрдм рд╢реБрджреНрдз рд╣рд┐рдВрджреА рдмреЛрд▓реВрдБрдЧрд╛ред")
    audio_input = gr.Audio(label="рдЕрдкрдиреА рдЖрд╡рд╛рдЬрд╝ рдХрд╛ рд╕реИрдВрдкрд▓ (.wav)", type="filepath")
    silence_btn = gr.Checkbox(label="рд╕рдиреНрдирд╛рдЯрд╛ рд╣рдЯрд╛рдПрдБ (Silence Remover)", value=True)
    btn = gr.Button("ЁЯЪА рдЖрд╡рд╛рдЬ рдЙрддреНрдкрдиреНрди рдХрд░реЗрдВ")
    audio_out = gr.Audio(label="рдЖрдЙрдЯрдкреБрдЯ")

    btn.click(generate_voice, [input_text, audio_input, silence_btn], audio_out)

demo.launch(share=True)
