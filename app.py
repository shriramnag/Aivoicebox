import os, torch, gradio as gr, requests, re, gc
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment, effects

# рез. рдЯрд░реНрдмреЛ рд╣рд╛рдИ рд╕реНрдкреАрдб рд╕реЗрдЯрдЕрдк
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# реи. рдорд╛рд╕реНрдЯрд░ рдореЙрдбрд▓ - рд╢рд┐рд╡ AI (LOCKED)
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth" 
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

G_RAW = "https://raw.githubusercontent.com/shriramnag/Aivoicebox/main/%F0%9F%93%81%20voices/"

# тЬи рдорд┐рдиреАрдореИрдХреНрд╕ рд╕реНрдЯрд╛рдЗрд▓: рдмрдЯрди рджрдмрд╛рддреЗ рд╣реА рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдореЗрдВ рдЯреИрдЧ рдЬреЛреЬрдирд╛
def add_emotion_tag(current_text, tag_value):
    if current_text is None: current_text = ""
    return current_text + f" {tag_value} "

def generate_shiv_ultimate(text, up_ref, git_ref, speed_s, pitch_s, use_silence, use_clean):
    # рей. рдирдВрдмрд░-рдЯреВ-рд╡рд░реНрдбреНрд╕ рдлрд┐рдХреНрд╕ (LOCKED)
    num_map = {'0':'рд╢реВрдиреНрдп','1':'рдПрдХ','2':'рджреЛ','3':'рддреАрди','4':'рдЪрд╛рд░','5':'рдкрд╛рдБрдЪ','6':'рдЫрд╣','7':'рд╕рд╛рдд','8':'рдЖрда','9':'рдиреМ'}
    for n, w in num_map.items(): text = text.replace(n, w)

    # рек. рд╡реЙрдпрд╕ рд╕рд┐рд▓реЗрдХреНрд╢рди
    ref = up_ref if up_ref else "ref.wav"
    if not up_ref:
        url = G_RAW + requests.utils.quote(git_ref)
        with open(ref, "wb") as f: f.write(requests.get(url).content)

    # рел. рдЪрдВрдХрд┐рдВрдЧ рдФрд░ рдЯрд░реНрдмреЛ рдЬрдирд░реЗрд╢рди (XTTS рдЯреИрдЧреНрд╕ рдХреЛ рдЦреБрдж рд╕рдордЭрддрд╛ рд╣реИ)
    chunks = [s.strip() for s in re.split('([ред!?рее\n])', text) if len(s.strip()) > 1]
    combined = AudioSegment.empty()
    
    for i, chunk in enumerate(chunks):
        name = f"c_{i}.wav"
        tts.tts_to_file(text=chunk, speaker_wav=ref, language="hi", file_path=name, speed=speed_s, repetition_penalty=10.0)
        seg = AudioSegment.from_wav(name)
        if use_silence:
            try: seg = effects.strip_silence(seg, silence_thresh=-40, padding=100)
            except: pass
        combined += seg
        if i % 5 == 0: torch.cuda.empty_cache(); gc.collect()
    
    if use_clean: combined = effects.normalize(combined).high_pass_filter(80)

    # тЬЕ рдлрд╛рдЗрдирд▓ рдлрд╛рдЗрд▓ рдиреЗрдо - Shri Ram Nag.wav (LOCKED)
    out_file = "Shri Ram Nag.wav"
    combined.export(out_file, format="wav")
    return out_file

# ЁЯОи рджрд┐рд╡реНрдп 'рдорд┐рдиреАрдореИрдХреНрд╕' рдереАрдо UI
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# ЁЯЪй рд╢рд┐рд╡ AI (Shiv AI) - 'рд╢реНрд░реА рд░рд╛рдо рдирд╛рдЧ' рдЗрдореЛрд╢рди рд╕реНрдЯреВрдбрд┐рдпреЛ")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="рдЕрдкрдиреА рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ", lines=12, placeholder="рдмрдЯрди рджрдмрд╛рдХрд░ рдкреЛрдЬрд╝ рдпрд╛ рд╕рд╛рдВрд╕ рдЬреЛреЬреЗрдВ...")
            
            # ЁЯФШ рдорд┐рдиреАрдореИрдХреНрд╕ рдЬреИрд╕реЗ рдмрдЯрди (Blue Tag Style)
            with gr.Row():
                btn_p = gr.Button("тП╕я╕П Pause (<#0.5#>)")
                btn_b = gr.Button("ЁЯТи Breath (breath)")
                btn_l = gr.Button("ЁЯШК Laugh (laugh)")
            
            # рдмрдЯрди рдХреНрд▓рд┐рдХ рдХрд░рдиреЗ рдкрд░ рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдХреЗ рдЖрдЧреЗ рдЯреИрдЧ рдЬреБреЬ рдЬрд╛рдПрдЧрд╛
            btn_p.click(add_emotion_tag, [txt, gr.State("[pause]")], [txt])
            btn_b.click(add_emotion_tag, [txt, gr.State("[breath]")], [txt])
            btn_l.click(add_emotion_tag, [txt, gr.State("[laugh]")], [txt])
            
            word_count = gr.Markdown("рд╢рдмреНрдж рд╕рдВрдЦреНрдпрд╛: рд╢реВрдиреНрдп")
            txt.change(lambda x: f"рд╢рдмреНрдж рд╕рдВрдЦреНрдпрд╛: {len(x.split()) if x else 'рд╢реВрдиреНрдп'}", [txt], [word_count])
            
        with gr.Column(scale=1):
            git_drop = gr.Dropdown(choices=["Joanne.wav", "Shri Shri.wav"], label="рдЧрд┐рдЯрд╣рдм рд╡реЙрдпрд╕", value="Joanne.wav")
            up_aud = gr.Audio(label="рдЕрдкрд▓реЛрдб рд╕реИрдВрдкрд▓", type="filepath")
            with gr.Accordion("ЁЯЫая╕П рд╕реБрдкрд░ рдЯреВрд▓реНрд╕ (LOCKED)", open=True):
                cln_sw = gr.Checkbox(label="AI рд╡реЙрдпрд╕ рдХреНрд▓реАрдирд░", value=True)
                sln_sw = gr.Checkbox(label="рд╕рд╛рдЗрд▓реЗрдВрд╕ рд░рд┐рдореВрд╡рд░", value=True)
            btn = gr.Button("рджрд┐рд╡реНрдп рдЬрдирд░реЗрд╢рди рд╢реБрд░реВ рдХрд░реЗрдВ ЁЯЪА", variant="primary")
            
    out = gr.Audio(label="рдбрд╛рдЙрдирд▓реЛрдб: Shri Ram Nag.wav", type="filepath", autoplay=True)
    btn.click(generate_shiv_ultimate, [txt, up_aud, git_drop, gr.Slider(0.8, 1.4, 1.0), gr.Slider(0.8, 1.1, 0.96), sln_sw, cln_sw], out)

demo.launch(share=True)
