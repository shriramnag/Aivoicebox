import gradio as gr
from TTS.api import TTS
import torch
import os
from pydub import AudioSegment
from pydub.silence import split_on_silence

# 1. рдЯрд░реНрдмреЛ рд╕реЗрдЯрдЕрдк рдФрд░ рдСрдЯреЛ-рдПрдЧреНрд░реАрдореЗрдВрдЯ
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

print("ЁЯЪА рдкреБрд░рд╛рдирд╛ рдЗрдВрдЬрди рд░рд┐рдкреЗрдпрд░ рд╣реЛрдХрд░ рд▓реЛрдб рд╣реЛ рд░рд╣рд╛ рд╣реИ...")
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

def generate_voice(text, voice_sample, speed, pitch, remove_silence):
    output_path = "output.wav"
    
    # рд╣рдХрд▓рд╛рдирд╛ рдФрд░ рдЕрд▓рдЧ рднрд╛рд╖рд╛ рд░реЛрдХрдиреЗ рдХреЗ рд▓рд┐рдП рд╕реБрдзрд╛рд░
    # рд╣рдордиреЗ 'split_sentences=True' рдЬреЛреЬрд╛ рд╣реИ рддрд╛рдХрд┐ рднрд╛рд╖рд╛ рди рднрдЯрдХреЗ
    tts.tts_to_file(
        text=text,
        speaker_wav=voice_sample,
        language="hi",
        file_path=output_path,
        speed=speed,
        split_sentences=True 
    )
    
    # рд╕рдиреНрдирд╛рдЯрд╛ рд╣рдЯрд╛рдирд╛ (Silence Remover)
    if remove_silence:
        sound = AudioSegment.from_file(output_path)
        chunks = split_on_silence(sound, min_silence_len=400, silence_thresh=-45)
        combined = AudioSegment.empty()
        for chunk in chunks:
            combined += chunk
        output_path = "final_fixed_voice.wav"
        combined.export(output_path, format="wav")
    
    return output_path

# 2. рдбрд╛рд░реНрдХ рдореЛрдб рдФрд░ рдпреВрдЖрдИ (UI)
custom_css = "body { background-color: #121212 !important; color: white !important; }"

with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange"), css=custom_css) as demo:
    # рдбрд╛рд░реНрдХ рдореЛрдб рдлреЛрд░реНрд╕ рдХрд░реЗрдВ
    demo.load(None, None, None, _js="() => { document.body.classList.add('dark'); }")
    
    gr.Markdown("# ЁЯОЩя╕П **рдПрдЖрдИ рд╡реЙрдпрд╕ рдмреЙрдХреНрд╕ - рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА (Fixed Version)**")
    
    with gr.Row():
        with gr.Column():
            txt = gr.Textbox(label="рд╣рд┐рдВрджреА рдЯреЗрдХреНрд╕реНрдЯ рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ", placeholder="рдЬреИрд╕реЗ: рдЬрдп рд╢реНрд░реА рдЧрдгреЗрд╢ред (рд╡рд╛рдХреНрдп рдХреЗ рдЕрдВрдд рдореЗрдВ рдкреВрд░реНрдг рд╡рд┐рд░рд╛рдо реЫрд░реВрд░ рд▓рдЧрд╛рдПрдБ)")
            audio_ref = gr.Audio(label="рдЕрдкрдирд╛ рд╕рд╛рдлрд╝ рд╡реЙрдпрд╕ рд╕реИрдВрдкрд▓ рджреЗрдВ", type="filepath")
            
            with gr.Row():
                speed_s = gr.Slider(0.5, 2.0, value=1.0, label="рдЧрддрд┐ (Speed)")
                # рдкрд┐рдЪ рдПрд░рд░ рд╕реЗ рдмрдЪрдиреЗ рдХреЗ рд▓рд┐рдП рдЗрд╕реЗ рдЕрднреА рд╡реЙрдпрд╕ рд╕реИрдВрдкрд▓ рдкрд░ рдЫреЛреЬреЗрдВ
            
            silence_btn = gr.Checkbox(label="Silence Remover (рд╕рдиреНрдирд╛рдЯрд╛ рд╣рдЯрд╛рдПрдБ)", value=True)
            submit = gr.Button("ЁЯЪА Generate Voice", variant="primary")
        
        with gr.Column():
            out = gr.Audio(label="рдЖрдкрдХрд╛ рдлрд╛рдЗрдирд▓ рдСрдбрд┐рдпреЛ")

    submit.click(generate_voice, [txt, audio_ref, speed_s, silence_btn], out)

if __name__ == "__main__":
    demo.launch(share=True)
