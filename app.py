import os, torch, gradio as gr, requests, re, gc, json
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment, effects

# ‡•ß. ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§π‡§æ‡§à ‡§∏‡•ç‡§™‡•Ä‡§° ‡§∏‡•á‡§ü‡§Ö‡§™ (LOCKED) [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ‡•®. ‡§Æ‡§æ‡§∏‡•ç‡§ü‡§∞ ‡§Æ‡•â‡§°‡§≤ - ‡§∂‡§ø‡§µ AI (Shiv AI) [cite: 2026-02-16]
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth" 
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

G_RAW = "https://raw.githubusercontent.com/shriramnag/Aivoicebox/main/%F0%9F%93%81%20voices/"
BRAIN_FILE = "shiv_brain.json"

# ‡•©. ‡§¶‡§ø‡§µ‡•ç‡§Ø ‡§°‡§ø‡§ï‡•ç‡§∂‡§®‡§∞‡•Ä: ‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂, ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§î‡§∞ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§ ‡§ï‡§æ ‡§Æ‡•á‡§≤
DEFAULT_BRAIN = {
    # ‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂ ‡§ü‡•Ç ‡§π‡§ø‡§Ç‡§¶‡•Ä (English to Hindi)
    "AI": "‡§è ‡§Ü‡§à", "YouTube": "‡§Ø‡•Ç‡§ü‡•ç‡§Ø‡•Ç‡§¨", "Update": "‡§Ö‡§™‡§°‡•á‡§ü", "Script": "‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü",
    "Subscriber": "‡§∏‡§¨‡•ç‡§∏‡§ï‡•ç‡§∞‡§æ‡§á‡§¨‡§∞", "Technology": "‡§ü‡•á‡§ï‡•ç‡§®‡•ã‡§≤‡•â‡§ú‡•Ä", "Video": "‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã",
    # ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§ ‡§∂‡§¨‡•ç‡§¶ ‡§´‡§ø‡§ï‡•ç‡§∏ (Sanskrit Fix)
    "‡§ï‡•É‡§∑‡•ç‡§£": "‡§ï‡•É‡§∑‡•ç ‡§£", "‡§®‡§Æ‡§É": "‡§® ‡§Æ ‡§π", "‡§Æ‡•É‡§§‡•ç‡§Ø‡•Å‡§Ç‡§ú‡§Ø": "‡§Æ‡•É‡§§‡•ç ‡§Ø‡•Å‡§®‡•ç ‡§ú‡§Ø", "‡•ê": "‡§ì‡§Æ",
    "‡§∂‡§æ‡§Ç‡§§‡§ø‡§É": "‡§∂‡§æ‡§®‡•ç ‡§§‡§ø ‡§π‡§ø", "‡§∏‡•ç‡§µ‡§∏‡•ç‡§§‡§ø": "‡§∏‡•ç‡§µ‡§∏‡•ç ‡§§‡§ø", "‡§ó‡§ö‡•ç‡§õ‡§§‡§ø": "‡§ó‡§ö‡•ç‡§õ ‡§§‡§ø",
    # ‡§ï‡§†‡§ø‡§® ‡§π‡§ø‡§Ç‡§¶‡•Ä (Hindi Stutter Fix)
    "‡§π‡§ï‡§≤‡§æ‡§®‡§æ": "‡§π‡§ï ‡§≤‡§æ‡§®‡§æ", "‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä": "‡§∂‡§ï‡•ç‡§§‡§ø ‡§∂‡§æ‡§≤‡•Ä", "‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§": "‡§∏‡§Ç‡§∏‡•ç ‡§ï‡•É‡§§"
}

def load_brain():
    if os.path.exists(BRAIN_FILE):
        try:
            with open(BRAIN_FILE, "r", encoding="utf-8") as f: return json.load(f)
        except: pass
    return DEFAULT_BRAIN

def save_brain(brain_data):
    with open(BRAIN_FILE, "w", encoding="utf-8") as f:
        json.dump(brain_data, f, ensure_ascii=False, indent=4)

def boost_realistic_audio(audio):
    """‡§Ü‡§µ‡§æ‡•õ ‡§ï‡•Ä ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü‡§§‡§æ ‡§î‡§∞ ‡§¨‡•á‡§∏ (LOCKED)"""
    resampled = audio.set_frame_rate(44100)
    return effects.normalize(resampled)

def master_brain_processor(text):
    """ü§ñ ‡§∂‡§ø‡§µ AI ‡§ï‡§æ ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü ‡§®‡§Ç‡§¨‡§∞ ‡§î‡§∞ ‡§°‡§ø‡§ï‡•ç‡§∂‡§®‡§∞‡•Ä ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§∞"""
    brain = load_brain()
    
    # ‡•ß. ‡§®‡§Ç‡§¨‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§®‡§æ (‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡§∞‡•ã‡§ï‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è) [cite: 2026-02-20]
    num_map = {'0':'‡§∂‡•Ç‡§®‡•ç‡§Ø','1':'‡§è‡§ï','2':'‡§¶‡•ã','3':'‡§§‡•Ä‡§®','4':'‡§ö‡§æ‡§∞','5':'‡§™‡§æ‡§Å‡§ö','6':'‡§õ‡§π','7':'‡§∏‡§æ‡§§','8':'‡§Ü‡§†','9':'‡§®‡•å'}
    for n, w in num_map.items(): text = text.replace(n, w)
    
    # ‡•®. ‡§°‡§ø‡§ï‡•ç‡§∂‡§®‡§∞‡•Ä ‡§∏‡•á ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡•Å‡§ß‡§æ‡§∞‡§®‡§æ
    for eng, hin in brain.items():
        text = re.sub(r'\b' + eng + r'\b', hin, text, flags=re.IGNORECASE)
        
    # ‡•©. ‡§≠‡§æ‡§∑‡§æ ‡§™‡§π‡§ö‡§æ‡§® (‡§∏‡§ø‡§∞‡•ç‡§´ ‡§ï‡•ã‡§°‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è)
    eng_chars = len(re.findall(r'[a-zA-Z]', text))
    hi_chars = len(re.findall(r'[\u0900-\u097F]', text))
    lang = "en" if eng_chars > hi_chars else "hi"
    
    return text.strip(), lang

# ‡•™. ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§á‡§Ç‡§ú‡§® (LOCKED TOOLS)
def generate_shiv_v1_2(text, up_ref, git_ref, speed_s, pitch_s, use_silence, use_clean, progress=gr.Progress()):
    if not text: return None
    
    # ‡§ë‡§ü‡•ã-‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó: ‡§®‡§à ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§∏‡•á ‡§∂‡§¨‡•ç‡§¶ ‡§∏‡•Ä‡§ñ‡§®‡§æ
    brain = load_brain()
    new_words = re.findall(r'\b[a-zA-Z]{3,}\b', text)
    for w in new_words:
        if w not in brain: brain[w] = w
    save_brain(brain)

    ref = up_ref if up_ref else "ref.wav"
    if not up_ref:
        url = G_RAW + requests.utils.quote(git_ref)
        with open(ref, "wb") as f: f.write(requests.get(url).content)

    # ‡§µ‡§æ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§∂‡•Å‡§¶‡•ç‡§ß ‡§§‡§∞‡•Ä‡§ï‡•á ‡§∏‡•á ‡§ï‡§æ‡§ü‡§®‡§æ
    raw_parts = re.split(r'(\[pause\]|\[breath\]|\[laugh\])', text)
    all_tasks = []
    for p in raw_parts:
        if p.strip() in ["[pause]", "[breath]", "[laugh]"]:
            all_tasks.append(p.strip())
        elif p.strip():
            sentences = re.split(r'(?<=[‡•§!?‡••\n.])\s+', p.strip())
            all_tasks.extend([s.strip() for s in sentences if len(s.strip()) > 1])
    
    combined = AudioSegment.empty()
    total = len(all_tasks)
    
    

    for i, task in enumerate(all_tasks):
        progress((i+1)/total, desc=f"üöÄ ‡§∂‡§ø‡§µ AI ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó: {i+1}/{total}")
        
        if task == "[pause]": combined += AudioSegment.silent(duration=800)
        elif task == "[breath]": combined += AudioSegment.silent(duration=400)
        elif task == "[laugh]": combined += AudioSegment.silent(duration=200)
        else:
            task_clean, detected_lang = master_brain_processor(task)
            name = f"chunk_{i}.wav"
            
            # --- ‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡§™‡§∞ ‡•ß‡•¶‡•¶‡•¶% ‡§´‡§æ‡§á‡§®‡§≤ ‡§™‡•ç‡§∞‡§π‡§æ‡§∞ (LOCKED) ---
            # Temperature 0.05: ‡§¶‡•Ç‡§∏‡§∞‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§¨‡•ã‡§≤‡§®‡•á ‡§∏‡•á ‡§∞‡•ã‡§ï‡•á‡§ó‡§æ‡•§
            # Repetition Penalty 5.0: ‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡§ñ‡§§‡•ç‡§Æ ‡§ï‡§∞‡•á‡§ó‡§æ‡•§
            tts.tts_to_file(text=task_clean, speaker_wav=ref, language=detected_lang, file_path=name, 
                            speed=speed_s, repetition_penalty=5.0, temperature=0.05, top_k=2)
            
            seg = AudioSegment.from_wav(name)
            # ‡•´. ‡§∏‡§æ‡§á‡§≤‡•á‡§Ç‡§∏ ‡§∞‡§ø‡§Æ‡•Ç‡§µ‡§∞ ‡§ü‡•Ç‡§≤ (LOCKED)
            if use_silence:
                try: seg = effects.strip_silence(seg, silence_thresh=-45, padding=100)
                except: pass
            combined += seg
            if os.path.exists(name): os.remove(name)
        
        if i % 3 == 0: torch.cuda.empty_cache(); gc.collect()

    if use_clean: combined = boost_realistic_audio(combined)
    
    final_path = "Shiv_AI_v1.2_Output.wav"
    combined.export(final_path, format="wav")
    return final_path

# ‡•¨. ‡§¶‡§ø‡§µ‡•ç‡§Ø ‡§á‡§Ç‡§ü‡§∞‡§´‡§º‡•á‡§∏ (O.G. Design)
js_code = "function insertTag(tag) { var t=document.querySelector('#script_box textarea'); var s=t.selectionStart; t.value=t.value.substring(0,s)+' '+tag+' '+t.value.substring(t.selectionEnd); t.focus(); return t.value; }"

with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange"), js=js_code) as demo:
    gr.Markdown("# üö© ‡§∂‡§ø‡§µ AI (Shiv AI) v1.2 ‚Äî ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó")
    gr.Markdown("### üîí ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§∏‡•ç‡§™‡•Ä‡§° | ‡§∏‡§æ‡§á‡§≤‡•á‡§Ç‡§∏ ‡§∞‡§ø‡§Æ‡•Ç‡§µ‡§∞ | ‡§°‡§ø‡§ï‡•ç‡§∂‡§®‡§∞‡•Ä ‡§≤‡•â‡§ï | ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§ ‡§∏‡§™‡•ã‡§∞‡•ç‡§ü")
    
    with gr.Tabs():
        with gr.TabItem("üéôÔ∏è ‡§Æ‡•á‡§® ‡§∏‡•ç‡§ü‡•Ç‡§°‡§ø‡§Ø‡•ã"):
            with gr.Row():
                with gr.Column(scale=2):
                    txt = gr.Textbox(label="‡§Ö‡§™‡§®‡•Ä ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü (‡§π‡§ø‡§Ç‡§¶‡•Ä, ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§ ‡§Ø‡§æ English) ‡§Ø‡§π‡§æ‡§Å ‡§≤‡§ø‡§ñ‡•á‡§Ç", lines=12, elem_id="script_box")
                    with gr.Row():
                        gr.Button("‚è∏Ô∏è ‡§∞‡•ã‡§ï‡•á").click(None, None, txt, js="() => insertTag('[pause]')")
                        gr.Button("üí® ‡§∏‡§æ‡§Ç‡§∏").click(None, None, txt, js="() => insertTag('[breath]')")
                        gr.Button("üòä ‡§π‡§Å‡§∏‡•ã").click(None, None, txt, js="() => insertTag('[laugh]')")
                
                with gr.Column(scale=1):
                    git_voice = gr.Dropdown(choices=["aideva.wav"], label="‡§µ‡•â‡§á‡§∏ ‡§ö‡§Ø‡§®", value="aideva.wav")
                    manual = gr.Audio(label="‡§∏‡•à‡§Ç‡§™‡§≤ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç", type="filepath")
                    with gr.Accordion("‚öôÔ∏è ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏ (LOCKED)", open=True):
                        spd = gr.Slider(0.9, 1.4, 1.15, label="‡§∞‡•û‡•ç‡§§‡§æ‡§∞")
                        ptc = gr.Slider(0.8, 1.1, 0.98, label="‡§™‡§ø‡§ö")
                        cln = gr.Checkbox(label="‡§è‡§Ü‡§à ‡§¨‡•á‡§∏ (Symmetry)", value=True)
                        sln = gr.Checkbox(label="‡§∏‡§æ‡§á‡§≤‡•á‡§Ç‡§∏ ‡§∞‡§ø‡§Æ‡•Ç‡§µ‡§∞", value=True)
                    btn = gr.Button("üöÄ ‡§ú‡§®‡§∞‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç (Turbo High Speed)", variant="primary")
            
            out = gr.Audio(label="Final Output", type="filepath", autoplay=True)
            btn.click(generate_shiv_v1_2, [txt, manual, git_voice, spd, ptc, sln, cln], out)

        with gr.TabItem("üß† ‡§Æ‡§∏‡•ç‡§§‡§ø‡§∑‡•ç‡§ï ‡§≤‡§æ‡§á‡§¨‡•ç‡§∞‡•á‡§∞‡•Ä"):
            gr.Markdown("### ‡§Ø‡§π‡§æ‡§Å ‡§®‡§è ‡§∂‡§¨‡•ç‡§¶ ‡§∏‡§ø‡§ñ‡§æ‡§è‡§Ç (English to Hindi / Sanskrit Fix)")
            with gr.Row():
                e_in = gr.Textbox(label="‡§∂‡§¨‡•ç‡§¶ (‡§ú‡•à‡§∏‡•á: ‡§ï‡•É‡§∑‡•ç‡§£)")
                h_in = gr.Textbox(label="‡§â‡§ö‡•ç‡§ö‡§æ‡§∞‡§£ (‡§ú‡•à‡§∏‡•á: ‡§ï‡•É‡§∑‡•ç ‡§£)")
            t_btn = gr.Button("‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§Æ‡•á‡§Ç ‡§∏‡•á‡§µ ‡§ï‡§∞‡•á‡§Ç")
            t_msg = gr.Markdown()
            t_btn.click(lambda e,h: (save_brain({**load_brain(), e:h}), f"‚úÖ ‡§∂‡§ø‡§µ AI ‡§®‡•á ‡§∏‡•Ä‡§ñ ‡§≤‡§ø‡§Ø‡§æ: {e}"), [e_in, h_in], t_msg)

demo.launch(share=True)
