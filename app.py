import os
import torch
import gradio as gr
import requests
import re
import gc
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment, effects

# рез. рдЯрд░реНрдмреЛ рд╣рд╛рдИ рд╕реНрдкреАрдб & GPU рд▓реЙрдХ [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# реи. рдорд╛рд╕реНрдЯрд░ рдореЙрдбрд▓ - рд╢рд┐рд╡ AI (LOCKED) [cite: 2026-02-16, 2026-02-20]
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth" 
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

# рей. рдЧрд┐рдЯрд╣рдм рд▓рд╛рдЗрд╡ рд╕реНрдХреИрдирд░
G_API = "https://api.github.com/repos/shriramnag/Aivoicebox/contents/%F0%9F%93%81%20voices"
G_RAW = "https://raw.githubusercontent.com/shriramnag/Aivoicebox/main/%F0%9F%93%81%20voices/"

def get_live_voices():
    try:
        r = requests.get(G_API, timeout=5).json()
        return [f['name'] for f in r if f['name'].endswith('.wav')]
    except:
        return ["ЁЯСЙЁЯСЙЁЯдЧ Shri Shri ЁЯдЧЁЯСНЁЯЩП.wav", "download (7).wav"]

def apply_cleaner(audio, use_clean):
    """рдЖрд╡рд╛реЫ рдХреЛ рд╕рд╛реЮ рдФрд░ рднрд╛рд░реА рдмрдирд╛рдиреЗ рд╡рд╛рд▓рд╛ рдЯреВрд▓"""
    if use_clean:
        audio = effects.normalize(audio)
        audio = audio.high_pass_filter(80)
    return audio

# тЬи рдирдпрд╛ рдлрдВрдХреНрд╢рди: рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдореЗрдВ рдЯреИрдЧ рдЬреЛреЬрдирд╛ [cite: 2026-02-22]
def add_tag(current_text, tag):
    if not current_text: return tag
    return current_text + f" {tag} "

def generate_final_shiv(text, upload_ref, github_ref, speed_s, pitch_s, use_silence, use_clean, progress=gr.Progress()):
    # рек. рдирдВрдмрд░-рдЯреВ-рд╡рд░реНрдбреНрд╕ рдлрд┐рдХреНрд╕ [cite: 2026-02-20]
    num_map = {'0':'рд╢реВрдиреНрдп','1':'рдПрдХ','2':'рджреЛ','3':'рддреАрди','4':'рдЪрд╛рд░','5':'рдкрд╛рдБрдЪ','6':'рдЫрд╣','7':'рд╕рд╛рдд','8':'рдЖрда','9':'рдиреМ'}
    for n, w in num_map.items(): text = text.replace(n, w)

    # рд╡реЙрдпрд╕ рдЪрдпрди
    ref_path = upload_ref if upload_ref else "temp_ref.wav"
    if not upload_ref:
        url = G_RAW + requests.utils.quote(github_ref)
        with open(ref_path, "wb") as f: f.write(requests.get(url).content)

    # тЪб рел. рдЕрд╕рд▓реА рдкреЙреЫ рдФрд░ рд╕рд╛рдВрд╕ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ (Fix) [cite: 2026-02-22]
    # рд╣рдо рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдХреЛ рдЯреИрдЧреНрд╕ рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рддреЛреЬреЗрдВрдЧреЗ рддрд╛рдХрд┐ рдПрдЖрдИ рдЙрдиреНрд╣реЗрдВ рдкреЭ рди рд╕рдХреЗ
    parts = re.split(r'(\[pause\]|\[breath\])', text)
    combined = AudioSegment.empty()
    
    for part in parts:
        if not part: continue
        
        if part == "[pause]":
            combined += AudioSegment.silent(duration=800) # рдЕрд╕рд▓реА рдард╣рд░рд╛рд╡
        elif part == "[breath]":
            combined += AudioSegment.silent(duration=300) # рд╕рд╛рдВрд╕ рд▓реЗрдиреЗ рдХрд╛ рдЧреИрдк
        else:
            # рд╕рд╛рдзрд╛рд░рдг рдЯреЗрдХреНрд╕реНрдЯ рдЬрдирд░реЗрд╢рди
            sentences = re.split('([ред!?рее\n])', part)
            chunks = [s.strip() for s in sentences if len(s.strip()) > 1]
            for chunk in chunks:
                name = "temp_chunk.wav"
                tts.tts_to_file(text=chunk, speaker_wav=ref_path, language="hi", file_path=name, 
                                speed=speed_s, repetition_penalty=10.0, temperature=0.65)
                chunk_audio = AudioSegment.from_wav(name)
                if use_silence:
                    try: chunk_audio = effects.strip_silence(chunk_audio, silence_thresh=-40, padding=100)
                    except: pass
                combined += chunk_audio
        torch.cuda.empty_cache(); gc.collect()

    # рд╡реЙрдпрд╕ рдХреНрд▓реАрдирд░ & рдмреВрд╕реНрдЯрд░ рдЕрдкреНрд▓рд╛рдИ рдХрд░рдирд╛ [cite: 2026-02-22]
    combined = apply_cleaner(combined, use_clean)

    # тЬЕ рем. рдлрд╛рдЗрдирд▓ рдЖрдЙрдЯрдкреБрдЯ рдирд╛рдо - Shri Ram Nag.wav (LOCKED) [cite: 2026-02-21]
    final_path = "Shri Ram Nag.wav"
    combined.export(final_path, format="wav")
    return final_path

# ЁЯОи рджрд┐рд╡реНрдп UI - рдкреБрд░рд╛рдиреЗ рдХреЛрдб рдХрд╛ рд╕реНрдЯрд╛рдЗрд▓ + рдорд┐рдиреАрдореИрдХреНрд╕ рдмрдЯрдиреНрд╕
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# ЁЯЪй рд╢рд┐рд╡ AI (Shiv AI) - 'рд╢реНрд░реА рд░рд╛рдо рдирд╛рдЧ' рдорд╣рд╛рдЬреНрдЮрд╛рдиреА рдкреНрд░реЛ")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="рдЕрдкрдиреА рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ", lines=12, placeholder="рдкреЙреЫ рдФрд░ рд╕рд╛рдВрд╕ рдХреЗ рдмрдЯрдиреНрд╕ рдХрд╛ рдкреНрд░рдпреЛрдЧ рдХрд░реЗрдВ...")
            
            # тЬи рдорд┐рдиреАрдореИрдХреНрд╕ рд╕реНрдЯрд╛рдЗрд▓ рдмрдЯрдиреНрд╕ [cite: 2026-02-22]
            with gr.Row():
                p_btn = gr.Button("тП╕я╕П Pause (рдард╣рд░рд╛рд╡)")
                b_btn = gr.Button("ЁЯТи Breath (рд╕рд╛рдВрд╕)")
            
            p_btn.click(add_tag, [txt, gr.State("[pause]")], [txt])
            b_btn.click(add_tag, [txt, gr.State("[breath]")], [txt])
            
            word_counter = gr.Markdown("рд╢рдмреНрдж рд╕рдВрдЦреНрдпрд╛: рд╢реВрдиреНрдп")
            txt.change(lambda x: f"рд╢рдмреНрдж рд╕рдВрдЦреНрдпрд╛: {len(x.split()) if x else 'рд╢реВрдиреНрдп'}", [txt], [word_counter])
            
        with gr.Column(scale=1):
            v_list = get_live_voices()
            git_voice = gr.Dropdown(choices=v_list, label="рдЧрд┐рдЯрд╣рдм рд╡реЙрдпрд╕ (рдСрдЯреЛ-рд╕реНрдХреИрди)", value=v_list[0])
            manual = gr.Audio(label="рдпрд╛ рдпрд╣рд╛рдБ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ", type="filepath")
            
            with gr.Accordion("ЁЯЫая╕П рд╕реБрдкрд░ рдЯреВрд▓реНрд╕ (LOCKED)", open=True):
                clean_btn = gr.Checkbox(label="AI рд╡реЙрдпрд╕ рдХреНрд▓реАрдирд░ & рдмреВрд╕реНрдЯрд░", value=True)
                silence_btn = gr.Checkbox(label="рд╕рд╛рдЗрд▓реЗрдВрд╕ рд░рд┐рдореВрд╡рд░", value=True)
            
            with gr.Accordion("тЪЩя╕П рд╕реЗрдЯрд┐рдВрдЧреНрд╕", open=False):
                speed = gr.Slider(label="рд░реЮреНрддрд╛рд░", minimum=0.8, maximum=1.4, value=1.0)
                pitch = gr.Slider(label="рдкрд┐рдЪ", minimum=0.8, maximum=1.1, value=0.96)
            
            btn = gr.Button("рджрд┐рд╡реНрдп рдЬрдирд░реЗрд╢рди рд╢реБрд░реВ рдХрд░реЗрдВ ЁЯЪА", variant="primary")
            
    out = gr.Audio(label="рдбрд╛рдЙрдирд▓реЛрдб: Shri Ram Nag.wav", type="filepath", autoplay=True)
    btn.click(generate_final_shiv, [txt, manual, git_voice, speed, pitch, silence_btn, clean_btn], out)

demo.launch(share=True)
