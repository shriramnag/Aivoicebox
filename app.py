import os
import torch
import gradio as gr
import shutil
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from app_config import MODEL_CONFIG
from text_engine import split_into_chunks
from parallel_processor import combine_chunks

# тЪб рдЯрд░реНрдмреЛ рд╣рд╛рдИ рд╕реНрдкреАрдб рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"
torch.backends.cudnn.benchmark = True 

# ЁЯУе 100% рдореИрдЪ рдЗрдВрдЬрди рд▓реЛрдб
print(f"тП│ рд╢реНрд░реАрд░рд╛рдо рдорд╛рд╕реНрдЯрд░ рдЗрдВрдЬрди рд▓реЛрдб рд╣реЛ рд░рд╣рд╛ рд╣реИ...")
model_path = hf_hub_download(repo_id=MODEL_CONFIG["repo_id"], filename=MODEL_CONFIG["model_file"])
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

def generate_voice(text, voice_sample, speed, pitch, emotion_scale, progress=gr.Progress()):
    if not text or not voice_sample:
        raise gr.Error("рдХреГрдкрдпрд╛ рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдФрд░ рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓ рджреЛрдиреЛрдВ рдкреНрд░рджрд╛рди рдХрд░реЗрдВред") 
    
    # ЁЯз╣ рдСрдЯреЛ-рдХреНрд▓реАрдирд░ (0:00 рдПрд░рд░ рдлрд┐рдХреНрд╕)
    output_folder = "outputs"
    if os.path.exists(output_folder): shutil.rmtree(output_folder)
    os.makedirs(output_folder, exist_ok=True)
    
    # тЪб рдЯрд░реНрдмреЛ рдЪрдВрдХрд┐рдВрдЧ
    chunks = split_into_chunks(text) 
    chunk_files = []
    
    for i, chunk in enumerate(chunks):
        progress((i+1)/len(chunks), desc=f"ЁЯЪА рдиреЗрдЪреБрд░рд▓ рдХреНрд▓реЛрдирд┐рдВрдЧ: {i+1}/{len(chunks)}") 
        name = os.path.join(output_folder, f"chunk_{i}.wav")
        
        # ЁЯОЩя╕П рд╣рдХрд▓рд╛рд╣рдЯ, рдЪреАрдиреА рд╢реЛрд░ рдФрд░ рд╕рд╛рдБрд╕ рд▓реЗрдиреЗ рдХрд╛ рдлрд┐рдХреНрд╕ [cite: 2026-01-06]
        # рдпрд╣рд╛рдБ temperature рдФрд░ top_k рдХреЛ "рдиреЛ-рдЧреНрд▓рд┐рдЪ" рдореЛрдб рдкрд░ рд╕реЗрдЯ рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ
        current_temp = 0.75 + (emotion_scale * 0.05) 
        
        tts.tts_to_file(
            text=chunk, 
            speaker_wav=voice_sample, 
            language="hi", 
            file_path=name,
            speed=speed,               
            repetition_penalty=15.0,   # ЁЯСИ рд╣рдХрд▓рд╛рд╣рдЯ рд░реЛрдХрдиреЗ рдХреЗ рд▓рд┐рдП рд╕рдмрд╕реЗ рд╕рдЦреНрдд рд╕реЗрдЯрд┐рдВрдЧ
            temperature=current_temp,  
            top_p=0.85,                # ЁЯСИ рд╕рд╛рдБрд╕ рдФрд░ рдиреЗрдЪреБрд░рд▓ рдлреАрд▓ рдХреЗ рд▓рд┐рдП
            top_k=25,                  # ЁЯСИ рдЪреАрдиреА рднрд╛рд╖рд╛/рдЕрдЬреАрдм рд╢реЛрд░ рд░реЛрдХрдиреЗ рдХреЗ рд▓рд┐рдП рд▓реЙрдХ рдХрд┐рдпрд╛ рдЧрдпрд╛
            length_penalty=1.0,        
            enable_text_splitting=False 
        )
        chunk_files.append(name)
    
    # тЪб рдЯрд░реНрдмреЛ рд╣рд╛рдИ рд╕реНрдкреАрдб рдорд░реНрдЬрд┐рдВрдЧ
    final_output = os.path.abspath("shriram_final_pro.wav")
    combine_chunks(chunk_files, output_file=final_output)
    return final_output

# ЁЯОи рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА UI (рдкрд░рдлреЗрдХреНрдЯ рд╕реЗрдЯрд┐рдВрдЧреНрд╕ рдХреЗ рд╕рд╛рде)
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange"), title="рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА AI") as demo:
    gr.Markdown("# ЁЯОЩя╕П рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА - рдорд╛рд╕реНрдЯрд░ рдЯрд░реНрдмреЛ v2 (Stable)")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(
                label="рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ", 
                lines=12, 
                placeholder="рд╕рд╛рдБрд╕ рдФрд░ рдкреЙреЫ рдХреЗ рд▓рд┐рдП рдХреЛрдорд╛ (,) рдпрд╛ рдкреВрд░реНрдгрд╡рд┐рд░рд╛рдо (ред) рдХрд╛ рдкреНрд░рдпреЛрдЧ рдХрд░реЗрдВ рдФрд░ рдПрдХ рд╕реНрдкреЗрд╕ рджреЗрдВ..."
            )
        with gr.Column(scale=1):
            ref = gr.Audio(label="рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ", type="filepath", interactive=True)
            
            # ЁЯОЪя╕П рдЯрд░реНрдмреЛ рдХрдВрдЯреНрд░реЛрд▓реНрд╕ (рд▓реЙрдХреНрдб)
            speed_slider = gr.Slider(label="рдЖрд╡рд╛реЫ рдХреА рд░реЮреНрддрд╛рд░ (Speed)", minimum=0.5, maximum=1.5, value=1.0, step=0.1)
            pitch_slider = gr.Slider(label="рдЖрд╡рд╛реЫ рдХреА рдЧрд╣рд░рд╛рдИ (Deep Match)", minimum=0.5, maximum=1.0, value=0.80, step=0.05)
            emotion_slider = gr.Slider(label="рдЗрдореЛрд╢рди/рд╕рд╛рдБрд╕ рдХреА рддреАрд╡реНрд░рддрд╛", minimum=0.1, maximum=1.0, value=0.5, step=0.1)
            
            btn = gr.Button("ЁЯЪА рдЯрд░реНрдмреЛ рдЬрдирд░реЗрдЯ рдХрд░реЗрдВ", variant="primary")
            
    with gr.Row():
        out = gr.Audio(label="рдлрд╛рдЗрдирд▓ рдХреНрд▓реЛрди рдХреА рдЧрдИ рдЖрд╡рд╛рдЬрд╝", type="filepath", autoplay=True)

    btn.click(generate_voice, [txt, ref, speed_slider, pitch_slider, emotion_slider], out)

if __name__ == "__main__":
    demo.launch(share=True, allowed_paths=[os.getcwd(), "/content/"])
