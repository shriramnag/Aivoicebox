import os
import torch
import gradio as gr
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from app_config import MODEL_CONFIG
from text_engine import split_into_chunks
from parallel_processor import combine_chunks

# тЪб рдЯрд░реНрдмреЛ рд╣рд╛рдИ рд╕реНрдкреАрдб рд╕реЗрдЯрдЕрдк [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
# GPU рдХрд╛ рдЕрдзрд┐рдХрддрдо рдЙрдкрдпреЛрдЧ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рдирд╛
device = "cuda" if torch.cuda.is_available() else "cpu"

# ЁЯУе рдореЙрдбрд▓ рд▓реЛрдб (рдЯрд░реНрдмреЛ рдореЛрдб)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

def generate_voice(text, voice_sample, speed, pitch, progress=gr.Progress()):
    if not text or not voice_sample:
        raise gr.Error("рдХреГрдкрдпрд╛ рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдФрд░ рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓ рджреЗрдВред") 
    
    # рдЯрд░реНрдмреЛ рд╕реНрдкреАрдб рдХреЗ рд▓рд┐рдП рдЯреБрдХрдбрд╝реЛрдВ рдХреЛ рдЫреЛрдЯрд╛ рдФрд░ рдореИрдиреЗрдЬреНрдб рд░рдЦрдирд╛ [cite: 2026-01-06]
    chunks = split_into_chunks(text) 
    chunk_files = []
    
    for i, chunk in enumerate(chunks):
        progress((i+1)/len(chunks), desc=f"ЁЯЪА рдЯрд░реНрдмреЛ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ: {i+1}/{len(chunks)}") 
        name = os.path.abspath(f"chunk_{i}.wav")
        
        # рд╕реНрдкреАрдб рдФрд░ рдкрд┐рдЪ рдХреЗ рд╕рд╛рде реЮрд╛рд╕реНрдЯ рдЬрдирд░реЗрд╢рди [cite: 2026-01-06]
        tts.tts_to_file(
            text=chunk, 
            speaker_wav=voice_sample, 
            language="hi", 
            file_path=name,
            speed=speed,              # рд░реЮреНрддрд╛рд░ рдХрдВрдЯреНрд░реЛрд▓
            repetition_penalty=10.0,  # рд╣рдХрд▓рд╛рд╣рдЯ рдлрд┐рдХреНрд╕
            temperature=pitch,        # рдкрд┐рдЪ/рдЧрдВрднреАрд░рддрд╛ рдХрдВрдЯреНрд░реЛрд▓
            enable_text_splitting=True # рдЯрд░реНрдмреЛ рдХреЗ рд▓рд┐рдП реЫрд░реВрд░реА
        )
        chunk_files.append(name)
    
    # рд╣рд╛рдИ рд╕реНрдкреАрдб рдорд░реНрдЬрд┐рдВрдЧ [cite: 2026-01-06]
    final_output = combine_chunks(chunk_files)
    return os.path.abspath(final_output)

# ЁЯОи рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА - рдкреНрд░реЛрдлреЗрд╢рдирд▓ рд▓реБрдХ v2
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange"), title="рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА AI") as demo:
    gr.Markdown("# ЁЯОЩя╕П рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА - рдЯрд░реНрдмреЛ рд╣рд╛рдИ рд╕реНрдкреАрдб v2")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдкреЗрд╕реНрдЯ рдХрд░реЗрдВ", lines=12, placeholder="рдпрд╣рд╛рдБ рдХрд╣рд╛рдиреА рд▓рд┐рдЦреЗрдВ...")
        with gr.Column(scale=1):
            ref = gr.Audio(label="рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓ (wav)", type="filepath", interactive=True)
            
            # ЁЯОЪя╕П рдПрдбрд╡рд╛рдВрд╕ рд╕реНрд▓рд╛рдЗрдбрд░реНрд╕ (Pitch рдФрд░ Speed) [cite: 2026-01-06]
            speed_slider = gr.Slider(label="рдЖрд╡рд╛реЫ рдХреА рд░реЮреНрддрд╛рд░ (Speed)", minimum=0.5, maximum=2.0, value=1.0, step=0.1)
            pitch_slider = gr.Slider(label="рдЖрд╡рд╛реЫ рдХреА рдкрд┐рдЪ (Pitch)", minimum=0.5, maximum=1.0, value=0.75, step=0.05)
            
            btn = gr.Button("ЁЯЪА рдЯрд░реНрдмреЛ рдЬрдирд░реЗрдЯ рдХрд░реЗрдВ", variant="primary")
            
    with gr.Row():
        out = gr.Audio(label="рдЕрдВрддрд┐рдо рдХреНрд▓реЛрди рдХреА рдЧрдИ рдЖрд╡рд╛рдЬрд╝", type="filepath", autoplay=True)

    btn.click(generate_voice, [txt, ref, speed_slider, pitch_slider], out)

if __name__ == "__main__":
    demo.launch(share=True, allowed_paths=[os.getcwd()])
