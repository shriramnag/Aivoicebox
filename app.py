import os
import torch
import gradio as gr
import shutil
import re
import gc
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment
from brain import MahagyaniBrain 

# ‚ö° ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§π‡§æ‡§à ‡§∏‡•ç‡§™‡•Ä‡§° & GPU ‡§≤‡•â‡§ï [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# üì• ‡§Æ‡§æ‡§∏‡•ç‡§ü‡§∞ ‡§Æ‡•â‡§°‡§≤ [cite: 2026-02-16]
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth"
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

# üß† ‡§Æ‡§π‡§æ‡§ú‡•ç‡§û‡§æ‡§®‡•Ä ‡§¨‡•ç‡§∞‡•á‡§®
brain = MahagyaniBrain(
    'sanskrit_knowledge.json', 'hindi_grammar.json', 
    'english_knowledge.json', 'prosody_config.json'
)

def permanent_number_fix(text):
    """NotImplementedError ‡§ï‡•ã ‡§π‡§Æ‡•á‡§∂‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ñ‡§§‡•ç‡§Æ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è"""
    # ‡§®‡§Ç‡§¨‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§®‡•á ‡§ï‡§æ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§§‡§∞‡•Ä‡§ï‡§æ
    num_map = {
        '0':'‡§∂‡•Ç‡§®‡•ç‡§Ø','1':'‡§è‡§ï','2':'‡§¶‡•ã','3':'‡§§‡•Ä‡§®','4':'‡§ö‡§æ‡§∞','5':'‡§™‡§æ‡§Å‡§ö',
        '6':'‡§õ‡§π','7':'‡§∏‡§æ‡§§','8':'‡§Ü‡§†','9':'‡§®‡•å'
    }
    for num, word in num_map.items():
        text = text.replace(num, word)
    return text

def count_words(text):
    """‡§µ‡§∞‡•ç‡§° ‡§ï‡§æ‡§â‡§Ç‡§ü‡§∞ ‡§≤‡•â‡§ú‡§ø‡§ï [cite: 2026-02-18]"""
    if not text: return "‡§∂‡§¨‡•ç‡§¶: 0"
    words = len(text.split())
    return f"‡§∂‡§¨‡•ç‡§¶: {words}"

def split_into_chunks(text):
    """‡§ö‡§Ç‡§ï‡§ø‡§Ç‡§ó ‡§≤‡•â‡§ú‡§ø‡§ï - LOCKED [cite: 2026-02-18]"""
    sentences = re.split('([‡•§!?‡••\n])', text)
    chunks = []
    current_chunk = ""
    for i in range(0, len(sentences)-1, 2):
        sentence = sentences[i] + sentences[i+1]
        if len(current_chunk) + len(sentence) < 150:
            current_chunk += sentence
        else:
            if current_chunk: chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk: chunks.append(current_chunk.strip())
    return [c for c in chunks if len(c) > 2]

def generate_voice(text, voice_sample, speed_s, pitch_s, weight_s, amp_s, progress=gr.Progress()):
    # 1. ‡§™‡§∞‡§Æ‡§æ‡§®‡•á‡§Ç‡§ü ‡§è‡§∞‡§∞ ‡§´‡§ø‡§ï‡•ç‡§∏ ‡§î‡§∞ ‡§¨‡•ç‡§∞‡•á‡§® ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó
    text = permanent_number_fix(text) 
    cleaned_text = brain.clean_and_format(text)
    profile = brain.get_voice_profile(text)
    final_speed = profile['global_speed'] if "‡••" in text else speed_s
    
    # 2. ‡§ö‡§Ç‡§ï‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§™‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡•á‡§∏ ‡§ó‡§ø‡§®‡§§‡•Ä
    chunks = split_into_chunks(cleaned_text)
    total = len(chunks)
    chunk_files = []
    output_folder = "turbo_cache"
    if os.path.exists(output_folder): shutil.rmtree(output_folder)
    os.makedirs(output_folder)

    combined = AudioSegment.empty()
    for i, chunk in enumerate(chunks):
        progress((i+1)/total, desc=f"üöÄ ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§ú‡§®‡§∞‡•á‡§∂‡§®: ‡§≠‡§æ‡§ó {i+1} / {total}")
        name = os.path.join(output_folder, f"c_{i}.wav")
        tts.tts_to_file(
            text=chunk, speaker_wav=voice_sample, language="hi", file_path=name,
            speed=final_speed, temperature=0.75, repetition_penalty=5.0
        )
        combined += AudioSegment.from_wav(name)
        if i % 5 == 0: torch.cuda.empty_cache(); gc.collect()

    final_path = "shriram_fixed_final.wav"
    combined.export(final_path, format="wav")
    return final_path

# üé® UI ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® (Word Counter ‡§ï‡•á ‡§∏‡§æ‡§•)
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# üö© ‡§∂‡•ç‡§∞‡•Ä‡§∞‡§æ‡§Æ ‡§µ‡§æ‡§£‡•Ä - ‡§Æ‡§π‡§æ‡§ú‡•ç‡§û‡§æ‡§®‡•Ä ‡§ü‡§∞‡•ç‡§¨‡•ã (LOCKED)")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="‡§Ö‡§™‡§®‡•Ä ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§Ø‡§π‡§æ‡§Å ‡§™‡•á‡§∏‡•ç‡§ü ‡§ï‡§∞‡•á‡§Ç", lines=12)
            word_count_display = gr.Label(value="‡§∂‡§¨‡•ç‡§¶: 0", label="‡§ï‡§æ‡§â‡§Ç‡§ü‡§∞")
            # ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§¨‡§¶‡§≤‡§§‡•á ‡§π‡•Ä ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•ã ‡§ó‡§ø‡§®‡§®‡§æ
            txt.change(count_words, inputs=[txt], outputs=[word_count_display])
            
        with gr.Column(scale=1):
            ref = gr.Audio(label="‡§Æ‡§æ‡§∏‡•ç‡§ü‡§∞ ‡§∏‡•à‡§Ç‡§™‡§≤", type="filepath")
            with gr.Accordion("‚öôÔ∏è ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏ (LOCKED)", open=True):
                speed_s = gr.Slider(label="‡§∞‡•û‡•ç‡§§‡§æ‡§∞", minimum=0.8, maximum=1.4, value=1.0)
                pitch_s = gr.Slider(label="‡§™‡§ø‡§ö", minimum=0.8, maximum=1.1, value=0.96)
                weight_s = gr.Slider(label="‡§≠‡§æ‡§∞‡•Ä‡§™‡§®", minimum=0, maximum=10, value=6)
                amp_s = gr.Slider(label="‡§∂‡§ï‡•ç‡§§‡§ø", minimum=-5, maximum=10, value=4)
            btn = gr.Button("‡§¶‡§ø‡§µ‡•ç‡§Ø ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•á‡§Ç üöÄ", variant="primary")
            
    out = gr.Audio(label="100% ‡§∂‡•Å‡§¶‡•ç‡§ß ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü", type="filepath", autoplay=True)
    btn.click(generate_voice, [txt, ref, speed_s, pitch_s, weight_s, amp_s], out)

demo.launch(share=True)
