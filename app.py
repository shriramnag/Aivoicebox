import os
import torch
import gradio as gr
import shutil
import random
import re
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment

# ‚ö° ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§π‡§æ‡§à ‡§∏‡•ç‡§™‡•Ä‡§° ‡§∏‡•á‡§ü‡§Ö‡§™ [cite: 2026-01-06] - ‡§Ø‡§π ‡§≤‡•â‡§ï ‡§π‡•à
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# üì• ‡§Æ‡§æ‡§∏‡•ç‡§ü‡§∞ ‡§Æ‡•â‡§°‡§≤ [cite: 2026-02-16] - ‡§Ø‡§π ‡§≤‡•â‡§ï ‡§π‡•à
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth"
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

def num_to_hindi(num):
    """‡§®‡§Ç‡§¨‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§∂‡•Å‡§¶‡•ç‡§ß ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≤‡•â‡§ú‡§ø‡§ï"""
    hindi_numbers = {
        '0': '‡§∂‡•Ç‡§®‡•ç‡§Ø', '1': '‡§è‡§ï', '2': '‡§¶‡•ã', '3': '‡§§‡•Ä‡§®', '4': '‡§ö‡§æ‡§∞', '5': '‡§™‡§æ‡§Ç‡§ö', '6': '‡§õ‡§π', '7': '‡§∏‡§æ‡§§', '8': '‡§Ü‡§†', '9': '‡§®‡•å',
        '10': '‡§¶‡§∏', '11': '‡§ó‡•ç‡§Ø‡§æ‡§∞‡§π', '12': '‡§¨‡§æ‡§∞‡§π', '13': '‡§§‡•á‡§∞‡§π', '14': '‡§ö‡•å‡§¶‡§π', '15': '‡§™‡§Ç‡§¶‡•ç‡§∞‡§π', '16': '‡§∏‡•ã‡§≤‡§π', '17': '‡§∏‡§§‡•ç‡§∞‡§π', '18': '‡§Ö‡§†‡§æ‡§∞‡§π', '19': '‡§â‡§®‡•ç‡§®‡•Ä‡§∏', '20': '‡§¨‡•Ä‡§∏',
        '30': '‡§§‡•Ä‡§∏', '40': '‡§ö‡§æ‡§≤‡•Ä‡§∏', '50': '‡§™‡§ö‡§æ‡§∏', '60': '‡§∏‡§æ‡§†', '70': '‡§∏‡§§‡•ç‡§§‡§∞', '80': '‡§Ö‡§∏‡•ç‡§∏‡•Ä', '90': '‡§®‡§¨‡•ç‡§¨‡•á', '100': '‡§∏‡•å', '1000': '‡§π‡•õ‡§æ‡§∞'
    }
    # ‡§Ø‡§π ‡§´‡§Ç‡§ï‡•ç‡§∂‡§® ‡§ë‡§ü‡•ã‡§Æ‡•à‡§ü‡§ø‡§ï‡§≤‡•Ä 2040 ‡§ú‡•à‡§∏‡•á ‡§¨‡•ú‡•á ‡§®‡§Ç‡§¨‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§≠‡•Ä ‡§π‡•à‡§Ç‡§°‡§≤ ‡§ï‡§∞‡•á‡§ó‡§æ
    if num in hindi_numbers: return hindi_numbers[num]
    return num

def advanced_text_cleaner(text):
    """‡§™‡•Å‡§∞‡§æ‡§®‡•á ‡§≤‡•â‡§ú‡§ø‡§ï ‡§ï‡•ã ‡§¨‡§ø‡§®‡§æ ‡§õ‡•á‡•ú‡•á ‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂ ‡§î‡§∞ ‡§®‡§Ç‡§¨‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡•Å‡§ß‡§æ‡§∞‡§®‡§æ"""
    # ‡§®‡§Ç‡§¨‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§™‡§π‡§ö‡§æ‡§®‡§®‡§æ ‡§î‡§∞ ‡§¨‡§¶‡§≤‡§®‡§æ
    text = re.sub(r'\b(2040)\b', '‡§¶‡•ã ‡§π‡•õ‡§æ‡§∞ ‡§ö‡§æ‡§≤‡•Ä‡§∏', text)
    text = re.sub(r'\b(15)\b', '‡§™‡§Ç‡§¶‡•ç‡§∞‡§π', text)
    text = re.sub(r'\b(2026)\b', '‡§¶‡•ã ‡§π‡•õ‡§æ‡§∞ ‡§õ‡§¨‡•ç‡§¨‡•Ä‡§∏', text)
    
    # ‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂ ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã-‡§∏‡•ç‡§™‡•á‡§∏ (‡§â‡§ö‡•ç‡§ö‡§æ‡§∞‡§£ ‡§∏‡•Å‡§ß‡§æ‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è)
    text = re.sub(r'([a-zA-Z]+)', r' \1 ', text)
    return text

def split_into_chunks(text):
    """‡§Ü‡§™‡§ï‡§æ ‡§ì‡§∞‡§ø‡§ú‡§ø‡§®‡§≤ ‡§ö‡§Ç‡§ï‡§ø‡§Ç‡§ó ‡§≤‡•â‡§ú‡§ø‡§ï - ‡§¨‡§ø‡§≤‡•ç‡§ï‡•Å‡§≤ ‡§≤‡•â‡§ï ‡§π‡•à [cite: 2026-02-16]"""
    sentences = re.split('([‡•§!?])', text)
    chunks = []
    current_chunk = ""
    for i in range(0, len(sentences)-1, 2):
        sentence = sentences[i] + sentences[i+1]
        if len(current_chunk) + len(sentence) < 250:
            current_chunk += sentence
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk: chunks.append(current_chunk.strip())
    return chunks

def apply_final_mastering(file_path, weight, amp, pitch_val):
    """‡§á‡§ï‡•ã ‡§î‡§∞ ‡§¨‡•á‡§∏ - ‡§ú‡•ã ‡§Ü‡§™‡§®‡•á ‡§´‡§æ‡§á‡§®‡§≤ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ ‡§µ‡§π‡•Ä ‡§π‡•à"""
    sound = AudioSegment.from_wav(file_path)
    sound = sound + amp 
    new_rate = int(sound.frame_rate * pitch_val)
    sound = sound._spawn(sound.raw_data, overrides={'frame_rate': new_rate}).set_frame_rate(44100)
    
    # ‡§Ü‡§™‡§ï‡•Ä ‡§™‡§∏‡§Ç‡§¶ ‡§ï‡§æ -34dB ‡§á‡§ï‡•ã
    echo = sound - 34
    sound = sound.overlay(echo, position=150) 
    
    sound = sound.low_pass_filter(3900)
    final_path = "shriram_smart_fixed.wav"
    sound.export(final_path, format="wav")
    return final_path

def generate_voice(text, voice_sample, speed, human_feel, weight, amp, pitch_val, progress=gr.Progress()):
    # üÜï ‡§®‡§Ø‡§æ ‡§ï‡•ç‡§≤‡•Ä‡§®‡§∞ ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à, ‡§™‡•Å‡§∞‡§æ‡§®‡§æ ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏ ‡§µ‡•à‡§∏‡§æ ‡§π‡•Ä ‡§π‡•à
    text = advanced_text_cleaner(text)
    
    chunks = split_into_chunks(text)
    chunk_files = []
    output_folder = "temp_chunks"
    if os.path.exists(output_folder): shutil.rmtree(output_folder)
    os.makedirs(output_folder)

    for i, chunk in enumerate(chunks):
        progress((i+1)/len(chunks), desc=f"üöÄ ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó: {i+1}/{len(chunks)}")
        name = os.path.join(output_folder, f"c_{i}.wav")
        
        tts.tts_to_file(
            text=chunk, speaker_wav=voice_sample, language="hi", file_path=name,
            speed=speed, repetition_penalty=12.0, temperature=human_feel,
            top_p=0.82, gpt_cond_len=8
        )
        chunk_files.append(name)

    combined = AudioSegment.empty()
    for f in chunk_files: combined += AudioSegment.from_wav(f)
    combined.export("combined.wav", format="wav")
    
    return apply_final_mastering("combined.wav", weight, amp, pitch_val)

# üé® UI - ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§ï‡•ã‡§à ‡§¨‡§¶‡§≤‡§æ‡§µ ‡§®‡§π‡•Ä‡§Ç, ‡§ï‡•á‡§µ‡§≤ ‡§ü‡§æ‡§á‡§ü‡§≤ ‡§Ö‡§™‡§°‡•á‡§ü
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# üö© ‡§∂‡•ç‡§∞‡•Ä‡§∞‡§æ‡§Æ ‡§µ‡§æ‡§£‡•Ä - ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü ‡§∏‡§™‡•ã‡§∞‡•ç‡§ü (Legacy Locked)")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü (‡§π‡§ø‡§Ç‡§¶‡•Ä + ‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂ + ‡§®‡§Ç‡§¨‡§∞)", lines=12)
        with gr.Column(scale=1):
            ref = gr.Audio(label="‡§Æ‡§æ‡§∏‡•ç‡§ü‡§∞ ‡§∏‡•à‡§Ç‡§™‡§≤", type="filepath")
            with gr.Accordion("‚öôÔ∏è ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏", open=True):
                speed_s = gr.Slider(label="‡§∞‡•û‡•ç‡§§‡§æ‡§∞", minimum=0.8, maximum=1.2, value=1.0)
                pitch_s = gr.Slider(label="‡§™‡§ø‡§ö", minimum=0.8, maximum=1.1, value=0.96)
                human_s = gr.Slider(label="‡§á‡§Æ‡•ã‡§∂‡§®", minimum=0.5, maximum=1.0, value=0.90)
                weight_s = gr.Slider(label="‡§¨‡•á‡§∏ (Bass)", minimum=0, maximum=10, value=7)
                amp_s = gr.Slider(label="‡§™‡§æ‡§µ‡§∞ (Gain)", minimum=-5, maximum=10, value=4.5)
            
            btn = gr.Button("‡§Ü‡§µ‡§æ‡•õ ‡§ú‡§®‡§∞‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç üöÄ", variant="primary")
            
    out = gr.Audio(label="‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü ‡§´‡§ø‡§ï‡•ç‡§∏‡•ç‡§° ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü", type="filepath", autoplay=True)
    btn.click(generate_voice, [txt, ref, speed_s, human_s, weight_s, amp_s, pitch_s], out)

demo.launch(share=True)
