import os
import torch
import gradio as gr
from TTS.api import TTS
from pydub import AudioSegment
from pydub.silence import split_on_silence
from huggingface_hub import hf_hub_download
import re

# 1. рд╣рдЧрд┐рдВрдЧ рдлреЗрд╕ рд╕реЗ рдореЙрдбрд▓ рдбрд╛рдЙрдирд▓реЛрдб (рдСрдЯреЛрдореЗрдЯрд┐рдХ)
# рдпрд╣ рд╣рд┐рд╕реНрд╕рд╛ рдкреБрд░рд╛рдиреЗ рдХреЛрдб рдХреЗ рдКрдкрд░ рд░рд╣реЗрдЧрд╛
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth"  # рдЖрдкрдХрд╛ 1000 Epochs рд╡рд╛рд▓рд╛ рдирдпрд╛ рдореЙрдбрд▓
INDEX_FILE = "added_IVF759_Flat_nprobe_Ramai_Shri_Ram_Voice_Training.index" # рдкреВрд░рд╛ рдирд╛рдо рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ

print("тП│ рд╣рдЧрд┐рдВрдЧ рдлреЗрд╕ рд╕реЗ рдирдпрд╛ рдореЙрдбрд▓ рдФрд░ рдЗрдВрдбреЗрдХреНрд╕ рдлрд╛рдЗрд▓ рдбрд╛рдЙрдирд▓реЛрдб рд╣реЛ рд░рд╣реА рд╣реИ...")
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
index_path = hf_hub_download(repo_id=REPO_ID, filename=INDEX_FILE)
print(f"тЬЕ рдореЙрдбрд▓ рдбрд╛рдЙрдирд▓реЛрдб рд╕рдлрд▓: {model_path}")

# 2. рдЯрд░реНрдмреЛ рд╕реНрдЯрд╛рд░реНрдЯрдЕрдк рдФрд░ рдПрдЧреНрд░реАрдореЗрдВрдЯ
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

def clean_hindi_text(text):
    # рдпрд╣ рджреВрд╕рд░реА рднрд╛рд╖рд╛ (рдЪреАрдиреА/рдЬреИрдкрдиреАрдЬ) рдмреЛрд▓рдиреЗ рд╕реЗ рд░реЛрдХрддрд╛ рд╣реИ
    return re.sub(r'[^\u0900-\u097F\sред,.?]', '', text)

def generate_voice(text, voice_sample, remove_silence):
    pure_text = clean_hindi_text(text)
    output_path = "final_output.wav"
    
    # рд╢реБрджреНрдз рд╣рд┐рдВрджреА рдФрд░ рд╣рдХрд▓рд╛рдирд╛ рд░реЛрдХрдиреЗ рдХреЗ рд▓рд┐рдП рдлрд┐рдХреНрд╕
    tts.tts_to_file(
        text=pure_text, 
        speaker_wav=voice_sample, 
        language="hi",
        file_path=output_path,
        split_sentences=True # рд╣рдХрд▓рд╛рдиреЗ рдХрд╛ рдЗрд▓рд╛рдЬ
    )
    
    # рд╕рдиреНрдирд╛рдЯрд╛ рд╣рдЯрд╛рдирд╛ (Silence Remover)
    if remove_silence:
        sound = AudioSegment.from_file(output_path)
        chunks = split_on_silence(sound, min_silence_len=400, silence_thresh=-45)
        combined = AudioSegment.empty()
        for chunk in chunks:
            combined += chunk
        output_path = "clean_final.wav"
        combined.export(output_path, format="wav")
    
    return output_path

# 3. рдЗрдВрдЯрд░рдлрд╝реЗрд╕ (Dark Mode)
with gr.Blocks(theme=gr.themes.Default(primary_hue="orange")) as demo:
    demo.load(None, None, None, _js="() => { document.body.classList.add('dark'); }")
    gr.Markdown("# ЁЯОЩя╕П **рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА - рд╢реБрджреНрдз рд╣рд┐рдВрджреА рдЯрд░реНрдмреЛ (v2)**")
    
    with gr.Row():
        with gr.Column():
            input_text = gr.Textbox(label="рд╣рд┐рдВрджреА рдЯреЗрдХреНрд╕реНрдЯ рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ", value="рдирдорд╕реНрддреЗ, рдореИрдВ рдЕрдм рд╢реБрджреНрдз рд╣рд┐рдВрджреА рдмреЛрд▓реВрдБрдЧрд╛ред")
            audio_input = gr.Audio(label="рдЕрдкрдиреА рдЖрд╡рд╛рдЬрд╝ рдХрд╛ рд╕реИрдВрдкрд▓ (.wav)", type="filepath")
            silence_btn = gr.Checkbox(label="рд╕рдиреНрдирд╛рдЯрд╛ рд╣рдЯрд╛рдПрдБ (Silence Remover)", value=True)
            btn = gr.Button("ЁЯЪА рдЖрд╡рд╛рдЬрд╝ рдЙрддреНрдкрдиреНрди рдХрд░реЗрдВ", variant="primary")
        
        with gr.Column():
            audio_out = gr.Audio(label="рдЖрдЙрдЯрдкреБрдЯ")

    btn.click(generate_voice, [input_text, audio_input, silence_btn], audio_out)

if __name__ == "__main__":
    demo.launch(share=True)
