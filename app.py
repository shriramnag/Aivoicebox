import os
import torch
import gradio as gr
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from app_config import MODEL_CONFIG
from text_engine import split_into_chunks
from parallel_processor import combine_chunks

# тЪб рдЯрд░реНрдмреЛ рд╕реЗрдЯрдЕрдк [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ЁЯУе рдореЙрдбрд▓ рд▓реЛрдб
print(f"тП│ рдореЙрдбрд▓ рд▓реЛрдб рд╣реЛ рд░рд╣рд╛ рд╣реИ...")
model_path = hf_hub_download(repo_id=MODEL_CONFIG["repo_id"], filename=MODEL_CONFIG["model_file"])
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

def generate_voice(text, voice_sample, progress=gr.Progress()):
    if not text or not voice_sample:
        raise gr.Error("рдХреГрдкрдпрд╛ рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдФрд░ рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓ рджреЛрдиреЛрдВ рдкреНрд░рджрд╛рди рдХрд░реЗрдВред") 
    
    chunks = split_into_chunks(text) 
    chunk_files = []
    
    for i, chunk in enumerate(chunks):
        progress(i/len(chunks), desc=f"рд╡рд╛рдХреНрдп {i+1}/{len(chunks)} рд╕рд╛реЮ рдХрд┐рдпрд╛ рдЬрд╛ рд░рд╣рд╛ рд╣реИ...") 
        name = os.path.abspath(f"chunk_{i}.wav")
        
        # ЁЯОЩя╕П рд╣рдХрд▓рд╛рд╣рдЯ рд░реЛрдХрдиреЗ рдХреЗ рд▓рд┐рдП рд╕реНрдкреЗрд╢рд▓ рд╕реЗрдЯрд┐рдВрдЧреНрд╕ (Hidden Fix) [cite: 2026-01-06]
        tts.tts_to_file(
            text=chunk, 
            speaker_wav=voice_sample, 
            language="hi", 
            file_path=name,
            speed=1.0,           # рдЯрд░реНрдмреЛ рд╕реНрдкреАрдб
            temperature=0.7,     # рдиреЗрдЪреБрд░рд▓ рдЖрд╡рд╛реЫ рдХреЗ рд▓рд┐рдП
            repetition_penalty=5.0, # рд╣рдХрд▓рд╛рдирд╛ (Stuttering) рд░реЛрдХрдиреЗ рдХреЗ рд▓рд┐рдП рд╕рдмрд╕реЗ реЫрд░реВрд░реА
            top_p=0.8,           # рд╢рдмреНрджреЛрдВ рдХреА рд╕реНрдкрд╖реНрдЯрддрд╛ рдХреЗ рд▓рд┐рдП
            enable_text_splitting=False
        )
        chunk_files.append(name)
    
    # рд╕рднреА рдЯреБрдХрдбрд╝реЛрдВ рдХреЛ рдЬреЛрдбрд╝рдирд╛
    final_output = combine_chunks(chunk_files)
    
    # рдСрдбрд┐рдпреЛ рд╕реБрдирд╛рдИ рджреЗрдиреЗ рдХреЗ рд▓рд┐рдП рдлреБрд▓ рдкрд╛рде рднреЗрдЬрдирд╛
    return os.path.abspath(final_output)

# ЁЯОи рдЖрдкрдХрд╛ рдУрд░рд┐рдЬрд┐рдирд▓ рдЗрдВрдЯрд░рдлрд╝реЗрд╕
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange"), title="рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА AI") as demo:
    gr.Markdown("# ЁЯОЩя╕П рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА - рд╣рдХрд▓рд╛рд╣рдЯ рдореБрдХреНрдд рдЗрдВрдЬрди v2")
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдкреЗрд╕реНрдЯ рдХрд░реЗрдВ", lines=12)
        with gr.Column(scale=1):
            # 'type=filepath' рдСрдбрд┐рдпреЛ рд╕реИрдВрдкрд▓ рдХреЛ рд╕рд╣реА рд╕реЗ рд▓реЛрдб рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП
            ref = gr.Audio(label="рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ", type="filepath", interactive=True)
            btn = gr.Button("ЁЯЪА рд╕рд╛реЮ рдЖрд╡рд╛реЫ рдЬрдирд░реЗрдЯ рдХрд░реЗрдВ", variant="primary")
            
    with gr.Row():
        # 'autoplay' рддрд╛рдХрд┐ рдЬрдирд░реЗрдЯ рд╣реЛрддреЗ рд╣реА рдмрдЬрдиреЗ рд▓рдЧреЗ
        out = gr.Audio(label="рдлрд╛рдЗрдирд▓ рдХреНрд▓реЛрди рдХреА рдЧрдИ рдЖрд╡рд╛рдЬрд╝", type="filepath", autoplay=True)

    btn.click(generate_voice, [txt, ref], out)

if __name__ == "__main__":
    demo.launch(share=True, allowed_paths=[os.getcwd()])
