import os
import torch
import gradio as gr
import shutil
from TTS.api import TTS
from huggingface_hub import hf_hub_download, snapshot_download
from app_config import MODEL_CONFIG
from text_engine import split_into_chunks
from parallel_processor import combine_chunks

# тЪб рдЯрд░реНрдмреЛ рдФрд░ рд╣рдЧрд┐рдВрдЧ рдлреЗрд╕ рдкрд╛рде рд╕реЗрдЯрдЕрдк [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ЁЯУе рдЖрдкрдХрд╛ рдХрд╕реНрдЯрдо рдореЙрдбрд▓ рдбрд╛рдЙрдирд▓реЛрдб рдЗрдВрдЬрди (1000% рдореИрдЪ рдХреЗ рд▓рд┐рдП) [cite: 2026-01-03]
print(f"тП│ рдЖрдкрдХреЗ рд╣рдЧрд┐рдВрдЧ рдлреЗрд╕ рдореЙрдбрд▓ рдХреЛ рд▓реЛрдб рдХрд┐рдпрд╛ рдЬрд╛ рд░рд╣рд╛ рд╣реИ...")
try:
    # рдпрд╣ рдЖрдкрдХреЗ MODEL_CONFIG рд╕реЗ repo_id рд▓реЗрдХрд░ рдкреВрд░рд╛ рдлреЛрд▓реНрдбрд░ рдбрд╛рдЙрдирд▓реЛрдб рдХрд░реЗрдЧрд╛
    model_path = snapshot_download(repo_id=MODEL_CONFIG["repo_id"])
    # рдЖрдкрдХреЗ рдЦреБрдж рдХреЗ рдореЙрдбрд▓ рдХреЛ рд▓реЛрдб рдХрд░рдирд╛
    tts = TTS(model_path=model_path, config_path=os.path.join(model_path, "config.json")).to(device)
    print("тЬЕ рдЖрдкрдХрд╛ рдХрд╕реНрдЯрдо рдореЙрдбрд▓ рд╕рдлрд▓рддрд╛рдкреВрд░реНрд╡рдХ рд▓реЛрдб рд╣реЛ рдЧрдпрд╛!")
except Exception as e:
    print(f"тЭМ рдореЙрдбрд▓ рд▓реЛрдб рдПрд░рд░: {e}. рдбрд┐рдлрд╝реЙрд▓реНрдЯ XTTS рд▓реЛрдб рд╣реЛ рд░рд╣рд╛ рд╣реИ...")
    tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

def generate_voice(text, voice_sample, speed, pitch, emotion_scale, progress=gr.Progress()):
    if not text or not voice_sample:
        raise gr.Error("рдХреГрдкрдпрд╛ рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдФрд░ рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓ рджреЛрдиреЛрдВ рдкреНрд░рджрд╛рди рдХрд░реЗрдВред") 
    
    output_folder = "outputs"
    if os.path.exists(output_folder): shutil.rmtree(output_folder)
    os.makedirs(output_folder, exist_ok=True)
    
    chunks = split_into_chunks(text) 
    chunk_files = []
    
    for i, chunk in enumerate(chunks):
        progress((i+1)/len(chunks), desc=f"ЁЯЪА {MODEL_CONFIG['repo_id']} рд╕реЗ рдХреНрд▓реЛрдирд┐рдВрдЧ: {i+1}/{len(chunks)}") 
        name = os.path.join(output_folder, f"chunk_{i}.wav")
        
        # ЁЯОЩя╕П 1000% рдореИрдЪ рд╕реЗрдЯрд┐рдВрдЧреНрд╕ (рдЖрдкрдХреЗ рдореЙрдбрд▓ рдХреЗ рд▓рд┐рдП рд▓реЙрдХ) [cite: 2026-01-06]
        tts.tts_to_file(
            text=chunk, 
            speaker_wav=voice_sample, 
            language="hi", 
            file_path=name,
            speed=speed,               
            repetition_penalty=15.0,   
            temperature=0.65,          # Purity рдХреЗ рд▓рд┐рдП рдХрдо рд░рдЦрд╛ рдЧрдпрд╛ рд╣реИ
            top_p=0.80,                
            top_k=25,                  
            enable_text_splitting=False 
        )
        chunk_files.append(name)
    
    final_output = os.path.abspath("shriram_final_pro.wav")
    combine_chunks(chunk_files, output_file=final_output)
    return final_output

# ЁЯОи UI рд▓реЗрдЖрдЙрдЯ (рдЬреИрд╕рд╛ рдЖрдкрдХреЛ рдкрд╕рдВрдж рд╣реИ)
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange"), title="рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА AI") as demo:
    gr.Markdown(f"# ЁЯОЩя╕П рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА - рдХрд╕реНрдЯрдо рдореЙрдбрд▓: {MODEL_CONFIG['repo_id']}")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ", lines=12)
        with gr.Column(scale=1):
            ref = gr.Audio(label="рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓", type="filepath", interactive=True)
            speed_slider = gr.Slider(label="рд╕реНрдкреАрдб", minimum=0.5, maximum=1.5, value=1.0, step=0.1)
            pitch_slider = gr.Slider(label="Deep Match", minimum=0.5, maximum=1.0, value=0.80, step=0.05)
            emotion_slider = gr.Slider(label="рд╕рд╛рдБрд╕/рдЗрдореЛрд╢рди", minimum=0.1, maximum=1.0, value=0.5, step=0.1)
            btn = gr.Button("ЁЯЪА рдЖрдкрдХреЗ рдореЙрдбрд▓ рд╕реЗ рдЬрдирд░реЗрдЯ рдХрд░реЗрдВ", variant="primary")
            
    with gr.Row():
        out = gr.Audio(label="рдлрд╛рдЗрдирд▓ рдЖрдЙрдЯрдкреБрдЯ", type="filepath", autoplay=True)

    btn.click(generate_voice, [txt, ref, speed_slider, pitch_slider, emotion_slider], out)

if __name__ == "__main__":
    demo.launch(share=True, allowed_paths=[os.getcwd(), "/content/"])
