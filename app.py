import os
import torch
import gradio as gr
import shutil
from TTS.api import TTS
from pydub import AudioSegment, AudioEffectsChain

# ЁЯЪй рдЖрдкрдХреЗ рдкреБрд░рд╛рдиреЗ рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдХреА рдлрд╛рдЗрд▓реЗрдВ (рдЗрдирдХреЗ рд╕рд╛рде рдХреЛрдИ рдЫреЗреЬрдЫрд╛реЬ рдирд╣реАрдВ)
try:
    from text_engine import split_into_chunks
    from parallel_processor import combine_chunks
except ImportError:
    print("тЪая╕П рд╕рд╣рд╛рдпрдХ рдлрд╛рдЗрд▓реЗрдВ рд▓реЛрдб рд╣реЛ рд░рд╣реА рд╣реИрдВ...")

# тЪб рдЯрд░реНрдмреЛ рдЗрдВрдЬрди рд╕реЗрдЯрдЕрдк [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

def apply_pro_effects(file_path, bass_boost, echo_level, amp_level):
    """рдкреБрд░рд╛рдиреЗ рдСрдбрд┐рдпреЛ рдореЗрдВ рднрд╛рд░реАрдкрди рдФрд░ рдЧреВрдБрдЬ рдЬреЛреЬрдирд╛"""
    sound = AudioSegment.from_wav(file_path)
    sound = sound + amp_level # рдПрдордкреНрд▓реАрдлрд╛рдпрд░
    
    # рднрд╛рд░реА рдмреЗрд╕ рдФрд░ рдордВрджрд┐рд░ рдЬреИрд╕реА рдЧреВрдБрдЬ рдХреЗ рд▓рд┐рдП рдЗрдлреЗрдХреНрдЯреНрд╕
    effects = AudioEffectsChain().bass(gain=bass_boost).reverb(reverberance=echo_level)
    processed_sound = effects(sound)
    
    final_path = "shriram_final_pro_v2.wav"
    processed_sound.export(final_path, format="wav")
    return final_path

def generate_voice(text, voice_sample, speed, pitch, emotion, bass, echo, amp, progress=gr.Progress()):
    if not text or not voice_sample:
        raise gr.Error("рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдФрд░ рд╕реИрдВрдкрд▓ реЫрд░реВрд░реА рд╣реИрдВред") 

    # ЁЯЪА рдЖрдкрдХрд╛ рдкреБрд░рд╛рдирд╛ 'рдЪрдВрдХ' рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рд▓реЙрдЬрд┐рдХ (рд╕реБрд░рдХреНрд╖рд┐рдд рд╣реИ)
    output_folder = "outputs"
    if os.path.exists(output_folder): shutil.rmtree(output_folder)
    os.makedirs(output_folder, exist_ok=True)

    chunks = split_into_chunks(text) 
    chunk_files = []

    for i, chunk in enumerate(chunks):
        progress((i+1)/len(chunks), desc=f"ЁЯЪА рдЯрд░реНрдмреЛ рдХреНрд▓реЛрдирд┐рдВрдЧ: {i+1}/{len(chunks)}") 
        name = os.path.join(output_folder, f"chunk_{i}.wav")

        # ЁЯОЩя╕П рдЖрдкрдХрд╛ рдкреБрд░рд╛рдирд╛ рдЗрдВрдЬрди рд╕реЗрдЯрд┐рдВрдЧреНрд╕ + рдирдпрд╛ рдЗрдореЛрд╢рди рдХрдВрдЯреНрд░реЛрд▓
        tts.tts_to_file(
            text=chunk, 
            speaker_wav=voice_sample, 
            language="hi", 
            file_path=name,
            speed=speed,               
            repetition_penalty=12.0,   
            temperature=emotion,       # рдирдпрд╛ рд╣реНрдпреВрдорди рдЯрдЪ рд╕реНрд▓рд╛рдЗрдбрд░
            top_p=0.85,
            gpt_cond_len=3             # 0.9 Deep Match рдХреЗ рд▓рд┐рдП
        )
        chunk_files.append(name)

    # ЁЯФЧ рдкреБрд░рд╛рдирд╛ рдХрдВрдмрд╛рдЗрди рд▓реЙрдЬрд┐рдХ
    combined_temp = "combined_temp.wav"
    combine_chunks(chunk_files, output_file=combined_temp)
    
    # тЬи рдЕрдм рдЗрд╕рдореЗрдВ рднрд╛рд░реАрдкрди рдФрд░ рдЧреВрдБрдЬ рдЬреЛреЬреЗрдВ
    final_output = apply_pro_effects(combined_temp, bass, echo, amp)
    return final_output

# ЁЯОи рдЖрдкрдХрд╛ рд╢рд╛рдирджрд╛рд░ рд░реЙрдпрд▓ UI (рдкреБрд░рд╛рдиреЗ рд╕реНрд▓рд╛рдЗрдбрд░реНрд╕ + рдирдП рд╕реНрд▓рд╛рдЗрдбрд░реНрд╕)
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange"), title="рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА AI") as demo:
    gr.Markdown("# ЁЯОЩя╕П рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА - 100% рдореИрдЪ рдЯрд░реНрдмреЛ рдЗрдВрдЬрди")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдкреЗрд╕реНрдЯ рдХрд░реЗрдВ", lines=12)
        with gr.Column(scale=1):
            ref = gr.Audio(label="рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ", type="filepath")
            
            with gr.Accordion("тЪЩя╕П рдкреБрд░рд╛рдиреЗ рд╡рд░реНрдХрд┐рдВрдЧ рд╕реНрд▓рд╛рдЗрдбрд░реНрд╕", open=True):
                speed_s = gr.Slider(label="рдЖрд╡рд╛реЫ рдХреА рд░реЮреНрддрд╛рд░ (Speed)", minimum=0.5, maximum=1.5, value=1.0)
                pitch_s = gr.Slider(label="Deep Match (рдЧрд╣рд░рд╛рдИ)", minimum=0.5, maximum=1.0, value=0.9)
            
            with gr.Accordion("ЁЯОн рдирдП рд╣реНрдпреВрдорди рдЯрдЪ рдФрд░ рдЧреВрдБрдЬ рдХрдВрдЯреНрд░реЛрд▓", open=True):
                emo_s = gr.Slider(label="рдЗрдореЛрд╢рди (Realistic)", minimum=0.1, maximum=1.0, value=0.8)
                bass_s = gr.Slider(label="рднрд╛рд░реАрдкрди (Deep Bass)", minimum=0, maximum=20, value=5)
                echo_s = gr.Slider(label="рдЧреВрдБрдЬ (Echo/Reverb)", minimum=0, maximum=100, value=20)
                amp_s = gr.Slider(label="рдПрдордкреНрд▓реАрдлрд╛рдпрд░ (Power)", minimum=-10, maximum=10, value=0)
            
            btn = gr.Button("ЁЯЪА рдЯрд░реНрдмреЛ рдЬрдирд░реЗрдЯ рдХрд░реЗрдВ", variant="primary")
            
    with gr.Row():
        out = gr.Audio(label="рдлрд╛рдЗрдирд▓ рдХреНрд▓реЛрди рдХреА рдЧрдИ рдЖрд╡рд╛рдЬрд╝", type="filepath", autoplay=True)

    btn.click(generate_voice, [txt, ref, speed_s, pitch_s, emo_s, bass_s, echo_s, amp_s], out)

if __name__ == "__main__":
    demo.launch(share=True, debug=True)
