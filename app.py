import os
import torch
import gradio as gr
import shutil
import random
import re
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment

# тЪб рдЯрд░реНрдмреЛ рдЗрдВрдЬрди рд╕реЗрдЯрдЕрдк [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ЁЯУе рд╣рдЧрд┐рдВрдЧ рдлреЗрд╕ рдореЙрдбрд▓
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth"
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

def split_into_chunks(text):
    """рдкреБрд░рд╛рдирд╛ рд╡рд░реНрдХрд┐рдВрдЧ рдЪрдВрдХрд┐рдВрдЧ рд▓реЙрдЬрд┐рдХ [cite: 2026-02-16]"""
    sentences = re.split('([ред!?])', text)
    chunks = []
    current_chunk = ""
    for i in range(0, len(sentences)-1, 2):
        sentence = sentences[i] + sentences[i+1]
        if len(current_chunk) + len(sentence) < 250:
            current_chunk += sentence
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk: chunks.append(current_chunk.strip())
    return chunks

def apply_pro_mastering(file_path, weight, amp, pitch_val):
    """100% рд╣реНрдпреВрдорди рд▓рд╛рдЗрдХ рдлрд┐рдирд┐рд╢рд┐рдВрдЧ"""
    sound = AudioSegment.from_wav(file_path)
    sound = sound + amp # рдкрд╛рд╡рд░
    
    # рдкрд┐рдЪ рдПрдбрдЬрд╕реНрдЯрдореЗрдВрдЯ
    new_sample_rate = int(sound.frame_rate * (pitch_val))
    sound = sound._spawn(sound.raw_data, overrides={'frame_rate': new_sample_rate})
    sound = sound.set_frame_rate(44100)
    
    # рднрд╛рд░реАрдкрди рдФрд░ рд╕реНрдореВрдерд┐рдВрдЧ
    if weight > 0:
        sound = sound.low_pass_filter(5000) # рдорд╢реАрдиреА рд╢реЛрд░ рд╣рдЯрд╛рдиреЗ рдХреЗ рд▓рд┐рдП
    
    final_path = "shriram_no_robot_final.wav"
    sound.export(final_path, format="wav")
    return final_path

def generate_voice(text, voice_sample, speed, human_feel, weight, amp, pitch_val, progress=gr.Progress()):
    # ЁЯза рд░реЛрдмреЛрдЯрд┐рдХ рдЯреЛрди рд╣рдЯрд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдЯреЗрдХреНрд╕реНрдЯ рдореЗрдВ рдкреНрд░рд╛рдХреГрддрд┐рдХ рд╡рд┐рд░рд╛рдо рдЬреЛреЬрдирд╛
    text = text.replace("ред", "ред ...") 
    
    chunks = split_into_chunks(text)
    chunk_files = []
    output_folder = "temp_chunks"
    if os.path.exists(output_folder): shutil.rmtree(output_folder)
    os.makedirs(output_folder)

    for i, chunk in enumerate(chunks):
        progress((i+1)/len(chunks), desc=f"ЁЯЪА рдЯрд░реНрдмреЛ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ: {i+1}/{len(chunks)}")
        name = os.path.join(output_folder, f"c_{i}.wav")
        
        # ЁЯОн рд░реИрдВрдбрдо рдкрд┐рдЪ рд╡реЗрд░рд┐рдПрд╢рди (рдЗрдВрд╕рд╛рдиреА рдЙрддрд╛рд░-рдЪрдврд╝рд╛рд╡ рдХреЗ рд▓рд┐рдП)
        dynamic_temp = human_feel + random.uniform(-0.05, 0.05)
        
        tts.tts_to_file(
            text=chunk, speaker_wav=voice_sample, language="hi", file_path=name,
            speed=speed, repetition_penalty=14.0, # 100% рд▓рдЧрд╛рдо
            temperature=dynamic_temp, top_p=0.85, gpt_cond_len=5
        )
        chunk_files.append(name)

    combined = AudioSegment.empty()
    for f in chunk_files: combined += AudioSegment.from_wav(f)
    combined.export("combined.wav", format="wav")
    
    return apply_pro_mastering("combined.wav", weight, amp, pitch_val)

# ЁЯОи рдЕрдкрдбреЗрдЯреЗрдб рд░реЙрдпрд▓ UI
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# ЁЯЪй рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА - 100% рд╣реНрдпреВрдорди 'рдиреЛ-рд░реЛрдмреЛрдЯ' рдЗрдВрдЬрди")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="рдЕрдкрдиреА рдЕрдореГрдд рд╡рд╛рдгреА рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ", lines=12)
        with gr.Column(scale=1):
            ref = gr.Audio(label="рдУрд░рд┐рдЬрд┐рдирд▓ рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓", type="filepath")
            with gr.Accordion("тЪЩя╕П рдорд╛рд╕реНрдЯрд░ рдХрдВрдЯреНрд░реЛрд▓ (100% рд░рд┐рдпрд▓рд┐рд╕реНрдЯрд┐рдХ)", open=True):
                # тЬЕ рд╕реНрдкреАрдб 1 рдкрд░ рд╕реЗрдЯ рдХрд░ рджреА рдЧрдИ рд╣реИ
                speed_s = gr.Slider(label="рдмреЛрд▓рдиреЗ рдХреА рд░рдлрд╝реНрддрд╛рд░ (Time)", minimum=0.8, maximum=1.2, value=1.0)
                pitch_s = gr.Slider(label="рдЖрд╡рд╛рдЬрд╝ рдХреА рдкрд┐рдЪ (Pitch)", minimum=0.8, maximum=1.1, value=0.98)
                human_s = gr.Slider(label="рд╕реНрдкрд░реНрд╢ (Emotions)", minimum=0.5, maximum=1.0, value=0.88)
                weight_s = gr.Slider(label="рдЖрд╡рд╛рдЬрд╝ рдХрд╛ рднрд╛рд░реАрдкрди (Bass)", minimum=0, maximum=10, value=5)
                amp_s = gr.Slider(label="рдПрдордкреНрд▓реАрдлрд╛рдпрд░ (Power)", minimum=-5, maximum=10, value=3)
            
            btn = gr.Button("рдЖрд╡рд╛рдЬрд╝ рдЬрдирд░реЗрдЯ рдХрд░реЗрдВ ЁЯЪА", variant="primary")
            
    out = gr.Audio(label="рдлрд╛рдЗрдирд▓ рдЖрдЙрдЯрдкреБрдЯ", type="filepath", autoplay=True)
    btn.click(generate_voice, [txt, ref, speed_s, human_s, weight_s, amp_s, pitch_s], out)

demo.launch(share=True)
