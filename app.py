import os
import torch
import gradio as gr
import requests
import re
import gc
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment, effects
from googletrans import Translator

# ‚ö° ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§π‡§æ‡§à ‡§∏‡•ç‡§™‡•Ä‡§° [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"
translator = Translator()

# üì• ‡§∂‡§ø‡§µ AI ‡§Æ‡•â‡§°‡§≤ [cite: 2026-02-16]
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth" 
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

# üåê ‡§ó‡§ø‡§ü‡§π‡§¨ ‡§ë‡§ü‡•ã-‡§∏‡•ç‡§ï‡•à‡§® ‡§≤‡§ø‡§Ç‡§ï
GITHUB_API = "https://api.github.com/repos/shriramnag/Aivoicebox/contents/%F0%9F%93%81%20voices"
GITHUB_RAW = "https://raw.githubusercontent.com/shriramnag/Aivoicebox/main/%F0%9F%93%81%20voices/"

def fetch_voices():
    """‡§ó‡§ø‡§ü‡§π‡§¨ ‡§∏‡•á ‡§´‡§æ‡§á‡§≤‡•ã‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•á ‡§Ü‡§™ ‡§∏‡•ç‡§ï‡•à‡§® ‡§ï‡§∞‡§®‡§æ"""
    try:
        r = requests.get(GITHUB_API)
        if r.status_code == 200:
            return [f['name'] for f in r.json() if f['name'].endswith('.wav')]
        return ["üëâüëâü§ó Shri Shri ü§óüëçüôè.wav"]
    except: return ["üëâüëâü§ó Shri Shri ü§óüëçüôè.wav"]

def apply_cleaner(audio):
    """‡§Ü‡§µ‡§æ‡•õ ‡§ï‡•ã ‡§∏‡§æ‡•û ‡§î‡§∞ ‡§è‡§®‡§π‡§æ‡§Ç‡§∏ ‡§ï‡§∞‡§®‡§æ (Voice Enhancer)"""
    audio = effects.normalize(audio)
    return audio.low_pass_filter(10000).high_pass_filter(80)

def generate_shiv_all_tools(text, up_ref, git_ref, speed, pitch, use_clean, use_trans, use_silence, progress=gr.Progress()):
    # ‡•ß. ‡§ë‡§ü‡•ã-‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§≤‡•á‡§∂‡§® (English to Hindi) [cite: 2025-11-23]
    if use_trans:
        try:
            detected = translator.detect(text)
            if detected.lang == 'en':
                text = translator.translate(text, dest='hi').text
        except: pass

    # ‡•®. ‡§®‡§Ç‡§¨‡§∞-‡§ü‡•Ç-‡§µ‡§∞‡•ç‡§°‡•ç‡§∏ (LOCKED) [cite: 2026-02-20]
    num_map = {'0':'‡§∂‡•Ç‡§®‡•ç‡§Ø','1':'‡§è‡§ï','2':'‡§¶‡•ã','3':'‡§§‡•Ä‡§®','4':'‡§ö‡§æ‡§∞','5':'‡§™‡§æ‡§Å‡§ö','6':'‡§õ‡§π','7':'‡§∏‡§æ‡§§','8':'‡§Ü‡§†','9':'‡§®‡•å'}
    for n, w in num_map.items(): text = text.replace(n, w)

    # ‡•©. ‡§µ‡•â‡§Ø‡§∏ ‡§∏‡§ø‡§≤‡•á‡§ï‡•ç‡§∂‡§®
    ref_path = up_ref if up_ref else "temp_v.wav"
    if not up_ref:
        r = requests.get(GITHUB_RAW + requests.utils.quote(git_ref))
        with open(ref_path, "wb") as f: f.write(r.content)

    # ‡•™. ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§ö‡§Ç‡§ï‡§ø‡§Ç‡§ó & ‡§ú‡§®‡§∞‡•á‡§∂‡§®
    chunks = [s.strip() for s in re.split('([‡•§!?‡••\n])', text) if len(s.strip()) > 1]
    combined = AudioSegment.empty()
    
    for i, chunk in enumerate(chunks):
        progress((i+1)/len(chunks), desc=f"üöÄ ‡§∂‡§ø‡§µ AI: ‡§≠‡§æ‡§ó {i+1}")
        name = f"c_{i}.wav"
        tts.tts_to_file(text=chunk, speaker_wav=ref_path, language="hi", file_path=name, 
                        speed=speed, repetition_penalty=10.0, temperature=0.65)
        
        c_aud = AudioSegment.from_wav(name)
        if use_silence: c_aud = effects.strip_silence(c_aud, silence_thresh=-40, padding=100)
        combined += c_aud
        if i % 5 == 0: torch.cuda.empty_cache(); gc.collect()

    # ‡•´. ‡§µ‡•â‡§Ø‡§∏ ‡§ï‡•ç‡§≤‡•Ä‡§®‡§∞ (Enhancer)
    if use_clean: combined = apply_cleaner(combined)

    # ‚úÖ ‡§´‡§æ‡§á‡§®‡§≤ ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§®‡§æ‡§Æ [cite: 2026-02-21]
    final_name = "Shri Ram Nag.wav"
    combined.export(final_name, format="wav")
    return final_name

# üé® ‡§¶‡§ø‡§µ‡•ç‡§Ø UI ‡§°‡§ø‡§ú‡§æ‡§á‡§®
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# üö© ‡§∂‡§ø‡§µ AI (Shiv AI) - ‡§ë‡§≤-‡§á‡§®-‡§µ‡§® ‡§ü‡•Ç‡§≤‡•ç‡§∏ ‡§è‡§°‡§ø‡§∂‡§®")
    
    with gr.Row():
        with gr.Column(scale=2):
            script = gr.Textbox(label="‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂ ‡§Ø‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§Ø‡§π‡§æ‡§Å ‡§≤‡§ø‡§ñ‡•á‡§Ç", lines=12)
            word_count = gr.Markdown("‡§∂‡§¨‡•ç‡§¶ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ: ‡§∂‡•Ç‡§®‡•ç‡§Ø") # [cite: 2026-02-18]
            script.change(lambda x: f"‡§∂‡§¨‡•ç‡§¶ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ: {len(x.split()) if x else '‡§∂‡•Ç‡§®‡•ç‡§Ø'}", inputs=[script], outputs=[word_count])
            
        with gr.Column(scale=1):
            v_drop = gr.Dropdown(choices=fetch_voices(), label="‡§ó‡§ø‡§ü‡§π‡§¨ ‡§ë‡§ü‡•ã-‡§∏‡•ç‡§ï‡•à‡§® ‡§µ‡•â‡§Ø‡§∏ üîΩ")
            v_up = gr.Audio(label="‡§Ø‡§æ ‡§Ö‡§™‡§®‡§æ ‡§µ‡•â‡§Ø‡§∏ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç", type="filepath")
            
            with gr.Accordion("üõ†Ô∏è ‡§è‡§ï‡•ç‡§∏‡•ç‡§ü‡•ç‡§∞‡§æ ‡§ü‡•Ç‡§≤‡•ç‡§∏ (LOCKED)", open=True):
                clean_sw = gr.Checkbox(label="AI ‡§µ‡•â‡§Ø‡§∏ ‡§ï‡•ç‡§≤‡•Ä‡§®‡§∞ (‡§∏‡§æ‡•û ‡§Ü‡§µ‡§æ‡•õ)", value=True)
                trans_sw = gr.Checkbox(label="‡§ë‡§ü‡•ã ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ (English to Hindi)", value=True)
                silence_sw = gr.Checkbox(label="‡§∏‡§æ‡§á‡§≤‡•á‡§Ç‡§∏ ‡§∞‡§ø‡§Æ‡•Ç‡§µ‡§∞", value=True)
            
            with gr.Accordion("‚öôÔ∏è ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏", open=False):
                sp = gr.Slider(label="‡§∞‡•û‡•ç‡§§‡§æ‡§∞", minimum=0.8, maximum=1.4, value=1.0)
                pt = gr.Slider(label="‡§™‡§ø‡§ö", minimum=0.8, maximum=1.1, value=0.96)
            
            btn = gr.Button("‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•á‡§Ç üöÄ", variant="primary")
            
    out = gr.Audio(label="‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§°: Shri Ram Nag.wav", type="filepath", autoplay=True)
    btn.click(generate_shiv_all_tools, [script, v_up, v_drop, sp, pt, clean_sw, trans_sw, silence_sw], out)

demo.launch(share=True)

