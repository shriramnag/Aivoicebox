import os, torch, gradio as gr, requests, re, gc
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment, effects

# ‡•ß. ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§π‡§æ‡§à ‡§∏‡•ç‡§™‡•Ä‡§° ‡§∏‡•á‡§ü‡§Ö‡§™ (LOCKED) [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ‡•®. ‡§Æ‡§æ‡§∏‡•ç‡§ü‡§∞ ‡§Æ‡•â‡§°‡§≤ - ‡§∂‡§ø‡§µ ‡§è‡§Ü‡§à (Shiv AI) [cite: 2026-02-16, 2026-02-20]
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth" 
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

G_RAW = "https://raw.githubusercontent.com/shriramnag/Aivoicebox/main/%F0%9F%93%81%20voices/"

def boost_realistic_audio(audio):
    """‡§Ü‡§µ‡§æ‡•õ ‡§ï‡•Ä ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü‡§§‡§æ ‡§î‡§∞ ‡§¨‡•á‡§∏ (LOCKED) [cite: 2026-02-22]"""
    resampled = audio.set_frame_rate(44100)
    return effects.normalize(resampled)

def generate_shiv_precise_progress(text, up_ref, git_ref, speed_s, pitch_s, use_silence, use_clean, progress=gr.Progress()):
    # ‡•©. ‡§®‡§Ç‡§¨‡§∞-‡§ü‡•Ç-‡§µ‡§∞‡•ç‡§°‡•ç‡§∏ ‡§´‡§ø‡§ï‡•ç‡§∏ [cite: 2026-02-20]
    num_map = {'0':'‡§∂‡•Ç‡§®‡•ç‡§Ø','1':'‡§è‡§ï','2':'‡§¶‡•ã','3':'‡§§‡•Ä‡§®','4':'‡§ö‡§æ‡§∞','5':'‡§™‡§æ‡§Å‡§ö','6':'‡§õ‡§π','7':'‡§∏‡§æ‡§§','8':'‡§Ü‡§†','9':'‡§®‡•å'}
    for n, w in num_map.items(): text = text.replace(n, w)

    ref = up_ref if up_ref else "ref.wav"
    if not up_ref:
        url = G_RAW + requests.utils.quote(git_ref)
        with open(ref, "wb") as f: f.write(requests.get(url).content)

    # ‚ö° ‡•™. ‡§π‡§æ‡§á‡§™‡§∞-‡§ü‡§∞‡•ç‡§¨‡•ã ‡§™‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡•á‡§∏ ‡§ü‡•ç‡§∞‡•à‡§ï‡§ø‡§Ç‡§ó (LOCKED) [cite: 2026-02-23]
    # ‡§™‡§π‡§≤‡•á ‡§™‡•Ç‡§∞‡•Ä ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§ï‡•ã ‡§µ‡§æ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§Ç‡§ü‡§§‡•á ‡§π‡•à‡§Ç ‡§§‡§æ‡§ï‡§ø ‡§ó‡§ø‡§®‡§§‡•Ä ‡§∏‡§π‡•Ä ‡§π‡•ã
    raw_parts = re.split(r'(\[pause\]|\[breath\]|\[laugh\])', text)
    all_tasks = []
    for p in raw_parts:
        if p.strip() in ["[pause]", "[breath]", "[laugh]"]:
            all_tasks.append(p.strip())
        elif p.strip():
            sentences = re.split('([‡•§!?‡••\n])', p)
            all_tasks.extend([s.strip() for s in sentences if len(s.strip()) > 1])
    
    combined = AudioSegment.empty()
    total = len(all_tasks)
    
    for i, task in enumerate(all_tasks):
        # ‡§Ø‡§π‡§æ‡§Å ‡§™‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡•á‡§∏ ‡§¨‡§æ‡§∞ ‡§π‡§∞ ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§™‡§∞ ‡§Ö‡§™‡§°‡•á‡§ü ‡§π‡•ã‡§ó‡§æ (1/10, 2/10...) [cite: 2026-02-23]
        progress((i+1)/total, desc=f"‚ö° ‡§ï‡•ç‡§≤‡•ã‡§®‡§ø‡§Ç‡§ó ‡§ú‡§æ‡§∞‡•Ä: {i+1} / {total} ‡§µ‡§æ‡§ï‡•ç‡§Ø")
        
        if task == "[pause]": combined += AudioSegment.silent(duration=850)
        elif task == "[breath]": combined += AudioSegment.silent(duration=350)
        elif task == "[laugh]": combined += AudioSegment.silent(duration=150)
        else:
            name = f"chunk_{i}.wav"
            # ‡§∂‡•Å‡§¶‡•ç‡§ß ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§î‡§∞ ‡§®‡•ã-‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏ [cite: 2026-02-23]
            tts.tts_to_file(text=task, speaker_wav=ref, language="hi", file_path=name, 
                            speed=speed_s, repetition_penalty=19.0, temperature=0.25,
                            top_k=20, top_p=0.8)
            
            seg = AudioSegment.from_wav(name)
            if use_silence:
                try: seg = effects.strip_silence(seg, silence_thresh=-45, padding=120)
                except: pass
            combined += seg
            os.remove(name) # ‡§ï‡§ö‡§∞‡§æ ‡§∏‡§æ‡•û ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡§æ‡§ï‡§ø ‡§∏‡•ç‡§™‡•Ä‡§° ‡§¨‡§®‡•Ä ‡§∞‡§π‡•á [cite: 2026-01-06]
        
        if i % 3 == 0: torch.cuda.empty_cache(); gc.collect()

    if use_clean: combined = boost_realistic_audio(combined)
    
    final_path = "Shri Ram Nag.wav"
    combined.export(final_path, format="wav")
    return final_path

# üé® ‡§¶‡§ø‡§µ‡•ç‡§Ø UI - ‡§Æ‡§æ‡§∏‡•ç‡§ü‡§∞ ‡§≤‡•â‡§ï [cite: 2026-02-22, 2026-02-23]
js_code = "function insertTag(tag) { var t=document.querySelector('#script_box textarea'); var s=t.selectionStart; t.value=t.value.substring(0,s)+' '+tag+' '+t.value.substring(t.selectionEnd); t.focus(); return t.value; }"

with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange"), js=js_code) as demo:
    gr.Markdown("# üö© ‡§∂‡§ø‡§µ ‡§è‡§Ü‡§à (Shiv AI) - '‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó' ‡§™‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡•á‡§∏ ‡§Æ‡§æ‡§∏‡•ç‡§ü‡§∞ ‡§≤‡•â‡§ï")
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="‡§Ö‡§™‡§®‡•Ä ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§Ø‡§π‡§æ‡§Å ‡§≤‡§ø‡§ñ‡•á‡§Ç", lines=12, elem_id="script_box")
            word_counter = gr.Markdown("‡§∂‡§¨‡•ç‡§¶ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ: ‡§∂‡•Ç‡§®‡•ç‡§Ø")
            txt.change(lambda x: f"‡§∂‡§¨‡•ç‡§¶ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ: {len(x.split()) if x else '‡§∂‡•Ç‡§®‡•ç‡§Ø'}", [txt], [word_counter])
            
            with gr.Row():
                gr.Button("‚è∏Ô∏è ‡§∞‡•ã‡§ï‡•á").click(None, None, txt, js="() => insertTag('[pause]')")
                gr.Button("üí® ‡§∏‡§æ‡§Ç‡§∏").click(None, None, txt, js="() => insertTag('[breath]')")
                gr.Button("üòä ‡§π‡§Å‡§∏‡•ã").click(None, None, txt, js="() => insertTag('[laugh]')")
            
        with gr.Column(scale=1):
            git_voice = gr.Dropdown(choices=["aideva.wav", "Joanne.wav"], label="‡§ö‡§Ø‡§®", value="aideva.wav")
            manual = gr.Audio(label="‡§µ‡§ø‡§µ‡§∞‡§£ ‡§Ö‡§™‡§≤‡•ã‡§°", type="filepath")
            with gr.Accordion("‚öôÔ∏è ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏ (LOCKED)", open=True):
                spd = gr.Slider(0.8, 1.4, 1.0, label="‡§∞‡•û‡•ç‡§§‡§æ‡§∞")
                ptc = gr.Slider(0.8, 1.1, 0.96, label="‡§™‡§ø‡§ö")
                cln = gr.Checkbox(label="‡§è‡§Ü‡§à ‡§¨‡•á‡§∏ ‡§∏‡§´‡§æ‡§à ‡§î‡§∞", value=True)
                sln = gr.Checkbox(label="‡§∏‡§æ‡§á‡§≤‡•á‡§Ç‡§∏ ‡§â‡§¶‡•ç‡§ß‡§∞‡§£", value=True)
            btn = gr.Button("‡•ß‡•¶‡•¶‡•¶% ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ú‡§®‡§∞‡•á‡§∂‡§® üöÄ", variant="primary")
            
    out = gr.Audio(label="Shri Ram Nag.wav", type="filepath", autoplay=True)
    btn.click(generate_shiv_precise_progress, [txt, manual, git_voice, spd, ptc, sln, cln], out)

demo.launch(share=True)
