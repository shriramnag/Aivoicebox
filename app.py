import os
import torch
import gradio as gr
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from app_config import MODEL_CONFIG
from text_engine import split_into_chunks
from parallel_processor import combine_chunks

# тЪб рдЯрд░реНрдмреЛ рд╕реЗрдЯрдЕрдк рдФрд░ GPU рдЪреЗрдХрд┐рдВрдЧ [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ЁЯУе рдореЙрдбрд▓ рд▓реЛрдб (v2 - 1000 Epochs)
print(f"тП│ рдореЙрдбрд▓ рд▓реЛрдб рд╣реЛ рд░рд╣рд╛ рд╣реИ {device} рдкрд░...")
model_path = hf_hub_download(repo_id=MODEL_CONFIG["repo_id"], filename=MODEL_CONFIG["model_file"])
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

def generate_voice(text, voice_sample, progress=gr.Progress()):
    if not text or not voice_sample:
        raise gr.Error("рдХреГрдкрдпрд╛ рдЯреЗрдХреНрд╕реНрдЯ рдФрд░ рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓ рджреЛрдиреЛрдВ рдкреНрд░рджрд╛рди рдХрд░реЗрдВред") [cite: 2026-01-06]
    
    # 10K рдХреИрд░реЗрдХреНрдЯрд░ рдХреЛ рдЯреБрдХрдбрд╝реЛрдВ рдореЗрдВ рдмрд╛рдВрдЯрдирд╛ [cite: 2026-01-06]
    chunks = split_into_chunks(text) 
    chunk_files = []
    
    for i, chunk in enumerate(chunks):
        # рдкреНрд░реЛрдЧреНрд░реЗрд╕ рдмрд╛рд░ рдЕрдкрдбреЗрдЯ рдХрд░рдирд╛
        progress(i/len(chunks), desc=f"рд╡рд╛рдХреНрдп {i+1} рдЬрдирд░реЗрдЯ рд╣реЛ рд░рд╣рд╛ рд╣реИ...") 
        name = f"chunk_{i}.wav"
        
        # рд╡реЙрдЗрд╕ рдХреНрд▓реЛрдирд┐рдВрдЧ рдкреНрд░реЛрд╕реЗрд╕ [cite: 2025-11-23]
        tts.tts_to_file(
            text=chunk, 
            speaker_wav=voice_sample, 
            language="hi", 
            file_path=name,
            split_sentences=True # рд╣рдХрд▓рд╛рдирд╛ рдХрдо рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП [cite: 2026-01-06]
        )
        chunk_files.append(name)
    
    # рд╕рднреА рдЯреБрдХрдбрд╝реЛрдВ рдХреЛ рдЬреЛрдбрд╝рдирд╛ рдФрд░ рд╕рдлрд╛рдИ рдХрд░рдирд╛ [cite: 2026-01-06]
    return combine_chunks(chunk_files)

# ЁЯОи рдкреНрд░реЛрдлреЗрд╢рдирд▓ UI рдереАрдо рд╕реЗрдЯрдЕрдк
custom_theme = gr.themes.Soft(
    primary_hue="orange",
    secondary_hue="gray",
    neutral_hue="slate",
).set(
    button_primary_background_fill="*primary_600",
    block_title_text_weight="700"
)

with gr.Blocks(theme=custom_theme, title="рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА AI") as demo:
    gr.Markdown("## ЁЯОЩя╕П рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА - рдкреНрд░реЛрдлреЗрд╢рдирд▓ AI рдЗрдВрдЬрди v2")
    gr.Markdown("---")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(
                label="рд▓рдВрдмреА рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдкреЗрд╕реНрдЯ рдХрд░реЗрдВ (10,000 рдХреИрд░реЗрдХреНрдЯрд░ рддрдХ)", 
                lines=15, 
                placeholder="рдпрд╣рд╛рдБ рдЕрдкрдиреА рд╣рд┐рдВрджреА рд╕реНрдХреНрд░рд┐рдкреНрдЯ рд▓рд┐рдЦреЗрдВ рдпрд╛ рдкреЗрд╕реНрдЯ рдХрд░реЗрдВ..."
            )
        with gr.Column(scale=1):
            ref = gr.Audio(label="рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ (.wav)", type="filepath")
            btn = gr.Button("ЁЯЪА рдЯрд░реНрдмреЛ рдЬрдирд░реЗрд╢рди рд╢реБрд░реВ рдХрд░реЗрдВ", variant="primary")
            gr.Markdown("> **рдиреЛрдЯ:** рдмрдбрд╝реА рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдореЗрдВ рдереЛрдбрд╝рд╛ рд╕рдордп рд▓рдЧ рд╕рдХрддрд╛ рд╣реИ, рдХреГрдкрдпрд╛ рдкреНрд░реЛрдЧреНрд░реЗрд╕ рдмрд╛рд░ рджреЗрдЦреЗрдВред [cite: 2026-01-06]")
            
    with gr.Row():
        out = gr.Audio(label="рдлрд╛рдЗрдирд▓ рдХреНрд▓реЛрди рдХреА рдЧрдИ рдЖрд╡рд╛рдЬрд╝", interactive=False)

    # рдмрдЯрди рдХреНрд▓рд┐рдХ рдЗрд╡реЗрдВрдЯ
    btn.click(generate_voice, [txt, ref], out)

# рдРрдк рд▓реЙрдиреНрдЪ рдХрд░рдирд╛
if __name__ == "__main__":
    demo.launch(share=True, show_error=True)
