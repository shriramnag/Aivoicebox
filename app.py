import os, torch, gradio as gr, requests, re, gc
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment, effects

# рез. рдЯрд░реНрдмреЛ рд╣рд╛рдИ рд╕реНрдкреАрдб рд╕реЗрдЯрдЕрдк (LOCKED)
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# реи. рдорд╛рд╕реНрдЯрд░ рдореЙрдбрд▓ - рд╢рд┐рд╡ AI (Shiv AI)
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth" 
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

G_RAW = "https://raw.githubusercontent.com/shriramnag/Aivoicebox/main/%F0%9F%93%81%20voices/"

def boost_realistic_audio(audio):
    """рдЖрд╡рд╛реЫ рдХреА рд╕реНрдкрд╖реНрдЯрддрд╛ рдФрд░ рдмреЗрд╕ (LOCKED)"""
    resampled = audio.set_frame_rate(44100)
    return effects.normalize(resampled)

def detect_lang_and_fix_numbers(text):
    """ЁЯдЦ рд╢рд┐рд╡ AI рдХрд╛ рд╕реНрдорд╛рд░реНрдЯ рд▓реИрдВрдЧреНрд╡реЗрдЬ рдФрд░ рдирдВрдмрд░ рдбрд┐рдЯреЗрдХреНрдЯрд░"""
    eng_chars = len(re.findall(r'[a-zA-Z]', text))
    hi_chars = len(re.findall(r'[\u0900-\u097F]', text))
    
    lang = "en" if eng_chars > hi_chars else "hi"
    
    # рдирдВрдмрд░реЛрдВ рдХреЛ рд╢рдмреНрджреЛрдВ рдореЗрдВ рдмрджрд▓рдирд╛ рддрд╛рдХрд┐ рд╣рдХрд▓рд╛рд╣рдЯ рди рд╣реЛ
    if lang == "hi":
        num_map = {'0':'рд╢реВрдиреНрдп','1':'рдПрдХ','2':'рджреЛ','3':'рддреАрди','4':'рдЪрд╛рд░','5':'рдкрд╛рдБрдЪ','6':'рдЫрд╣','7':'рд╕рд╛рдд','8':'рдЖрда','9':'рдиреМ'}
        for n, w in num_map.items(): text = text.replace(n, w)
    else:
        en_map = {'0':'zero','1':'one','2':'two','3':'three','4':'four','5':'five','6':'six','7':'seven','8':'eight','9':'nine'}
        for n, w in en_map.items(): text = text.replace(n, w)
        
    return text, lang

def generate_shiv_bilingual_ultra_locked(text, up_ref, git_ref, speed_s, pitch_s, use_silence, use_clean, progress=gr.Progress()):
    ref = up_ref if up_ref else "ref.wav"
    if not up_ref:
        url = G_RAW + requests.utils.quote(git_ref)
        with open(ref, "wb") as f: f.write(requests.get(url).content)

    # тЪб рей. рджреНрд╡рд┐рднрд╛рд╖реА рдХрдЯрд░ рдФрд░ рдЕрд▓реНрдЯреНрд░рд╛-рд╕реНрдореВрде рдкреНрд░реЛрдЧреНрд░реЗрд╕ рдЯреНрд░реИрдХрд┐рдВрдЧ
    raw_parts = re.split(r'(\[pause\]|\[breath\]|\[laugh\])', text)
    all_tasks = []
    for p in raw_parts:
        if p.strip() in ["[pause]", "[breath]", "[laugh]"]:
            all_tasks.append(p.strip())
        elif p.strip():
            # рд╣рд┐рдВрджреА (ред) рдФрд░ рдЗрдВрдЧреНрд▓рд┐рд╢ (.) рджреЛрдиреЛрдВ рдХреЗ рдлреБрд▓рд╕реНрдЯреЙрдк рдХреЛ рд╕рдордЭреЗрдЧрд╛
            sentences = re.split(r'[ред!?рее\n]+', p)
            all_tasks.extend([s.strip() for s in sentences if len(s.strip()) > 1])
    
    combined = AudioSegment.empty()
    total = len(all_tasks)
    
    for i, task in enumerate(all_tasks):
        progress((i+1)/total, desc=f"тЪб рджреНрд╡рд┐рднрд╛рд╖реА рдЕрд▓реНрдЯреНрд░рд╛-рд╕реНрдореВрде рдХреНрд▓реЛрдирд┐рдВрдЧ: {i+1} / {total}")
        
        if task == "[pause]": combined += AudioSegment.silent(duration=850)
        elif task == "[breath]": combined += AudioSegment.silent(duration=350)
        elif task == "[laugh]": combined += AudioSegment.silent(duration=150)
        else:
            # ЁЯза рд╕реНрдорд╛рд░реНрдЯ рднрд╛рд╖рд╛ рдкрд╣рдЪрд╛рди
            task_clean, detected_lang = detect_lang_and_fix_numbers(task)
            
            name = f"chunk_{i}.wav"
            
            # --- рд╣рдХрд▓рд╛рд╣рдЯ рдкрд░ резрежрежреж% рдлрд╛рдЗрдирд▓ рдкреНрд░рд╣рд╛рд░ (LOCKED) ---
            # Temperature 0.15: рдПрдЖрдИ рдХреЛ рд╕реЛрдЪрдиреЗ рдХреА рдЖреЫрд╛рджреА рдирд╣реАрдВ, рд╕реАрдзрд╛ рдкреЭреЗрдЧрд╛ред
            # Repetition Penalty 20.0: рд╣рдХрд▓рд╛рд╣рдЯ (Stuttering) рдХрд╛ рдирд╛рдореЛрдВ-рдирд┐рд╢рд╛рди рдорд┐рдЯрд╛ рджреЗрдЧрд╛ред
            # Top_k 10: рд╕рдмрд╕реЗ рд╕рдЯреАрдХ рдЙрдЪреНрдЪрд╛рд░рдг рд╡рд╛рд▓реЗ рд╢рдмреНрдж рд╣реА рдЪреБрдиреЗрдЧрд╛ред
            tts.tts_to_file(text=task_clean, speaker_wav=ref, language=detected_lang, file_path=name, 
                            speed=speed_s, repetition_penalty=20.0, temperature=0.15,
                            top_k=10, top_p=0.8)
            
            seg = AudioSegment.from_wav(name)
            if use_silence:
                try: seg = effects.strip_silence(seg, silence_thresh=-45, padding=120)
                except: pass
            combined += seg
            if os.path.exists(name): os.remove(name)
        
        if i % 3 == 0: torch.cuda.empty_cache(); gc.collect()

    if use_clean: combined = boost_realistic_audio(combined)
    
    final_path = "Shri Ram Nag.wav"
    combined.export(final_path, format="wav")
    return final_path

# ЁЯОи рджрд┐рд╡реНрдп UI - рдорд╛рд╕реНрдЯрд░ рд▓реЙрдХ 
js_code = "function insertTag(tag) { var t=document.querySelector('#script_box textarea'); var s=t.selectionStart; t.value=t.value.substring(0,s)+' '+tag+' '+t.value.substring(t.selectionEnd); t.focus(); return t.value; }"

with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange"), js=js_code) as demo:
    gr.Markdown("# ЁЯЪй рд╢рд┐рд╡ AI (Shiv AI) - 'рд╢реНрд░реА рд░рд╛рдо рдирд╛рдЧ' рджреНрд╡рд┐рднрд╛рд╖реА (Bilingual) рдкреНрд░реЛ рд▓реЙрдХ")
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="рдЕрдкрдиреА рд╕реНрдХреНрд░рд┐рдкреНрдЯ (рд╣рд┐рдВрджреА рдпрд╛ English) рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ", lines=12, elem_id="script_box")
            
            word_counter = gr.Markdown("рд╢рдмреНрдж рд╕рдВрдЦреНрдпрд╛: рд╢реВрдиреНрдп")
            txt.change(lambda x: f"рд╢рдмреНрдж рд╕рдВрдЦреНрдпрд╛: {len(x.split()) if x else 'рд╢реВрдиреНрдп'}", [txt], [word_counter])
            
            with gr.Row():
                gr.Button("тП╕я╕П рд░реЛрдХреЗ").click(None, None, txt, js="() => insertTag('[pause]')")
                gr.Button("ЁЯТи рд╕рд╛рдВрд╕").click(None, None, txt, js="() => insertTag('[breath]')")
                gr.Button("ЁЯШК рд╣рдБрд╕реЛ").click(None, None, txt, js="() => insertTag('[laugh]')")
            
        with gr.Column(scale=1):
            git_voice = gr.Dropdown(choices=["aideva.wav", "Joanne.wav"], label="рдЪрдпрди", value="aideva.wav")
            manual = gr.Audio(label="рд╡рд┐рд╡рд░рдг рдЕрдкрд▓реЛрдб", type="filepath")
            with gr.Accordion("тЪЩя╕П рд╕реЗрдЯрд┐рдВрдЧреНрд╕ (LOCKED)", open=True):
                spd = gr.Slider(0.8, 1.4, 1.0, label="рд░реЮреНрддрд╛рд░")
                ptc = gr.Slider(0.8, 1.1, 0.96, label="рдкрд┐рдЪ")
                cln = gr.Checkbox(label="рдПрдЖрдИ рдмреЗрд╕ рдФрд░ рд╕рдлрд╛рдИ", value=True)
                sln = gr.Checkbox(label="рд╕рд╛рдЗрд▓реЗрдВрд╕ рд░рд┐рдореВрд╡рд░", value=True)
            btn = gr.Button("рд╢реБрджреНрдз рджреНрд╡рд┐рднрд╛рд╖реА рдЬрдирд░реЗрд╢рди ЁЯЪА", variant="primary")
            
    out = gr.Audio(label="Shri Ram Nag.wav", type="filepath", autoplay=True)
    btn.click(generate_shiv_bilingual_ultra_locked, [txt, manual, git_voice, spd, ptc, sln, cln], out)

demo.launch(share=True)
