import os, torch, gradio as gr, requests, re, gc, json
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment, effects

# ‡•ß. ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§π‡§æ‡§à ‡§∏‡•ç‡§™‡•Ä‡§° ‡§∏‡•á‡§ü‡§Ö‡§™ (LOCKED) [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ‡•®. ‡§Æ‡§æ‡§∏‡•ç‡§ü‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§î‡§∞ ‡§´‡§æ‡§á‡§≤‡•ã‡§Ç ‡§ï‡§æ ‡§á‡§Ç‡§ü‡•Ä‡§ó‡•ç‡§∞‡•á‡§∂‡§® (Hugging Face ‡§∏‡•á) [cite: 2026-02-26]
# ‡§Ü‡§™‡§ï‡•á ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ä‡§®‡§∂‡•â‡§ü ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§∏‡§π‡•Ä ‡§∞‡§ø‡§™‡•â‡§ú‡§ø‡§ü‡§∞‡•Ä: Shriramnag/My-Shriram-Voice
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth" # ‡§Ü‡§™‡§ï‡§æ ‡§µ‡§∞‡•ç‡§ï‡§ø‡§Ç‡§ó ‡§Æ‡•â‡§°‡§≤ [cite: 2026-02-16]

print("‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó ‡§ú‡•Ä, ‡§π‡§ó‡§ø‡§Ç‡§ó ‡§´‡•á‡§∏ ‡§∏‡•á ‡§´‡§æ‡§á‡§≤‡•ã‡§Ç ‡§ï‡•ã ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§Æ‡•ã‡§° ‡§Æ‡•á‡§Ç ‡§ú‡•ã‡•ú‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à...")
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
# ONNX ‡§î‡§∞ ‡§Ö‡§®‡•ç‡§Ø ‡§´‡§æ‡§á‡§≤‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•à‡§∂ ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡§®‡§æ
hf_hub_download(repo_id=REPO_ID, filename="config.json")
hf_hub_download(repo_id=REPO_ID, filename="tokenizer.json")

tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

G_RAW = "https://raw.githubusercontent.com/shriramnag/Aivoicebox/main/%F0%9F%93%81%20voices/"

# ‡•©. ‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡§∞‡•ã‡§ï‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§æ‡§∏‡•ç‡§ü‡§∞ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ï‡•ç‡§≤‡•Ä‡§®‡§∞ (LOCKED) [cite: 2026-02-20]
def shiv_super_cleaner(text):
    # ‡§®‡§Ç‡§¨‡§∞ ‡§´‡§ø‡§ï‡•ç‡§∏ [2026-02-20]
    num_map = {'0':'‡§∂‡•Ç‡§®‡•ç‡§Ø','1':'‡§è‡§ï','2':'‡§¶‡•ã','3':'‡§§‡•Ä‡§®','4':'‡§ö‡§æ‡§∞','5':'‡§™‡§æ‡§Å‡§ö','6':'‡§õ‡§π','7':'‡§∏‡§æ‡§§','8':'‡§Ü‡§†','9':'‡§®‡•å'}
    for n, w in num_map.items(): text = text.replace(n, w)
    
    # ‡§Æ‡•Å‡§∂‡•ç‡§ï‡§ø‡§≤ ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•ã‡•ú‡§®‡§æ ‡§§‡§æ‡§ï‡§ø AI ‡§® ‡§Ö‡§ü‡§ï‡•á
    brain_fix = {"‡§ú‡§ø‡§Ç‡§¶‡§ó‡•Ä": "‡§ú‡§º‡§ø‡§®‡•ç‡§¶‡§ó‡•Ä", "‡§≠‡§æ‡§ó‡§¶‡•å‡§°‡§º": "‡§≠‡§æ‡§ó ‡§¶‡•å‡§°‡§º", "YouTube": "‡§Ø‡•Ç‡§ü‡•ç‡§Ø‡•Ç‡§¨", "AI": "‡§è ‡§Ü‡§à"}
    for k, v in brain_fix.items(): text = text.replace(k, v)
    
    return text.strip()

# ‡•™. ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§á‡§Ç‡§ú‡§® - '‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã-‡§ö‡§Ç‡§ï‡§ø‡§Ç‡§ó' ‡§§‡§ï‡§®‡•Ä‡§ï (LOCKED) [cite: 2026-01-06]
def generate_shiv_v1_5(text, up_ref, git_ref, speed_s, pitch_s, use_silence, use_clean, progress=gr.Progress()):
    if not text: return None
    
    p_text = shiv_super_cleaner(text)
    ref = up_ref if up_ref else "ref.wav"
    if not up_ref:
        url = G_RAW + requests.utils.quote(git_ref)
        with open(ref, "wb") as f: f.write(requests.get(url).content)

    # ‚ö° ‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡§´‡§ø‡§ï‡•ç‡§∏: ‡§µ‡§æ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•ã‡§Æ‡§æ (,) ‡§î‡§∞ ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§µ‡§ø‡§∞‡§æ‡§Æ (‡•§) ‡§™‡§∞ ‡§õ‡•ã‡§ü‡•á ‡§ü‡•Å‡§ï‡•ú‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§§‡•ã‡•ú‡§®‡§æ [cite: 2026-02-20]
    chunks = re.split(r'([,‡•§!?‡••\n])', p_text)
    combined = AudioSegment.empty()
    
    valid_chunks = []
    temp_chunk = ""
    for c in chunks:
        if c in [",", "‡•§", "!", "?", "‡••", "\n"]:
            valid_chunks.append(temp_chunk + c)
            temp_chunk = ""
        else: temp_chunk += c
    if temp_chunk: valid_chunks.append(temp_chunk)

    for i, chunk in enumerate(valid_chunks):
        if len(chunk.strip()) < 2: continue
        progress((i+1)/len(valid_chunks), desc="‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡§Æ‡•Å‡§ï‡•ç‡§§ ‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§ú‡§æ‡§∞‡•Ä ‡§π‡•à...")
        
        # [pause] ‡§ú‡•à‡§∏‡•á ‡§ü‡•à‡§ó‡•ç‡§∏ ‡§ï‡•ã ‡§∏‡§Ç‡§≠‡§æ‡§≤‡§®‡§æ
        if "[pause]" in chunk: combined += AudioSegment.silent(duration=800); continue
        
        name = f"final_chunk_{i}.wav"
        # üîí ‡§∏‡§¨‡§∏‡•á ‡§∏‡§ü‡•Ä‡§ï XTTS ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏: Penalty 1.2, Temp 0.1 [cite: 2026-02-20]
        tts.tts_to_file(text=chunk.strip(), speaker_wav=ref, language="hi", file_path=name, 
                        speed=speed_s, repetition_penalty=1.2, temperature=0.1, top_k=1)
        
        seg = AudioSegment.from_wav(name)
        if use_silence: # ‡§∏‡§æ‡§á‡§≤‡•á‡§Ç‡§∏ ‡§∞‡§ø‡§Æ‡•Ç‡§µ‡§∞ ‡§¨‡§ü‡§® [cite: 2026-01-06]
            try: seg = effects.strip_silence(seg, silence_thresh=-45, padding=100)
            except: pass
        combined += seg
        os.remove(name)
        torch.cuda.empty_cache(); gc.collect()

    if use_clean: # Symmetry Clean ‡§ü‡•Ç‡§≤ [cite: 2026-01-06]
        combined = combined.set_frame_rate(44100)
        combined = effects.normalize(combined)
    
    final_p = "Shiv_AI_v1.5_Pure.wav"
    combined.export(final_p, format="wav")
    return final_p

# ‡•´. ‡§¶‡§ø‡§µ‡•ç‡§Ø UI (‡§µ‡§∞‡•ç‡§° ‡§ï‡§æ‡§â‡§Ç‡§ü‡§∞ ‡§ï‡•á ‡§∏‡§æ‡§•) [cite: 2026-02-20]
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# üö© ‡§∂‡§ø‡§µ AI (Shiv AI) v1.5 ‚Äî ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó")
    gr.Markdown("### üîí ‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡§æ‡§∏‡•ç‡§§‡•ç‡§∞ ‡§Ö‡§™‡§°‡•á‡§ü: ‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡•ß‡•¶‡•¶‡•¶% ‡§¨‡§Ç‡§¶ | ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§π‡§æ‡§à ‡§∏‡•ç‡§™‡•Ä‡§° [cite: 2026-01-06]")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§Ø‡§π‡§æ‡§Å ‡§≤‡§ø‡§ñ‡•á‡§Ç", lines=12, elem_id="script_box")
            word_count = gr.Markdown("‡§∂‡§¨‡•ç‡§¶ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ: **‡§∂‡•Ç‡§®‡•ç‡§Ø**")
            txt.change(lambda x: f"‡§∂‡§¨‡•ç‡§¶ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ: **{len(x.split()) if x else '‡§∂‡•Ç‡§®‡•ç‡§Ø'}**", [txt], [word_count])
            
        with gr.Column(scale=1):
            git_v = gr.Dropdown(choices=["aideva.wav"], label="‡§µ‡•â‡§á‡§∏", value="aideva.wav")
            up_v = gr.Audio(label="‡§∏‡•à‡§Ç‡§™‡§≤ ‡§Ö‡§™‡§≤‡•ã‡§°", type="filepath")
            with gr.Accordion("‚öôÔ∏è ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏ (LOCKED)", open=True):
                spd = gr.Slider(0.9, 1.4, 1.15, label="‡§∞‡•û‡•ç‡§§‡§æ‡§∞")
                cln = gr.Checkbox(label="‡§è‡§Ü‡§à ‡§¨‡•á‡§∏ ‡§∏‡§´‡§æ‡§à (Symmetry)", value=True)
                sln = gr.Checkbox(label="‡§∏‡§æ‡§á‡§≤‡•á‡§Ç‡§∏ ‡§∞‡§ø‡§Æ‡•Ç‡§µ‡§∞", value=True)
            btn = gr.Button("üöÄ ‡§∂‡•Å‡§¶‡•ç‡§ß ‡§Ü‡§µ‡§æ‡§ú ‡§ú‡§®‡§∞‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç", variant="primary")
            
    out = gr.Audio(label="‡§´‡§æ‡§á‡§®‡§≤ ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü", type="filepath", autoplay=True)
    btn.click(generate_shiv_v1_5, [txt, up_v, git_v, spd, gr.State(1.0), sln, cln], out)

demo.launch(share=True)
