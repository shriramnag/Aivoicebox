import os, torch, gradio as gr, requests, re, gc
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment, effects

# ‡•ß. ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§π‡§æ‡§à ‡§∏‡•ç‡§™‡•Ä‡§° ‡§∏‡•á‡§ü‡§Ö‡§™ (LOCKED)
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ‡•®. ‡§Æ‡§æ‡§∏‡•ç‡§ü‡§∞ ‡§Æ‡•â‡§°‡§≤ - ‡§∂‡§ø‡§µ ‡§è‡§Ü‡§à (Shiv AI)
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth" 
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

G_RAW = "https://raw.githubusercontent.com/shriramnag/Aivoicebox/main/%F0%9F%93%81%20voices/"

def boost_realistic_audio(audio):
    """‡§Ü‡§µ‡§æ‡•õ ‡§ï‡•ã aideva.wav ‡§ú‡•à‡§∏‡§æ ‡§¶‡§Æ‡§¶‡§æ‡§∞ ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è"""
    resampled = audio.set_frame_rate(44100)
    return effects.normalize(resampled)

def clean_script_shiv_ai(text):
    """ü§ñ ‡§ï‡•á‡§µ‡§≤ ‡§∂‡•Å‡§¶‡•ç‡§ß ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§î‡§∞ ‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂ ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•ã ‡§™‡§æ‡§∏ ‡§π‡•ã‡§®‡•á ‡§¶‡•á‡§ó‡§æ (LOCKED)"""
    # ‡§Ö‡§®‡§ö‡§æ‡§π‡•á ‡§ï‡•à‡§∞‡•á‡§ï‡•ç‡§ü‡§∞‡•ç‡§∏ ‡§π‡§ü‡§æ‡§®‡§æ ‡§ú‡•ã AI ‡§ï‡•ã ‡§≠‡§ü‡§ï‡§æ‡§§‡•á ‡§π‡•à‡§Ç
    text = re.sub(r'[^\w\s‡•§!?.,-]', '', text)
    
    eng_chars = len(re.findall(r'[a-zA-Z]', text))
    hi_chars = len(re.findall(r'[\u0900-\u097F]', text))
    lang = "en" if eng_chars > hi_chars else "hi"
    
    # ‡§®‡§Ç‡§¨‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§®‡§æ ‡§Ö‡§®‡§ø‡§µ‡§æ‡§∞‡•ç‡§Ø ‡§π‡•à (‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡§∞‡•ã‡§ï‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è)
    if lang == "hi":
        num_map = {'0':'‡§∂‡•Ç‡§®‡•ç‡§Ø','1':'‡§è‡§ï','2':'‡§¶‡•ã','3':'‡§§‡•Ä‡§®','4':'‡§ö‡§æ‡§∞','5':'‡§™‡§æ‡§Å‡§ö','6':'‡§õ‡§π','7':'‡§∏‡§æ‡§§','8':'‡§Ü‡§†','9':'‡§®‡•å'}
        for n, w in num_map.items(): text = text.replace(n, w)
    else:
        en_map = {'0':'zero','1':'one','2':'two','3':'three','4':'four','5':'five','6':'six','7':'seven','8':'eight','9':'nine'}
        for n, w in en_map.items(): text = text.replace(n, w)
    return text.strip(), lang

def generate_shiv_final_warrior(text, up_ref, git_ref, speed_s, pitch_s, use_silence, use_clean, progress=gr.Progress()):
    ref = up_ref if up_ref else "ref.wav"
    if not up_ref:
        url = G_RAW + requests.utils.quote(git_ref)
        with open(ref, "wb") as f: f.write(requests.get(url).content)

    # ‚ö° ‡•©. '‡§Ö‡§≤‡•ç‡§ü‡•ç‡§∞‡§æ-‡§∂‡•â‡§∞‡•ç‡§ü' ‡§ü‡•Å‡§ï‡•ú‡•á (Micro-Chunking)
    # ‡§õ‡•ã‡§ü‡•á ‡§ü‡•Å‡§ï‡•ú‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏ ‡§ï‡§∞‡§®‡•á ‡§∏‡•á ‡§è‡§Ü‡§à ‡§ï‡§≠‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡§ï‡§≤‡§æ‡§§‡§æ
    sentences = re.split(r'(?<=[‡•§!?‡••.])\s+', text.strip())
    all_tasks = [s.strip() for s in sentences if len(s.strip()) > 1]
    
    combined = AudioSegment.empty()
    total = len(all_tasks)
    
    

    for i, task in enumerate(all_tasks):
        progress((i+1)/total, desc=f"‚ö° ‡§∂‡§ø‡§µ ‡§è‡§Ü‡§à ‡•ß‡•¶‡•¶‡•¶% ‡§∂‡•Å‡§¶‡•ç‡§ß ‡§ï‡•ç‡§≤‡•ã‡§®‡§ø‡§Ç‡§ó: {i+1} / {total}")
        
        task_clean, detected_lang = clean_script_shiv_ai(task)
        if not task_clean: continue
        
        name = f"chunk_{i}.wav"
        
        # --- üö© ‡§∂‡§ø‡§µ ‡§è‡§Ü‡§à ‡§ï‡§æ '‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ö‡§ï‡•ç‡§∞' ‡§™‡•à‡§∞‡§æ‡§Æ‡•Ä‡§ü‡§∞‡•ç‡§∏ (LOCKED) ---
        # Temperature 0.01: ‡§è‡§Ü‡§à ‡§ï‡•Ä '‡§Æ‡§∞‡•ç‡§ú‡•Ä' ‡§ñ‡§§‡•ç‡§Æ, ‡§Ö‡§¨ ‡§∏‡§ø‡§∞‡•ç‡§´ ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§¨‡•ã‡§≤‡•á‡§ó‡§æ‡•§
        # Repetition Penalty 15.0: ‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡§∞‡•ã‡§ï‡§®‡•á ‡§ï‡§æ ‡§∏‡§¨‡§∏‡•á ‡§∏‡§ü‡•Ä‡§ï ‡§¨‡•à‡§≤‡•á‡§Ç‡§∏‡•§
        # Top_k 1: ‡§∏‡§¨‡§∏‡•á ‡§¨‡•á‡§∏‡•ç‡§ü ‡§î‡§∞ ‡§ï‡•ç‡§≤‡§ø‡§Ø‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø ‡§ï‡§æ ‡§ö‡•Å‡§®‡§æ‡§µ‡•§
        tts.tts_to_file(text=task_clean, speaker_wav=ref, language=detected_lang, file_path=name, 
                        speed=speed_s, repetition_penalty=15.0, temperature=0.01,
                        top_p=0.8, top_k=1)
        
        seg = AudioSegment.from_wav(name)
        if use_silence:
            try: seg = effects.strip_silence(seg, silence_thresh=-50, padding=100)
            except: pass
        combined += seg
        if os.path.exists(name): os.remove(name)
        
        torch.cuda.empty_cache(); gc.collect()

    if use_clean: combined = boost_realistic_audio(combined)
    final_path = "Shri Ram Nag.wav"
    combined.export(final_path, format="wav")
    return final_path

# üé® ‡§¶‡§ø‡§µ‡•ç‡§Ø UI
js_code = "function insertTag(tag) { var t=document.querySelector('#script_box textarea'); var s=t.selectionStart; t.value=t.value.substring(0,s)+' '+tag+' '+t.value.substring(t.selectionEnd); t.focus(); return t.value; }"

with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange"), js=js_code) as demo:
    gr.Markdown("# üö© ‡§∂‡§ø‡§µ ‡§è‡§Ü‡§à (Shiv AI) - '‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó' ‡•ß‡•¶‡•¶‡•¶% ‡§´‡§æ‡§á‡§®‡§≤ ‡§´‡§ø‡§ï‡•ç‡§∏")
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="‡§Ö‡§™‡§®‡•Ä ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§Ø‡§π‡§æ‡§Å ‡§≤‡§ø‡§ñ‡•á‡§Ç (‡§π‡§ø‡§Ç‡§¶‡•Ä/English)", lines=12, elem_id="script_box")
        with gr.Column(scale=1):
            git_voice = gr.Dropdown(choices=["aideva.wav", "Joanne.wav"], label="‡§Ü‡§µ‡§æ‡•õ", value="aideva.wav")
            manual = gr.Audio(label="‡§ì‡§∞‡§ø‡§ú‡§ø‡§®‡§≤ ‡§∏‡•à‡§Ç‡§™‡§≤ (aideva.wav)", type="filepath")
            with gr.Accordion("‚öôÔ∏è ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏", open=True):
                spd = gr.Slider(0.8, 1.5, 1.15, label="‡§∞‡•û‡•ç‡§§‡§æ‡§∞ (Speed)")
                ptc = gr.Slider(0.8, 1.1, 1.0, label="‡§™‡§ø‡§ö (Pitch)")
                cln = gr.Checkbox(label="AI ‡§¨‡•á‡§∏ ‡§î‡§∞ ‡§∏‡§´‡§æ‡§à", value=True)
                sln = gr.Checkbox(label="‡§∏‡§æ‡§á‡§≤‡•á‡§Ç‡§∏ ‡§∞‡§ø‡§Æ‡•Ç‡§µ‡§∞", value=True)
            btn = gr.Button("‡•ß‡•¶‡•¶‡•¶% ‡§∂‡•Å‡§¶‡•ç‡§ß ‡§ï‡•ç‡§≤‡•ã‡§®‡§ø‡§Ç‡§ó üöÄ", variant="primary")
    out = gr.Audio(label="‡§´‡§æ‡§á‡§®‡§≤ ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü (Shri Ram Nag)", type="filepath", autoplay=True)
    btn.click(generate_shiv_final_warrior, [txt, manual, git_voice, spd, ptc, sln, cln], out)

demo.launch(share=True)
