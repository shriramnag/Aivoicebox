import os, torch, gradio as gr, requests, re, gc
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment, effects

# ‡•ß. ‡§Ö‡§≤‡•ç‡§ü‡•ç‡§∞‡§æ ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§∏‡•á‡§ü‡§Ö‡§™ (LOCKED) [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
torch.backends.cudnn.benchmark = True
device = "cuda" if torch.cuda.is_available() else "cpu"

# ‡•®. ‡§π‡§ó‡§ø‡§Ç‡§ó ‡§´‡•á‡§∏ ‡§Æ‡•â‡§°‡§≤ ‡§á‡§Ç‡§ü‡•Ä‡§ó‡•ç‡§∞‡•á‡§∂‡§® [cite: 2026-02-16]
REPO_ID = "Shriramnag/My-Shriram-Voice" 

print("‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó ‡§ú‡•Ä, ‡§Ö‡§®‡§≤‡§ø‡§Æ‡§ø‡§ü‡•á‡§° ‡§á‡§Ç‡§ú‡§® ‡§≤‡•ã‡§° ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à...")
model_path = hf_hub_download(repo_id=REPO_ID, filename="Ramai.pth")
hf_hub_download(repo_id=REPO_ID, filename="config.json")

tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)
G_RAW = "https://raw.githubusercontent.com/shriramnag/Aivoicebox/main/%F0%9F%93%81%20voices/"

# ‡•©. ‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡§´‡§ø‡§ï‡•ç‡§∏ ‡§ü‡•Ç‡§≤ [cite: 2026-02-20]
def shiv_super_cleaner(text):
    if not text: return ""
    num_map = {'0':'‡§∂‡•Ç‡§®‡•ç‡§Ø','1':'‡§è‡§ï','2':'‡§¶‡•ã','3':'‡§§‡•Ä‡§®','4':'‡§ö‡§æ‡§∞','5':'‡§™‡§æ‡§Å‡§ö','6':'‡§õ‡§π','7':'‡§∏‡§æ‡§§','8':'‡§Ü‡§†','9':'‡§®‡•å'}
    for n, w in num_map.items(): text = text.replace(n, w)
    text = text.replace('.', ',')
    return text.strip()

# ‡•™. ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§á‡§Ç‡§ú‡§® - ‡§Ö‡§®‡§≤‡§ø‡§Æ‡§ø‡§ü‡•á‡§° ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§ï‡§ü‡§∞ (LOCKED) [cite: 2026-01-06]
def generate_shiv_v1_5(text, up_ref, git_ref, speed_s, pitch_s, use_silence, use_clean, progress=gr.Progress()):
    if not text: return None
    
    p_text = shiv_super_cleaner(text)
    ref = up_ref if up_ref else "ref.wav"
    if not up_ref:
        url = G_RAW + requests.utils.quote(git_ref)
        with open(ref, "wb") as f: f.write(requests.get(url).content)

    # ‚ö° ‡§Ö‡§®‡§≤‡§ø‡§Æ‡§ø‡§ü‡•á‡§° ‡§ö‡§Ç‡§ï‡§ø‡§Ç‡§ó ‡§≤‡•â‡§ú‡§ø‡§ï: ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•Ä ‡§ï‡•ã‡§à ‡§∏‡•Ä‡§Æ‡§æ ‡§®‡§π‡•Ä‡§Ç
    all_words = p_text.split()
    chunks = []
    # ‡§π‡§∞ ‡•ß‡•´‡•¶ ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§è‡§ï ‡§®‡§Ø‡§æ ‡§π‡§ø‡§∏‡•ç‡§∏‡§æ ‡§¨‡§®‡§æ‡§®‡§æ (‡§¨‡§ø‡§®‡§æ ‡§ï‡§ø‡§∏‡•Ä ‡•™‡•¶‡•¶ ‡§ï‡•Ä ‡§≤‡§ø‡§Æ‡§ø‡§ü ‡§ï‡•á)
    for i in range(0, len(all_words), 150):
        chunks.append(" ".join(all_words[i:i+150]))

    combined = AudioSegment.empty()
    
    for i, chunk in enumerate(chunks):
        progress((i+1)/len(chunks), desc=f"‡§Ö‡§®‡§≤‡§ø‡§Æ‡§ø‡§ü‡•á‡§° ‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§ú‡§æ‡§∞‡•Ä ‡§π‡•à... ‡§≠‡§æ‡§ó {i+1}")
        
        name = f"turbo_{i}.wav"
        # üîí ‡§∏‡•ç‡§ü‡•á‡§¨‡§ø‡§≤‡§ø‡§ü‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó [cite: 2026-02-20]
        tts.tts_to_file(text=chunk, speaker_wav=ref, language="hi", file_path=name, 
                        speed=speed_s, repetition_penalty=2.0, temperature=0.5, top_k=50)
        
        seg = AudioSegment.from_wav(name)
        if pitch_s != 1.0:
            new_rate = int(seg.frame_rate * pitch_s)
            seg = seg._spawn(seg.raw_data, overrides={'frame_rate': new_rate}).set_frame_rate(44100)

        if use_silence: [cite: 2026-01-06]
            try: seg = effects.strip_silence(seg, silence_thresh=-45, padding=200)
            except: pass
            
        combined += seg
        os.remove(name)
        torch.cuda.empty_cache(); gc.collect()

    if use_clean: [cite: 2026-01-06]
        combined = effects.normalize(combined)
    
    final_output_name = "Shri_Ram_Nag_Output.wav"
    combined.export(final_output_name, format="wav")
    return final_output_name

# ‡•´. UI [cite: 2026-02-20]
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# üö© ‡§∂‡§ø‡§µ AI (Shiv AI) v1.5 ‚Äî ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó")
    gr.Markdown("### üîí ‡§Ö‡§®‡§≤‡§ø‡§Æ‡§ø‡§ü‡•á‡§° ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§Æ‡•ã‡§° | ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§π‡§æ‡§à ‡§∏‡•ç‡§™‡•Ä‡§° [cite: 2026-01-06]")
    
    txt = gr.Textbox(label="‡§≤‡§Ç‡§¨‡•Ä ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§Ø‡§π‡§æ‡§Å ‡§™‡•á‡§∏‡•ç‡§ü ‡§ï‡§∞‡•á‡§Ç (‡§ï‡•ã‡§à ‡§≤‡§ø‡§Æ‡§ø‡§ü ‡§®‡§π‡•Ä‡§Ç)", lines=15)
    with gr.Row():
        spd = gr.Slider(0.9, 1.4, 1.15, label="‡§∞‡•û‡•ç‡§§‡§æ‡§∞")
        ptch = gr.Slider(0.7, 1.3, 1.0, label="‡§™‡§ø‡§ö")
    
    btn = gr.Button("üöÄ ‡§Ö‡§®‡§≤‡§ø‡§Æ‡§ø‡§ü‡•á‡§° ‡§ú‡§®‡§∞‡•á‡§ü ‡§î‡§∞ ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§°", variant="primary")
    out = gr.Audio(label="‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü", type="filepath")
    
    btn.click(generate_shiv_v1_5, [txt, gr.State(None), gr.State("aideva.wav"), spd, ptch, gr.State(True), gr.State(True)], out)

demo.launch(share=True)
