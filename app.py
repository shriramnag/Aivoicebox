import os, torch, gradio as gr, requests, re, gc
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment, effects

# ‡•ß. ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§∏‡•á‡§ü‡§Ö‡§™ [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ‡•®. ‡§Æ‡§æ‡§∏‡•ç‡§ü‡§∞ ‡§Æ‡•â‡§°‡§≤ - ‡§∂‡§ø‡§µ AI (LOCKED) [cite: 2026-02-16]
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth" 
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

G_API = "https://api.github.com/repos/shriramnag/Aivoicebox/contents/%F0%9F%93%81%20voices"
G_RAW = "https://raw.githubusercontent.com/shriramnag/Aivoicebox/main/%F0%9F%93%81%20voices/"

def get_live_voices():
    try:
        r = requests.get(G_API, timeout=5).json()
        return [f['name'] for f in r if f['name'].endswith('.wav')]
    except: return ["Joanne.wav"]

def apply_cleaner(audio, use_clean):
    if use_clean:
        audio = effects.normalize(audio)
        audio = audio.high_pass_filter(80)
    return audio

def generate_final_shiv(text, upload_ref, github_ref, speed_s, pitch_s, use_silence, use_clean, progress=gr.Progress()):
    # ‡•©. ‡§®‡§Ç‡§¨‡§∞-‡§ü‡•Ç-‡§µ‡§∞‡•ç‡§°‡•ç‡§∏ ‡§´‡§ø‡§ï‡•ç‡§∏ [cite: 2026-02-20]
    num_map = {'0':'‡§∂‡•Ç‡§®‡•ç‡§Ø','1':'‡§è‡§ï','2':'‡§¶‡•ã','3':'‡§§‡•Ä‡§®','4':'‡§ö‡§æ‡§∞','5':'‡§™‡§æ‡§Å‡§ö','6':'‡§õ‡§π','7':'‡§∏‡§æ‡§§','8':'‡§Ü‡§†','9':'‡§®‡•å'}
    for n, w in num_map.items(): text = text.replace(n, w)

    ref_path = upload_ref if upload_ref else "temp_ref.wav"
    if not upload_ref:
        url = G_RAW + requests.utils.quote(github_ref)
        with open(ref_path, "wb") as f: f.write(requests.get(url).content)

    # ‚ö° ‡•™. ‡§™‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡•á‡§∏ ‡§î‡§∞ ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§ï‡§ü‡§∞ (Chunks) [cite: 2026-02-22]
    parts = re.split(r'(\[pause\]|\[breath\])', text)
    combined = AudioSegment.empty()
    
    total = len(parts)
    for i, part in enumerate(parts):
        if not part.strip(): continue
        progress((i+1)/total, desc=f"üöÄ ‡§ú‡§®‡§∞‡•á‡§ü ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à: {i+1}/{total}")
        
        if part == "[pause]":
            combined += AudioSegment.silent(duration=800)
        elif part == "[breath]":
            combined += AudioSegment.silent(duration=300)
        else:
            # ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§ï‡§ü‡§∞ (Sentences)
            sentences = re.split('([‡•§!?‡••\n])', part)
            chunks = [s.strip() for s in sentences if len(s.strip()) > 1]
            for chunk in chunks:
                name = "temp.wav"
                tts.tts_to_file(text=chunk, speaker_wav=ref_path, language="hi", file_path=name, speed=speed_s)
                seg = AudioSegment.from_wav(name)
                if use_silence:
                    try: seg = effects.strip_silence(seg, silence_thresh=-40, padding=100)
                    except: pass
                combined += seg
        torch.cuda.empty_cache(); gc.collect()

    combined = apply_cleaner(combined, use_clean)
    final_path = "Shri Ram Nag.wav"
    combined.export(final_path, format="wav")
    return final_path

# üé® ‡§¶‡§ø‡§µ‡•ç‡§Ø UI - ‡§ï‡§∞‡•ç‡§∏‡§∞ ‡§™‡•ã‡§ú‡•Ä‡§∂‡§® ‡§´‡§ø‡§ï‡•ç‡§∏ ‡§ï‡•á ‡§∏‡§æ‡§• [cite: 2026-02-22]
js_func = """
function insertTag(tag) {
    var textarea = document.querySelector("#script_box textarea");
    var start = textarea.selectionStart;
    var end = textarea.selectionEnd;
    var text = textarea.value;
    textarea.value = text.substring(0, start) + " " + tag + " " + text.substring(end);
    textarea.focus();
    textarea.selectionStart = textarea.selectionEnd = start + tag.length + 2;
    return textarea.value;
}
"""

with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange"), js=js_func) as demo:
    gr.Markdown("# üö© ‡§∂‡§ø‡§µ AI (Shiv AI) - '‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó' ‡§Æ‡§π‡§æ‡§ú‡•ç‡§û‡§æ‡§®‡•Ä ‡§™‡•ç‡§∞‡•ã")
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="‡§Ö‡§™‡§®‡•Ä ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§Ø‡§π‡§æ‡§Å ‡§≤‡§ø‡§ñ‡•á‡§Ç", lines=12, elem_id="script_box")
            with gr.Row():
                # ‡§ú‡§æ‡§µ‡§æ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§ï‡•á ‡§ú‡§∞‡§ø‡§è ‡§ï‡§∞‡•ç‡§∏‡§∞ ‡§ï‡•Ä ‡§ú‡§ó‡§π ‡§ü‡•à‡§ó ‡§≤‡§ó‡•á‡§ó‡§æ [cite: 2026-02-22]
                btn_p = gr.Button("‚è∏Ô∏è ‡§∞‡•ã‡§ï‡•á (‡§†‡§π‡§∞‡§æ‡§µ)")
                btn_b = gr.Button("üí® ‡§∏‡§æ‡§Ç‡§∏ (‡§∏‡§æ‡§Ç‡§∏)")
            
            btn_p.click(None, None, txt, js="() => insertTag('[pause]')")
            btn_b.click(None, None, txt, js="() => insertTag('[breath]')")
            
            word_counter = gr.Markdown("‡§∂‡§¨‡•ç‡§¶ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ: ‡§∂‡•Ç‡§®‡•ç‡§Ø")
            txt.change(lambda x: f"‡§∂‡§¨‡•ç‡§¶ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ: {len(x.split()) if x else '‡§∂‡•Ç‡§®‡•ç‡§Ø'}", [txt], [word_counter])
            
        with gr.Column(scale=1):
            v_list = get_live_voices()
            git_voice = gr.Dropdown(choices=v_list, label="‡§ó‡§ø‡§ü‡§π‡§¨ ‡§µ‡•â‡§Ø‡§∏", value=v_list[0])
            manual = gr.Audio(label="‡§Ö‡§™‡§≤‡•ã‡§° ‡§∏‡•à‡§Ç‡§™‡§≤", type="filepath")
            with gr.Accordion("üõ†Ô∏è ‡§∏‡•Å‡§™‡§∞ ‡§ü‡•Ç‡§≤‡•ç‡§∏ (LOCKED)", open=True):
                clean_btn = gr.Checkbox(label="AI ‡§∞‡•ã‡§¨‡•ã‡§ü‡§ø‡§ï‡•ç‡§∏ ‡§î‡§∞ ‡§¨‡•Ç‡§∏‡•ç‡§ü‡§∞", value=True)
                silence_btn = gr.Checkbox(label="‡§∏‡§æ‡§á‡§≤‡•á‡§Ç‡§∏ ‡§â‡§¶‡§æ‡§π‡§∞‡§£", value=True)
            btn = gr.Button("‡§¶‡§ø‡§µ‡•ç‡§Ø ‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•á‡§Ç üöÄ", variant="primary")
            
    out = gr.Audio(label="‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§°: Shri Ram Nag.wav", type="filepath", autoplay=True)
    btn.click(generate_final_shiv, [txt, manual, git_voice, gr.State(1.0), gr.State(0.96), silence_btn, clean_btn], out)

demo.launch(share=True)
