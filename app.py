import os
import torch
import gradio as gr
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from app_config import MODEL_CONFIG
from text_engine import split_into_chunks
from parallel_processor import combine_chunks

os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ‡§Æ‡•â‡§°‡§≤ ‡§≤‡•ã‡§°
model_path = hf_hub_download(repo_id=MODEL_CONFIG["repo_id"], filename=MODEL_CONFIG["model_file"])
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

def generate_voice(text, voice_sample, progress=gr.Progress()):
    if not text or not voice_sample:
        raise gr.Error("‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§î‡§∞ ‡§µ‡•â‡§á‡§∏ ‡§∏‡•à‡§Ç‡§™‡§≤ ‡§¶‡•á‡§Ç‡•§")
    
    chunks = split_into_chunks(text)
    chunk_files = []
    
    for i, chunk in enumerate(chunks):
        progress(i/len(chunks), desc=f"‡§µ‡§æ‡§ï‡•ç‡§Ø {i+1}/{len(chunks)} ‡§ú‡§æ‡§∞‡•Ä ‡§π‡•à...")
        name = f"chunk_{i}.wav"
        tts.tts_to_file(text=chunk, speaker_wav=voice_sample, language="hi", file_path=name)
        chunk_files.append(name)
    
    return combine_chunks(chunk_files)

with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# üéôÔ∏è ‡§∂‡•ç‡§∞‡•Ä‡§∞‡§æ‡§Æ ‡§µ‡§æ‡§£‡•Ä - ‡§ü‡§∞‡•ç‡§¨‡•ã v2")
    with gr.Row():
        with gr.Column():
            txt = gr.Textbox(label="10,000 ‡§ï‡•à‡§∞‡•á‡§ï‡•ç‡§ü‡§∞ ‡§§‡§ï ‡§ï‡•Ä ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü", lines=15)
            ref = gr.Audio(label="‡§µ‡•â‡§á‡§∏ ‡§∏‡•à‡§Ç‡§™‡§≤ (.wav)", type="filepath")
            btn = gr.Button("üöÄ ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§ú‡§®‡§∞‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç", variant="primary")
        with gr.Column():
            out = gr.Audio(label="‡§´‡§æ‡§á‡§®‡§≤ ‡§ë‡§°‡§ø‡§Ø‡•ã")
    btn.click(generate_voice, [txt, ref], out)

demo.launch(share=True)
