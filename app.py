import os, torch, gradio as gr, requests, re, gc
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment, effects

# ‡•ß. ‡§Ö‡§≤‡•ç‡§ü‡•ç‡§∞‡§æ ‡§ü‡§∞‡•ç‡§¨‡•ã 2000% ‡§π‡§æ‡§à ‡§∏‡•ç‡§™‡•Ä‡§° ‡§∏‡•á‡§ü‡§Ö‡§™ (LOCKED)
os.environ["COQUI_TOS_AGREED"] = "1"
torch.backends.cudnn.benchmark = True 
device = "cuda" if torch.cuda.is_available() else "cpu"

# ‡•®. ‡§π‡§ó‡§ø‡§Ç‡§ó ‡§´‡•á‡§∏ ‡§Æ‡•â‡§°‡§≤ ‡§á‡§Ç‡§ü‡•Ä‡§ó‡•ç‡§∞‡•á‡§∂‡§®
REPO_ID = "Shriramnag/My-Shriram-Voice" 

print("‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó ‡§ú‡•Ä, ‡§∂‡§ø‡§µ AI ‡§ï‡§æ ‡§∂‡•Å‡§¶‡•ç‡§ß ‡§á‡§Ç‡§ú‡§® ‡§≤‡•ã‡§° ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à...")

try:
    hf_hub_download(repo_id=REPO_ID, filename="Ramai.pth")
    hf_hub_download(repo_id=REPO_ID, filename="config.json")
    hf_hub_download(repo_id=REPO_ID, filename="tokenizer.json")
except:
    print("‚ö†Ô∏è ‡§Æ‡•â‡§°‡§≤ ‡§´‡§æ‡§á‡§≤‡•ç‡§∏ ‡§™‡§π‡§≤‡•á ‡§∏‡•á ‡§Æ‡•å‡§ú‡•Ç‡§¶ ‡§π‡•à‡§Ç‡•§")

tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)
G_RAW = "https://raw.githubusercontent.com/shriramnag/Aivoicebox/main/%F0%9F%93%81%20voices/"

# ‡•©. ‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡§î‡§∞ ‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂ ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡•Å‡§ß‡§æ‡§∞ (Transliteration Logic)
def shiv_super_cleaner(text):
    if not text: return ""
    
    # ‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂ ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•ã ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§â‡§ö‡•ç‡§ö‡§æ‡§∞‡§£ ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§®‡§æ ‡§§‡§æ‡§ï‡§ø AI ‡§® ‡§π‡§ï‡§≤‡§æ‡§è [cite: 2026-02-20]
    eng_to_hindi = {
        "Life": "‡§≤‡§æ‡§á‡§´", "Simple": "‡§∏‡§ø‡§Ç‡§™‡§≤", "Dream": "‡§°‡•ç‡§∞‡•Ä‡§Æ", 
        "Mindset": "‡§Æ‡§æ‡§á‡§Ç‡§°‡§∏‡•á‡§ü", "Believe": "‡§¨‡§ø‡§≤‡•Ä‡§µ", "Strong": "‡§∏‡•ç‡§ü‡•ç‡§∞‡•â‡§®‡•ç‡§ó",
        "Step": "‡§∏‡•ç‡§ü‡•á‡§™", "Fear": "‡§´‡§ø‡§Ø‡§∞", "Fail": "‡§´‡•á‡§≤", "YouTube": "‡§Ø‡•Ç‡§ü‡•ç‡§Ø‡•Ç‡§¨",
        "AI": "‡§è ‡§Ü‡§à", "Turbo": "‡§ü‡§∞‡•ç‡§¨‡•ã", "Speed": "‡§∏‡•ç‡§™‡•Ä‡§°"
    }
    
    for eng, hindi in eng_to_hindi.items():
        text = re.sub(rf'\b{eng}\b', hindi, text, flags=re.IGNORECASE)

    # ‡§®‡§Ç‡§¨‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§®‡§æ [cite: 2026-02-20]
    num_map = {'0':'‡§∂‡•Ç‡§®‡•ç‡§Ø','1':'‡§è‡§ï','2':'‡§¶‡•ã','3':'‡§§‡•Ä‡§®','4':'‡§ö‡§æ‡§∞','5':'‡§™‡§æ‡§Å‡§ö','6':'‡§õ‡§π','7':'‡§∏‡§æ‡§§','8':'‡§Ü‡§†','9':'‡§®‡•å'}
    for n, w in num_map.items(): text = text.replace(n, w)
    
    # ‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡§∞‡•ã‡§ï‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡•â‡§ü ‡§ï‡•ã ‡§ï‡•ã‡§Æ‡§æ ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§®‡§æ [cite: 2026-02-20]
    text = text.replace('.', ',')
    return text.strip()

# ‡•™. ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§á‡§Ç‡§ú‡§® - ‡•ß‡•´‡•¶-‡•®‡•¶‡•¶ ‡§µ‡§∞‡•ç‡§° ‡§ï‡§ü‡§∞ + ‡§Ö‡§®‡§≤‡§ø‡§Æ‡§ø‡§ü‡•á‡§° ‡§Æ‡•ã‡§° (LOCKED)
def generate_shiv_v1_5(text, up_ref, git_ref, speed_s, pitch_s, use_silence, use_clean, progress=gr.Progress()):
    if not text: return None
    
    p_text = shiv_super_cleaner(text)
    ref = up_ref if up_ref else "ref.wav"
    if not up_ref:
        url = G_RAW + requests.utils.quote(git_ref)
        with open(ref, "wb") as f: f.write(requests.get(url).content)

    # ‡•ß‡•´‡•¶-‡•®‡•¶‡•¶ ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü ‡§ï‡§ü‡§∞
    all_words = p_text.split()
    chunks = [" ".join(all_words[i:i+180]) for i in range(0, len(all_words), 180)]

    combined = AudioSegment.empty()
    
    for i, chunk in enumerate(chunks):
        progress((i+1)/len(chunks), desc=f"‡§Ö‡§≤‡•ç‡§ü‡•ç‡§∞‡§æ ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§ú‡§®‡§∞‡•á‡§∂‡§®: ‡§≠‡§æ‡§ó {i+1}")
        
        name = f"chunk_{i}.wav"
        # ‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡§î‡§∞ ‡§∂‡•ã‡§∞ ‡§ñ‡§§‡•ç‡§Æ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è Temperature 0.6 ‡§™‡§∞ ‡§∏‡•á‡§ü [cite: 2026-02-20]
        tts.tts_to_file(text=chunk, speaker_wav=ref, language="hi", file_path=name, 
                        speed=speed_s, repetition_penalty=2.0, temperature=0.6, top_k=50)
        
        seg = AudioSegment.from_wav(name)
        
        if pitch_s != 1.0:
            new_rate = int(seg.frame_rate * pitch_s)
            seg = seg._spawn(seg.raw_data, overrides={'frame_rate': new_rate}).set_frame_rate(44100)

        if use_silence:
            try: seg = effects.strip_silence(seg, silence_thresh=-45, padding=200)
            except: pass
            
        combined += seg
        os.remove(name)
        torch.cuda.empty_cache(); gc.collect()

    if use_clean:
        combined = combined.set_frame_rate(44100)
        combined = effects.normalize(combined)
    
    # ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§´‡§æ‡§á‡§≤ ‡§®‡•á‡§Æ [cite: 2026-02-22]
    final_output_name = "Shri_Ram_Nag_Output.wav"
    combined.export(final_output_name, format="wav")
    return final_output_name

# ‡•´. ‡§¶‡§ø‡§µ‡•ç‡§Ø UI (‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£)
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# üö© ‡§∂‡§ø‡§µ AI (Shiv AI) v1.5 ‚Äî ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó")
    gr.Markdown("### üîí ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§∏‡•ç‡§™‡•Ä‡§° | ‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂ ‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡§´‡§ø‡§ï‡•ç‡§∏ | ‡§Ö‡§®‡§≤‡§ø‡§Æ‡§ø‡§ü‡•á‡§° ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§Ø‡§π‡§æ‡§Å ‡§≤‡§ø‡§ñ‡•á‡§Ç", lines=12)
            word_count = gr.Markdown("‡§∂‡§¨‡•ç‡§¶ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ: **‡§∂‡•Ç‡§®‡•ç‡§Ø**")
            txt.change(lambda x: f"‡§∂‡§¨‡•ç‡§¶ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ: **{len(x.split()) if x else '‡§∂‡•Ç‡§®‡•ç‡§Ø'}**", [txt], [word_count])
            
        with gr.Column(scale=1):
            git_v = gr.Dropdown(choices=["aideva.wav"], label="‡§µ‡•â‡§á‡§∏", value="aideva.wav")
            up_v = gr.Audio(label="‡§∏‡•à‡§Ç‡§™‡§≤ ‡§Ö‡§™‡§≤‡•ã‡§°", type="filepath")
            with gr.Accordion("‚öôÔ∏è ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏ (LOCKED)", open=True):
                spd = gr.Slider(0.9, 1.4, 1.15, label="‡§ü‡§∞‡•ç‡§¨‡•ã ‡§∞‡•û‡•ç‡§§‡§æ‡§∞")
                ptch = gr.Slider(0.7, 1.3, 1.0, label="‡§™‡§ø‡§ö (Pitch)")
                cln = gr.Checkbox(label="Symmetry Clean", value=True)
                sln = gr.Checkbox(label="Silence Remover", value=True)
            btn = gr.Button("üöÄ ‡§ú‡§®‡§∞‡•á‡§ü ‡§î‡§∞ ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§°", variant="primary")
            
    out = gr.Audio(label="‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü", type="filepath", autoplay=True)
    btn.click(generate_shiv_v1_5, [txt, up_v, git_v, spd, ptch, sln, cln], out)

demo.launch(share=True, debug=True)
