import os
import torch
import gradio as gr
import shutil
import random
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment

# тЪб рдЯрд░реНрдмреЛ рдЗрдВрдЬрди рд╕реЗрдЯрдЕрдк [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ЁЯУе рдЖрдкрдХрд╛ рд░реЙрдпрд▓ рдореЙрдбрд▓ рд▓реЛрдб
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth"
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

def apply_human_vibration(file_path, weight, amp):
    """рдЖрд╡рд╛реЫ рдХреЛ рднрд╛рд░реА, рдордЦрдорд▓реА рдФрд░ рджрдорджрд╛рд░ рдмрдирд╛рдирд╛"""
    sound = AudioSegment.from_wav(file_path)
    
    # рдПрдордкреНрд▓реАрдлрд╛рдпрд░ (Power)
    sound = sound + amp 
    
    if weight > 0:
        # рдЧрд╣рд░рд╛ рдмреЗрд╕: рдпрд╣ рд╕рдВрддреЛрдВ рд╡рд╛рд▓реА рднрд╛рд░реА рдЖрд╡рд╛реЫ рджреЗрдЧрд╛
        new_sample_rate = int(sound.frame_rate * (1.0 - (weight / 90)))
        sound = sound._spawn(sound.raw_data, overrides={'frame_rate': new_sample_rate})
        sound = sound.set_frame_rate(44100)
    
    final_path = "shriram_100percent_realistic.wav"
    sound.export(final_path, format="wav")
    return final_path

def generate_voice(text, voice_sample, speed, emotion_depth, weight, amp):
    if not text or not voice_sample:
        raise gr.Error("рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдФрд░ рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓ реЫрд░реВрд░реА рд╣реИрдВред") 

    # ЁЯЪА рдЖрдкрдХрд╛ рдкреБрд░рд╛рдирд╛ рдЪрдВрдХ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ (рд╕реБрд░рдХреНрд╖рд┐рдд) [cite: 2026-02-16]
    # (рдпрд╣рд╛рдБ split_into_chunks рдФрд░ combine_chunks рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ)
    
    temp_file = "temp_ultimate.wav"
    
    # ЁЯза 100% рд╣реНрдпреВрдорди рдЯрдЪ рд▓реЙрдЬрд┐рдХ: рд░реИрдВрдбрдо рдЗрдореЛрд╢рди рд╡реЗрд░рд┐рдПрд╢рди
    # рдпрд╣ рдореЙрдбрд▓ рдХреЛ рдорд╢реАрдиреА рд╣реЛрдиреЗ рд╕реЗ рд░реЛрдХрддрд╛ рд╣реИ
    jittered_temp = emotion_depth + random.uniform(-0.05, 0.05)
    
    tts.tts_to_file(
        text=text,
        speaker_wav=voice_sample,
        language="hi",
        file_path=temp_file,
        speed=speed,
        repetition_penalty=16.0,   # рд╣рдХрд▓рд╛рд╣рдЯ рдкрд░ 100% рд▓рдЧрд╛рдо
        temperature=jittered_temp,  # рдбрд╛рдпрдирд╛рдорд┐рдХ рдЗрдореЛрд╢рди
        top_p=0.88,                # рд╢реБрджреНрдзрддрд╛ рдФрд░ рд╕реНрдкрд╖реНрдЯрддрд╛ рдХрд╛ рд╕рдВрддреБрд▓рди
        gpt_cond_len=4,            # рд╕реИрдВрдкрд▓ рдХреЛ рдмрд╛рд░реАрдХреА рд╕реЗ рд╕рдордЭрдиреЗ рдХреЗ рд▓рд┐рдП
        enable_text_splitting=True 
    )
    
    return apply_human_vibration(temp_file, weight, amp)

# ЁЯОи 100% рд░рд┐рдпрд▓рд┐рд╕реНрдЯрд┐рдХ рдорд╛рд╕реНрдЯрд░ рд╕реНрдЯреВрдбрд┐рдпреЛ UI
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# ЁЯЪй рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА - 100% рд░рд┐рдпрд▓рд┐рд╕реНрдЯрд┐рдХ 'рдЕрд▓реНрдЯреАрдореЗрдЯ' рдЗрдВрдЬрди")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="рдЕрдкрдиреА рдЕрдореГрдд рд╡рд╛рдгреА рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ", lines=12)
        with gr.Column(scale=1):
            ref = gr.Audio(label="рдУрд░рд┐рдЬрд┐рдирд▓ рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓", type="filepath")
            
            with gr.Accordion("ЁЯТО рд░рд┐рдпрд▓рд┐рд╕реНрдЯрд┐рдХ рдХрдВрдЯреНрд░реЛрд▓", open=True):
                speed_s = gr.Slider(label="рдмреЛрд▓рдиреЗ рдХреА рд░реЮреНрддрд╛рд░", minimum=0.8, maximum=1.2, value=0.96)
                emo_s = gr.Slider(label="рд╣реНрдпреВрдорди рдЯрдЪ (Emotions)", minimum=0.5, maximum=1.0, value=0.88)
                weight_s = gr.Slider(label="рдЖрд╡рд╛реЫ рдХрд╛ рднрд╛рд░реАрдкрди (Bass)", minimum=0, maximum=10, value=5)
                amp_s = gr.Slider(label="рдПрдордкреНрд▓реАрдлрд╛рдпрд░ (Gain)", minimum=-5, maximum=10, value=3)
            
            btn = gr.Button("ЁЯЪА 100% рд╣реНрдпреВрдорди рд╡реЙрдЗрд╕ рдЬрдирд░реЗрдЯ рдХрд░реЗрдВ", variant="primary")
            
    out = gr.Audio(label="рдЕрдВрддрд┐рдо рдХреНрд▓реЛрди рдХреА рдЧрдИ рдЖрд╡рд╛рдЬрд╝", type="filepath", autoplay=True)
    btn.click(generate_voice, [txt, ref, speed_s, emo_s, weight_s, amp_s], out)

demo.launch(share=True)
