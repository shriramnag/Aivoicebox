import os, torch, gradio as gr, requests, re, gc, json
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment, effects

# ‡•ß. ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§π‡§æ‡§à ‡§∏‡•ç‡§™‡•Ä‡§° ‡§∏‡•á‡§ü‡§Ö‡§™ (LOCKED)
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ‡•®. ‡§Æ‡§æ‡§∏‡•ç‡§ü‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§î‡§∞ ‡§°‡§ø‡§ï‡•ç‡§∂‡§®‡§∞‡•Ä (‡§Æ‡§∏‡•ç‡§§‡§ø‡§∑‡•ç‡§ï) ‡§∏‡•á‡§ü‡§Ö‡§™
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth" 
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

BRAIN_FILE = "shiv_brain.json"

def load_brain():
    if os.path.exists(BRAIN_FILE):
        try:
            with open(BRAIN_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except: return {}
    return {"YouTube": "‡§Ø‡•Ç‡§ü‡•ç‡§Ø‡•Ç‡§¨", "AI": "‡§è ‡§Ü‡§à", "Technology": "‡§ü‡•á‡§ï‡•ç‡§®‡•ã‡§≤‡•â‡§ú‡•Ä"}

def save_brain(brain_data):
    with open(BRAIN_FILE, "w", encoding="utf-8") as f:
        json.dump(brain_data, f, ensure_ascii=False, indent=4)

# ‡•©. ‡§ë‡§ü‡•ã-‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§≤‡•â‡§ú‡§ø‡§ï: ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§∏‡•á ‡§ñ‡•Å‡§¶ ‡§∏‡•Ä‡§ñ‡§®‡§æ
def auto_learn_from_script(text):
    brain = load_brain()
    # ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§Æ‡•á‡§Ç ‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂ ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•ã ‡§ñ‡•ã‡§ú‡§®‡§æ
    eng_words = re.findall(r'\b[a-zA-Z]+\b', text)
    new_learned = False
    
    for word in eng_words:
        if word not in brain:
            # ‡§Ø‡§π‡§æ‡§Å ‡§π‡§Æ ‡§è‡§ï ‡§¨‡•á‡§∏‡§ø‡§ï ‡§∞‡•Ç‡§≤ ‡§≤‡§ó‡§æ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç, ‡§Ü‡§™ ‡§¨‡§æ‡§¶ ‡§Æ‡•á‡§Ç ‡§á‡§∏‡•á ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§≠‡•Ä ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç
            # ‡§Ö‡§≠‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π ‡§®‡§è ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•ã ‡§∞‡§ú‡§ø‡§∏‡•ç‡§ü‡§∞ ‡§ï‡§∞ ‡§≤‡•á‡§ó‡§æ
            brain[word] = word 
            new_learned = True
    
    if new_learned:
        save_brain(brain)

def brain_processor(text):
    brain = load_brain()
    # ‡§®‡§Ç‡§¨‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§®‡§æ [2026-02-20]
    nums = {'0':'‡§∂‡•Ç‡§®‡•ç‡§Ø','1':'‡§è‡§ï','2':'‡§¶‡•ã','3':'‡§§‡•Ä‡§®','4':'‡§ö‡§æ‡§∞','5':'‡§™‡§æ‡§Å‡§ö','6':'‡§õ‡§π','7':'‡§∏‡§æ‡§§','8':'‡§Ü‡§†','9':'‡§®‡•å'}
    for n, w in nums.items(): text = text.replace(n, w)
    
    # ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§∏‡•á ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡§æ ‡§Æ‡§ø‡§≤‡§æ‡§® ‡§î‡§∞ ‡§∏‡•Å‡§ß‡§æ‡§∞
    for eng, hin in brain.items():
        text = re.sub(r'\b' + eng + r'\b', hin, text, flags=re.IGNORECASE)
    return text.strip()

# ‡•™. ‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§î‡§∞ ‡§ë‡§ü‡•ã-‡§ü‡•ç‡§∞‡•á‡§®‡§ø‡§Ç‡§ó ‡§á‡§Ç‡§ú‡§®
def generate_and_learn(text, up_ref, git_ref, speed_s, use_silence, progress=gr.Progress()):
    if not text: return None, "‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§ñ‡§æ‡§≤‡•Ä ‡§π‡•à!"
    
    # ‡§∏‡•ç‡§ü‡•á‡§™ ‡•ß: ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§∏‡•á '‡§∏‡•á‡§≤‡•ç‡§´-‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó' ‡§ï‡§∞‡§®‡§æ
    auto_learn_from_script(text)
    
    # ‡§∏‡•ç‡§ü‡•á‡§™ ‡•®: ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ï‡•ã ‡§∏‡§æ‡•û ‡§ï‡§∞‡§®‡§æ
    clean_text = brain_processor(text)
    
    ref = up_ref if up_ref else "ref.wav"
    if not up_ref:
        url = "https://raw.githubusercontent.com/shriramnag/Aivoicebox/main/%F0%9F%93%81%20voices/" + requests.utils.quote(git_ref)
        with open(ref, "wb") as f: f.write(requests.get(url).content)

    chunks = re.split(r'(?<=[‡•§!?‡••.])\s+', clean_text)
    combined = AudioSegment.empty()
    
    

    for i, task in enumerate(chunks):
        if not task.strip(): continue
        progress((i+1)/len(chunks), desc=f"‡§∂‡§ø‡§µ AI ‡§∏‡•Ä‡§ñ ‡§∞‡§π‡§æ ‡§π‡•à... {i+1}")
        out_name = f"chunk_{i}.wav"
        
        # ‡•ß‡•¶‡•¶‡•¶% ‡§∂‡•Å‡§¶‡•ç‡§ß ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏ (LOCKED)
        tts.tts_to_file(text=task, speaker_wav=ref, language="hi", file_path=out_name, 
                        speed=speed_s, repetition_penalty=15.0, temperature=0.01)
        
        combined += AudioSegment.from_wav(out_name)
        os.remove(out_name)
        torch.cuda.empty_cache(); gc.collect()

    final_path = "Shiv_AI_SelfLearned.wav"
    combined.export(final_path, format="wav")
    return final_path, f"‚úÖ ‡§è‡§Ü‡§à ‡§®‡•á ‡§®‡§à ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§∏‡•á ‡§∏‡•Ä‡§ñ‡§æ ‡§î‡§∞ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§¨‡§®‡§æ‡§Ø‡§æ‡•§"

# ‡•´. ‡§Æ‡•à‡§®‡•ç‡§Ø‡•Å‡§Ö‡§≤ ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ü‡•à‡§¨
def manual_update_brain(word, correction):
    brain = load_brain()
    brain[word] = correction
    save_brain(brain)
    return f"‚úÖ '‡§¶‡§ø‡§Æ‡§æ‡§ó' ‡§Ö‡§™‡§°‡•á‡§ü ‡§π‡•Å‡§Ü: {word} -> {correction}"

# ‡•¨. ‡§¶‡§ø‡§µ‡•ç‡§Ø ‡§á‡§Ç‡§ü‡§∞‡§´‡§º‡•á‡§∏ (v1.2)
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# üö© ‡§∂‡§ø‡§µ AI (Shiv AI) v1.2 ‚Äî ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó")
    gr.Markdown("### üß† '‡§Æ‡§π‡§æ‡§∏‡§Ç‡§ó‡§£‡§ï' - ‡§π‡§∞ ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§∏‡•á ‡§ñ‡•Å‡§¶ ‡§∏‡•Ä‡§ñ‡§®‡•á ‡§µ‡§æ‡§≤‡§æ ‡§è‡§Ü‡§à")
    
    with gr.Tabs():
        with gr.TabItem("üéôÔ∏è ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§¶‡•á‡§Ç ‡§î‡§∞ ‡§∏‡§ø‡§ñ‡§æ‡§è‡§Ç"):
            with gr.Row():
                with gr.Column(scale=2):
                    txt = gr.Textbox(label="‡§Ø‡§π‡§æ‡§Å ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§°‡§æ‡§≤‡•á‡§Ç (‡§ú‡§ø‡§§‡§®‡•Ä ‡§ú‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü, ‡§â‡§§‡§®‡§æ ‡§ú‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó)", lines=12)
                    spd = gr.Slider(0.9, 1.4, 1.15, label="‡§∏‡•ç‡§™‡•Ä‡§°")
                with gr.Column(scale=1):
                    git_v = gr.Dropdown(choices=["aideva.wav"], label="‡§µ‡•â‡§á‡§∏", value="aideva.wav")
                    up_v = gr.Audio(label="‡§∏‡•à‡§Ç‡§™‡§≤ ‡§Ö‡§™‡§≤‡•ã‡§°", type="filepath")
                    btn = gr.Button("üöÄ ‡§∏‡•Ä‡§ñ‡•á‡§Ç ‡§î‡§∞ ‡§ú‡§®‡§∞‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç", variant="primary")
            out_audio = gr.Audio(label="‡§∂‡§ø‡§µ AI ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü", type="filepath", autoplay=True)
            out_msg = gr.Markdown()
            
        with gr.TabItem("üß† ‡§Æ‡§∏‡•ç‡§§‡§ø‡§∑‡•ç‡§ï ‡§≤‡§æ‡§á‡§¨‡•ç‡§∞‡•á‡§∞‡•Ä"):
            gr.Markdown("### ‡§Ø‡§π‡§æ‡§Å ‡§Ü‡§™ ‡§¶‡•á‡§ñ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§è‡§Ü‡§à ‡§®‡•á ‡§ï‡•ç‡§Ø‡§æ-‡§ï‡•ç‡§Ø‡§æ ‡§∏‡•Ä‡§ñ‡§æ ‡§π‡•à ‡§Ø‡§æ ‡§ñ‡•Å‡§¶ ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç:")
            with gr.Row():
                wrong_w = gr.Textbox(label="‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂ ‡§∂‡§¨‡•ç‡§¶")
                correct_w = gr.Textbox(label="‡§∏‡§π‡•Ä ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§â‡§ö‡•ç‡§ö‡§æ‡§∞‡§£")
            update_btn = gr.Button("‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞‡•á‡§Ç")
            update_msg = gr.Markdown()

    btn.click(generate_and_learn, [txt, up_v, git_v, spd, gr.State(True)], [out_audio, out_msg])
    update_btn.click(manual_update_brain, [wrong_w, correct_w], update_msg)

demo.launch(share=True)
