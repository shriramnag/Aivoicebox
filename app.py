import os
import torch
import gradio as gr
import shutil
import re
import gc
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment
from brain import MahagyaniBrain 

# ЁЯЪА рдЯрд░реНрдмреЛ рдореИрдХреНрд╕ GPU рд╕реЗрдЯрдЕрдк [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ЁЯУе рдореЙрдбрд▓ рд▓реЛрдб (Ramai.pth - LOCKED) [cite: 2026-02-16]
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth"
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)

# GPU рдХрд╛ рдкреВрд░рд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬреЗрд╢рди [cite: 2026-01-06]
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

# ЁЯза рдорд╣рд╛рдЬреНрдЮрд╛рдиреА рдмреНрд░реЗрди
brain = MahagyaniBrain(
    'sanskrit_knowledge.json', 'hindi_grammar.json', 
    'english_knowledge.json', 'prosody_config.json'
)

def clean_text_for_xtts(text):
    """NotImplementedError рдлрд┐рдХреНрд╕ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП"""
    # рдирдВрдмрд░реЛрдВ рдХреЛ рдЯреЗрдХреНрд╕реНрдЯ рдореЗрдВ рдмрджрд▓рдиреЗ рдХрд╛ рдореИрдиреНрдпреБрдЕрд▓ рддрд░реАрдХрд╛ (рдмреНрд░реЗрди рдХреЗ рд╕рд╛рде)
    text = text.replace("2026", "рджреЛ рд╣рдЬрд╛рд░ рдЫрдмреНрдмреАрд╕").replace("2040", "рджреЛ рд╣рдЬрд╛рд░ рдЪрд╛рд▓реАрд╕")
    return text

def split_into_chunks(text):
    """рд▓рдВрдмреЗ рдСрдбрд┐рдпреЛ рдХреЗ рд▓рд┐рдП рд╕реНрдорд╛рд░реНрдЯ рдЪрдВрдХрд┐рдВрдЧ [cite: 2026-02-18]"""
    # рдЕрдм рдпрд╣ 150 рдХреИрд░реЗрдХреНрдЯрд░ рдкрд░ рдХрд╛рдЯреЗрдЧрд╛ рддрд╛рдХрд┐ GPU рдХрднреА рдУрд╡рд░рд▓реЛрдб рди рд╣реЛ
    sentences = re.split('([ред!?рее\n])', text)
    chunks = []
    current_chunk = ""
    for i in range(0, len(sentences)-1, 2):
        sentence = sentences[i] + sentences[i+1]
        if len(current_chunk) + len(sentence) < 150:
            current_chunk += sentence
        else:
            if current_chunk: chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk: chunks.append(current_chunk.strip())
    return [c for c in chunks if len(c) > 2]

def generate_voice(text, voice_sample, speed_s, progress=gr.Progress()):
    # 1. рдПрд░рд░ рдлрд┐рдХреНрд╕ рдФрд░ рдЯреЗрдХреНрд╕реНрдЯ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ
    text = clean_text_for_xtts(text)
    cleaned_text = brain.clean_and_format(text)
    profile = brain.get_voice_profile(text)
    final_speed = profile['global_speed'] if "рее" in text else speed_s
    
    # 2. рдЪрдВрдХрд┐рдВрдЧ (рдЯреБрдХрдбрд╝реЛрдВ рдХреА рдЧрд┐рдирддреА рджреЗрдЦрдиреЗ рдХреЗ рд▓рд┐рдП) [cite: 2026-02-18]
    chunks = split_into_chunks(cleaned_text)
    total_chunks = len(chunks)
    chunk_files = []
    output_folder = "turbo_chunks"
    if os.path.exists(output_folder): shutil.rmtree(output_folder)
    os.makedirs(output_folder)

    # 3. рдлреБрд▓ GPU рдЯрд░реНрдмреЛ рд▓реВрдк [cite: 2026-01-06]
    combined = AudioSegment.empty()
    
    for i, chunk in enumerate(chunks):
        # рдкреНрд░реЛрдЧреНрд░реЗрд╕ рдЕрдкрдбреЗрдЯ - рдЕрдм рдЖрдкрдХреЛ рджрд┐рдЦреЗрдЧрд╛ рдХрд┐рддрдиреЗ рдЯреБрдХрдбрд╝реЗ рд╣реИрдВ (рдЬреИрд╕реЗ 1/150)
        progress((i+1)/total_chunks, desc=f"ЁЯЪА рдЯрд░реНрдмреЛ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ: рдЯреБрдХрдбрд╝рд╛ {i+1} / {total_chunks}")
        
        name = os.path.join(output_folder, f"c_{i}.wav")
        
        # XTTS рдЬрдирд░реЗрд╢рди
        tts.tts_to_file(
            text=chunk, speaker_wav=voice_sample, language="hi", file_path=name,
            speed=final_speed, temperature=0.75, repetition_penalty=5.0
        )
        
        # рдореЗрдореЛрд░реА рдореИрдиреЗрдЬрдореЗрдВрдЯ (рд▓рдВрдмреА рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдХреЗ рд▓рд┐рдП рдЬрд░реВрд░реА)
        temp_audio = AudioSegment.from_wav(name)
        combined += temp_audio
        
        # рд╣рд░ 10 рдЯреБрдХрдбрд╝реЛрдВ рдХреЗ рдмрд╛рдж GPU рдХреИрд╢ рд╕рд╛рдл рдХрд░реЗрдВ
        if i % 10 == 0:
            torch.cuda.empty_cache()
            gc.collect()

    final_path = "shriram_long_turbo_output.wav"
    combined.export(final_path, format="wav")
    return final_path

# ЁЯОи UI рдбрд┐рдЬрд╝рд╛рдЗрди (LOCKED & IMPROVED)
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# ЁЯЪй рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА - рдЯрд░реНрдмреЛ рдореИрдХреНрд╕ (Long Audio Support)")
    gr.Markdown("### рдЕрдм 40-50 рдорд┐рдирдЯ рдХрд╛ рдСрдбрд┐рдпреЛ рдЬрдирд░реЗрдЯ рдХрд░реЗрдВ рдмрд┐рдирд╛ рдХрд┐рд╕реА рдПрд░рд░ рдХреЗред")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="рдпрд╣рд╛рдБ рдЕрдкрдиреА рд▓рдВрдмреА рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдпрд╛ рд╢реНрд▓реЛрдХ рдбрд╛рд▓реЗрдВ", lines=15)
        with gr.Column(scale=1):
            ref = gr.Audio(label="рдорд╛рд╕реНрдЯрд░ рд╕реИрдВрдкрд▓ (aideva.wav)", type="filepath")
            speed = gr.Slider(label="рд░реЮреНрддрд╛рд░", minimum=0.8, maximum=1.4, value=1.0)
            btn = gr.Button("рджрд┐рд╡реНрдп рдЯрд░реНрдмреЛ рдЬрдирд░реЗрд╢рди рд╢реБрд░реВ рдХрд░реЗрдВ ЁЯЪА", variant="primary")
            
    out = gr.Audio(label="рдлрд╛рдЗрдирд▓ рдЖрдЙрдЯрдкреБрдЯ (рд╣рд╛рдИ рдХреНрд╡рд╛рд▓рд┐рдЯреА)", type="filepath")
    
    btn.click(generate_voice, [txt, ref, speed], out)

demo.launch(share=True, debug=True)
