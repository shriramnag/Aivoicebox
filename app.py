import os, torch, gradio as gr, requests, re, gc
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment, effects

# ‡•ß. ‡§Ö‡§≤‡•ç‡§ü‡•ç‡§∞‡§æ ‡§ü‡§∞‡•ç‡§¨‡•ã 2000% ‡§π‡§æ‡§à ‡§∏‡•ç‡§™‡•Ä‡§° ‡§∏‡•á‡§ü‡§Ö‡§™ (LOCKED)
os.environ["COQUI_TOS_AGREED"] = "1"
torch.backends.cudnn.benchmark = True # GPU ‡§ï‡•Ä ‡§´‡•Å‡§≤ ‡§∏‡•ç‡§™‡•Ä‡§°
torch.set_num_threads(4)
device = "cuda" if torch.cuda.is_available() else "cpu"

# ‡•®. ‡§π‡§ó‡§ø‡§Ç‡§ó ‡§´‡•á‡§∏ ‡§Æ‡•â‡§°‡§≤ ‡§á‡§Ç‡§ü‡•Ä‡§ó‡•ç‡§∞‡•á‡§∂‡§®
REPO_ID = "Shriramnag/My-Shriram-Voice" 

print("‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó ‡§ú‡•Ä, 2000% ‡§Ö‡§≤‡•ç‡§ü‡•ç‡§∞‡§æ-‡§ü‡§∞‡•ç‡§¨‡•ã ‡§á‡§Ç‡§ú‡§® ‡§≤‡•ã‡§° ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à...")

# ‡§Æ‡•â‡§°‡§≤ ‡§´‡§æ‡§á‡§≤‡•ç‡§∏ ‡§ï‡•ã ‡§ï‡•á‡§µ‡§≤ ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§ï‡§∞‡§®‡§æ
try:
    model_path = hf_hub_download(repo_id=REPO_ID, filename="Ramai.pth")
    hf_hub_download(repo_id=REPO_ID, filename="config.json")
    print("‚úÖ ‡§Æ‡•â‡§°‡§≤ ‡§∏‡§´‡§≤‡§§‡§æ‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§ï‡§®‡•á‡§ï‡•ç‡§ü ‡§π‡•ã ‡§ó‡§Ø‡§æ‡•§")
except Exception as e:
    print("‚ö†Ô∏è ‡§Æ‡•â‡§°‡§≤ ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡•§")

# ‡§Æ‡§æ‡§∏‡•ç‡§ü‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§≤‡•ã‡§°
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)
G_RAW = "https://raw.githubusercontent.com/shriramnag/Aivoicebox/main/%F0%9F%93%81%20voices/"

# ‡•©. ‡§Æ‡§æ‡§∏‡•ç‡§ü‡§∞ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ï‡•ç‡§≤‡•Ä‡§®‡§∞ (‡§π‡§ï‡§≤‡§æ‡§π‡§ü ‡§î‡§∞ ‡§®‡§Ç‡§¨‡§∞ ‡§´‡§ø‡§ï‡•ç‡§∏)
def shiv_super_cleaner(text):
    if not text: return ""
    num_map = {'0':'‡§∂‡•Ç‡§®‡•ç‡§Ø','1':'‡§è‡§ï','2':'‡§¶‡•ã','3':'‡§§‡•Ä‡§®','4':'‡§ö‡§æ‡§∞','5':'‡§™‡§æ‡§Å‡§ö','6':'‡§õ‡§π','7':'‡§∏‡§æ‡§§','8':'‡§Ü‡§†','9':'‡§®‡•å'}
    for n, w in num_map.items(): text = text.replace(n, w)
    
    brain_fix = {"‡§ú‡§ø‡§Ç‡§¶‡§ó‡•Ä": "‡§ú‡§º‡§ø‡§®‡•ç‡§¶‡§ó‡•Ä", "YouTube": "‡§Ø‡•Ç‡§ü‡•ç‡§Ø‡•Ç‡§¨", "AI": "‡§è ‡§Ü‡§à"}
    for k, v in brain_fix.items(): text = text.replace(k, v)
    return text.strip()

# ‡•™. ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§á‡§Ç‡§ú‡§® - 150-200 ‡§µ‡§∞‡•ç‡§° ‡§ï‡§ü‡§∞ + ‡§Ö‡§≤‡•ç‡§ü‡•ç‡§∞‡§æ ‡§ü‡§∞‡•ç‡§¨‡•ã (LOCKED)
def generate_shiv_v1_5(text, up_ref, git_ref, speed_s, pitch_s, use_silence, use_clean, progress=gr.Progress()):
    if not text: return None
    
    p_text = shiv_super_cleaner(text)
    ref = up_ref if up_ref else "ref.wav"
    if not up_ref:
        url = G_RAW + requests.utils.quote(git_ref)
        with open(ref, "wb") as f: f.write(requests.get(url).content)

    # ‚ö° 150-200 ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü ‡§ï‡§ü‡§∞ (SMART SCRIPT CUTTER)
    raw_sentences = re.split(r'([‡•§!?\n])', p_text)
    sentences = []
    temp_s = ""
    for c in raw_sentences:
        if c in ["‡•§", "!", "?", "\n"]:
            sentences.append((temp_s + c).strip())
            temp_s = ""
        else:
            temp_s += c
    if temp_s: sentences.append(temp_s.strip())

    chunks = []
    current_chunk = ""
    for sentence in sentences:
        if not sentence: continue
        # ‡§ú‡§¨ ‡§§‡§ï 160-180 ‡§∂‡§¨‡•ç‡§¶ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã ‡§ú‡§æ‡§§‡•á, ‡§µ‡§æ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§ú‡•ã‡§°‡§º‡§§‡•á ‡§∞‡§π‡•ã
        if len(current_chunk.split()) + len(sentence.split()) <= 180:
            current_chunk += " " + sentence
        else:
            if current_chunk: chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk: chunks.append(current_chunk.strip())
    
    # ‡§Ö‡§ó‡§∞ ‡§ï‡•ã‡§à ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§π‡•Ä 200 ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§∏‡•á ‡§¨‡§°‡§º‡§æ ‡§π‡•ã (Fallback)
    final_chunks = []
    for c in chunks:
        words = c.split()
        if len(words) > 200:
            for i in range(0, len(words), 150):
                final_chunks.append(" ".join(words[i:i+150]))
        else:
            final_chunks.append(c)

    combined = AudioSegment.empty()
    
    for i, chunk in enumerate(final_chunks):
        progress((i+1)/len(final_chunks), desc=f"‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó ‡§ú‡•Ä, 150-200 ‡§µ‡§∞‡•ç‡§° ‡§ö‡§Ç‡§ï ‡§ú‡§®‡§∞‡•á‡§ü ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à... ({i+1}/{len(final_chunks)})")
        
        name = f"temp_chunk_{i}.wav"
        
        # üîí HALLUCINATION FIX: Temperature 0.5 ‡§î‡§∞ Penalty 2.0 (‡§®‡•ã ‡§∂‡§¨‡•ç‡§¶ ‡§ú‡§Ç‡§™)
        tts.tts_to_file(text=chunk, speaker_wav=ref, language="hi", file_path=name, 
                        speed=speed_s, repetition_penalty=2.0, temperature=0.5, top_k=50)
        
        seg = AudioSegment.from_wav(name)
        
        # ‡§™‡§ø‡§ö ‡§ï‡§Ç‡§ü‡•ç‡§∞‡•ã‡§≤
        if pitch_s != 1.0:
            new_rate = int(seg.frame_rate * pitch_s)
            seg = seg._spawn(seg.raw_data, overrides={'frame_rate': new_rate}).set_frame_rate(44100)

        if use_silence:
            try: seg = effects.strip_silence(seg, silence_thresh=-45, padding=200)
            except: pass
            
        combined += seg
        os.remove(name)
    
    # ‡§è‡§ï ‡§π‡•Ä ‡§¨‡§æ‡§∞ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§ñ‡§æ‡§≤‡•Ä ‡§ï‡§∞‡§®‡§æ (SPEED BOOST)
    torch.cuda.empty_cache(); gc.collect()

    if use_clean:
        combined = combined.set_frame_rate(44100)
        combined = effects.normalize(combined)
    
    # ‚úÖ ‡§Ü‡§™‡§ï‡§æ ‡§§‡§Ø ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•Å‡§Ü ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§®‡§æ‡§Æ
    final_output_name = "Shri_Ram_Nag_Output.wav"
    combined.export(final_output_name, format="wav")
    return final_output_name

# ‡•´. ‡§¶‡§ø‡§µ‡•ç‡§Ø UI (‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó)
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# üö© ‡§∂‡§ø‡§µ AI (Shiv AI) v1.5 ‚Äî ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó")
    gr.Markdown("### üîí 2000% ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§∏‡•ç‡§™‡•Ä‡§° | 150-200 ‡§µ‡§∞‡•ç‡§° ‡§ï‡§ü‡§∞ | 0% ‡§π‡§ï‡§≤‡§æ‡§π‡§ü")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§Ø‡§π‡§æ‡§Å ‡§≤‡§ø‡§ñ‡•á‡§Ç", lines=12, placeholder="‡§Ö‡§¨ ‡§™‡•Ç‡§∞‡§æ ‡§™‡•à‡§∞‡§æ‡§ó‡•ç‡§∞‡§æ‡§´ 150-200 ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•á ‡§ö‡§Ç‡§ï ‡§Æ‡•á‡§Ç ‡§§‡•á‡§ú‡§º‡•Ä ‡§∏‡•á ‡§ú‡§®‡§∞‡•á‡§ü ‡§π‡•ã‡§ó‡§æ...")
            word_count = gr.Markdown("‡§∂‡§¨‡•ç‡§¶ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ: **‡§∂‡•Ç‡§®‡•ç‡§Ø**")
            txt.change(lambda x: f"‡§∂‡§¨‡•ç‡§¶ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ: **{len(x.split()) if x else '‡§∂‡•Ç‡§®‡•ç‡§Ø'}**", [txt], [word_count])
            
        with gr.Column(scale=1):
            git_v = gr.Dropdown(choices=["aideva.wav"], label="‡§µ‡•â‡§á‡§∏", value="aideva.wav")
            up_v = gr.Audio(label="‡§∏‡•à‡§Ç‡§™‡§≤ ‡§Ö‡§™‡§≤‡•ã‡§°", type="filepath")
            with gr.Accordion("‚öôÔ∏è ‡§Ö‡§≤‡•ç‡§ü‡•ç‡§∞‡§æ ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏ (LOCKED)", open=True):
                spd = gr.Slider(0.9, 1.4, 1.15, label="‡§ü‡§∞‡•ç‡§¨‡•ã ‡§∞‡•û‡•ç‡§§‡§æ‡§∞")
                ptch = gr.Slider(0.7, 1.3, 1.0, label="‡§™‡§ø‡§ö (Pitch)")
                cln = gr.Checkbox(label="‡§∂‡•ã‡§∞ ‡§´‡§ø‡§ï‡•ç‡§∏ (Symmetry Clean)", value=True)
                sln = gr.Checkbox(label="Silence Remover", value=True)
            btn = gr.Button("üöÄ ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§ú‡§®‡§∞‡•á‡§ü ‡§î‡§∞ ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§°", variant="primary")
            
    out = gr.Audio(label="‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ ‡§®‡§æ‡§ó ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü", type="filepath", autoplay=True)
    btn.click(generate_shiv_v1_5, [txt, up_v, git_v, spd, ptch, sln, cln], out)

demo.launch(share=True, debug=True)
