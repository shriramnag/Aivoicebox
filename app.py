import os
import torch
import gradio as gr
import shutil
import re
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment
from brain import MahagyaniBrain # рдЖрдкрдХрд╛ рдЧрд┐рдЯрд╣рдм рд╡рд╛рд▓рд╛ рджрд┐рдорд╛рдЧ

# тЪб рдЯрд░реНрдмреЛ рд╣рд╛рдИ рд╕реНрдкреАрдб рд╕реЗрдЯрдЕрдк [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ЁЯУе рдорд╛рд╕реНрдЯрд░ рдореЙрдбрд▓ [cite: 2026-02-16]
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth"
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

# ЁЯза рдорд╣рд╛рдЬреНрдЮрд╛рдиреА рдмреНрд░реЗрди рдХрдиреЗрдХреНрд╢рди (LOCKED)
brain = MahagyaniBrain(
    'sanskrit_knowledge.json', 
    'hindi_grammar.json', 
    'english_knowledge.json', 
    'prosody_config.json'
)

def split_into_chunks(text):
    """рдЯреБрдХрдбрд╝реЛрдВ рдореЗрдВ рдХрд╛рдЯрдиреЗ рд╡рд╛рд▓рд╛ рд▓реЙрдЬрд┐рдХ - 100% рдлрд┐рдХреНрд╕реНрдб рдФрд░ рдЯрд░реНрдмреЛ рд╕реНрдкреАрдб рдХреЗ рд▓рд┐рдП рддреИрдпрд╛рд░ [cite: 2026-02-18]"""
    # рдкреВрд░реНрдг рд╡рд┐рд░рд╛рдо (ред) рдФрд░ рд╢реНрд▓реЛрдХ рд╡рд┐рд░рд╛рдо (рее) рдкрд░ рдЖрдзрд╛рд░рд┐рдд
    sentences = re.split('([ред!?рее])', text)
    chunks = []
    current_chunk = ""
    for i in range(0, len(sentences)-1, 2):
        sentence = sentences[i] + sentences[i+1]
        # 180 рдХреИрд░реЗрдХреНрдЯрд░ рдХрд╛ рд╕рд╛рдЗрдЬ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдХреЛ рдмрд╣реБрдд рддреЗрдЬ рдмрдирд╛рддрд╛ рд╣реИ
        if len(current_chunk) + len(sentence) < 180:
            current_chunk += sentence
        else:
            if current_chunk: chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk: chunks.append(current_chunk.strip())
    return chunks

def apply_final_mastering(file_path, amp, pitch_val):
    """рдЗрдХреЛ рд╕реБрдзрд╛рд░ рдФрд░ рдХреНрд▓реИрд░рд┐рдЯреА [cite: 2026-01-06]"""
    sound = AudioSegment.from_wav(file_path)
    sound = sound + amp 
    new_rate = int(sound.frame_rate * pitch_val)
    sound = sound._spawn(sound.raw_data, overrides={'frame_rate': new_rate}).set_frame_rate(44100)
    
    # рд╕рдВрддреБрд▓рд┐рдд рдЗрдХреЛ -42dB (рд╣рдХрд▓рд╛рд╣рдЯ рд░реЛрдХрдиреЗ рдХреЗ рд▓рд┐рдП) [cite: 2026-01-06]
    echo = sound - 42 
    sound = sound.overlay(echo, position=180) 
    
    return sound.low_pass_filter(4000)

def generate_voice(text, voice_sample, speed_s, pitch_s, weight_s, amp_s, progress=gr.Progress()):
    # 1. рдмреНрд░реЗрди рд╕реЗ рдЯреЗрдХреНрд╕реНрдЯ рд╢реБрджреНрдз рдХрд░рдирд╛ [cite: 2026-02-18]
    cleaned_text = brain.clean_and_format(text)
    profile = brain.get_voice_profile(text)
    
    # 2. рдЯрд░реНрдмреЛ рд╕реНрдкреАрдб рдФрд░ рд▓рдп рддрдп рдХрд░рдирд╛
    final_speed = profile['global_speed'] if "рее" in text else speed_s
    
    # 3. рдЪрдВрдХрд┐рдВрдЧ рд▓реЙрдЬрд┐рдХ (LOCKED & FIXED) [cite: 2026-02-18]
    chunks = split_into_chunks(cleaned_text)
    chunk_files = []
    output_folder = "temp_chunks"
    if os.path.exists(output_folder): shutil.rmtree(output_folder)
    os.makedirs(output_folder)

    # 4. рдЯрд░реНрдмреЛ рдЬрдирд░реЗрд╢рди рд▓реВрдк
    for i, chunk in enumerate(chunks):
        progress((i+1)/len(chunks), desc=f"тЪб {i+1}/{len(chunks)} рдкреНрд░реЛрд╕реЗрд╕ рд╣реЛ рд░рд╣рд╛ рд╣реИ...")
        name = os.path.join(output_folder, f"c_{i}.wav")
        tts.tts_to_file(
            text=chunk, speaker_wav=voice_sample, language="hi", file_path=name,
            speed=final_speed, 
            repetition_penalty=1.5, # рд╣рдХрд▓рд╛рд╣рдЯ рдкреВрд░реА рддрд░рд╣ рдЦрддреНрдо рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдмреЭрд╛рдпрд╛ рдЧрдпрд╛ [cite: 2026-02-18]
            temperature=0.7, top_p=0.8
        )
        chunk_files.append(name)

    combined = AudioSegment.empty()
    for f in chunk_files: combined += AudioSegment.from_wav(f)
    
    combined.export("temp.wav", format="wav")
    final_audio = apply_final_mastering("temp.wav", amp_s, pitch_s)
    final_audio.export("shriram_fixed_turbo.wav", format="wav")
    return "shriram_fixed_turbo.wav"

# ЁЯОи UI - рд╕рднреА рдкреБрд░рд╛рдиреЗ рдлреАрдЪрд░реНрд╕ рдФрд░ рд╕реНрд▓рд╛рдЗрдбрд░реНрд╕ LOCKED [cite: 2026-01-06]
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange")) as demo:
    gr.Markdown("# ЁЯЪй рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА - рдЯрд░реНрдмреЛ рдорд╣рд╛рдЬреНрдЮрд╛рдиреА (рд╕рдм рдХреБрдЫ рдлрд┐рдХреНрд╕реНрдб)")
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="рдпрд╣рд╛рдБ рд╢реНрд▓реЛрдХ рдпрд╛ рд╕реНрдХреНрд░рд┐рдкреНрдЯ рд▓рд┐рдЦреЗрдВ", lines=12)
        with gr.Column(scale=1):
            ref = gr.Audio(label="рдорд╛рд╕реНрдЯрд░ рд╕реИрдВрдкрд▓ (aideva.wav)", type="filepath")
            with gr.Accordion("тЪЩя╕П рд╕реЗрдЯрд┐рдВрдЧреНрд╕ (LOCKED)", open=True):
                speed_s = gr.Slider(label="рд░реЮреНрддрд╛рд░", minimum=0.8, maximum=1.3, value=1.0)
                pitch_s = gr.Slider(label="рдкрд┐рдЪ", minimum=0.8, maximum=1.1, value=0.96)
                weight_s = gr.Slider(label="рднрд╛рд░реАрдкрди", minimum=0, maximum=10, value=6)
                amp_s = gr.Slider(label="рдкрд╛рд╡рд░", minimum=-5, maximum=10, value=4)
            
            btn = gr.Button("рджрд┐рд╡реНрдп рдЖрд╡рд╛реЫ рдЬрдирд░реЗрдЯ рдХрд░реЗрдВ ЁЯЪА", variant="primary")
            
    out = gr.Audio(label="100% рдлрд┐рдХреНрд╕реНрдб рдЯрд░реНрдмреЛ рдЖрдЙрдЯрдкреБрдЯ", type="filepath", autoplay=True)
    btn.click(generate_voice, [txt, ref, speed_s, pitch_s, weight_s, amp_s], out)

demo.launch(share=True)
