import os, torch, gradio as gr, requests, re, gc
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment, effects

# рез. рдЯрд░реНрдмреЛ рд╣рд╛рдИ рд╕реНрдкреАрдб & GPU рд▓реЙрдХ [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# реи. рдорд╛рд╕реНрдЯрд░ рдореЙрдбрд▓ - рд╢рд┐рд╡ AI (LOCKED) [cite: 2026-02-16]
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth" 
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

G_RAW = "https://raw.githubusercontent.com/shriramnag/Aivoicebox/main/%F0%9F%93%81%20voices/"

def generate_shiv_crystal_clear(text, up_ref, git_ref, speed_s, pitch_s, use_silence, use_clean, progress=gr.Progress()):
    # рей. рдирдВрдмрд░-рдЯреВ-рд╡рд░реНрдбреНрд╕ рдлрд┐рдХреНрд╕ [cite: 2026-02-20]
    num_map = {'0':'рд╢реВрдиреНрдп','1':'рдПрдХ','2':'рджреЛ','3':'рддреАрди','4':'рдЪрд╛рд░','5':'рдкрд╛рдБрдЪ','6':'рдЫрд╣','7':'рд╕рд╛рдд','8':'рдЖрда','9':'рдиреМ'}
    for n, w in num_map.items(): text = text.replace(n, w)

    ref = up_ref if up_ref else "ref.wav"
    if not up_ref:
        url = G_RAW + requests.utils.quote(git_ref)
        with open(ref, "wb") as f: f.write(requests.get(url).content)

    # тЪб рек. рдЕрд╕рд▓реА рдЗрдореЛрд╢рди рдФрд░ рдиреЛ-рд╣рдХрд▓рд╛рд╣рдЯ рдЗрдВрдЬрди (Enhanced) [cite: 2026-02-22]
    parts = re.split(r'(\[pause\]|\[breath\]|\[laugh\]|\[cry\])', text)
    combined = AudioSegment.empty()
    
    for i, part in enumerate(parts):
        if not part.strip(): continue
        progress((i+1)/len(parts), desc=f"ЁЯЪА рд╕реНрдкрд╖реНрдЯ рд╡рд╛рдгреА рдЬрдирд░реЗрд╢рди: {i+1}/{len(parts)}")
        
        # рдЯреИрдЧреНрд╕ рдХреЗ рдЕрдиреБрд╕рд╛рд░ рдЖрд╡рд╛реЫ рдореЗрдВ рдкреНрд░рднрд╛рд╡ рдЬреЛреЬрдирд╛
        if part == "[pause]": 
            combined += AudioSegment.silent(duration=900)
        elif part == "[breath]": 
            combined += AudioSegment.silent(duration=400)
        elif part == "[laugh]":
            # рд╣рдВрд╕реА рдХреЗ рдкреНрд░рднрд╛рд╡ рдХреЗ рд▓рд┐рдП рдореЙрдбрд▓ рдХреЛ рдереЛреЬрд╛ рддреЗрдЬ рдХрд░рдирд╛ [cite: 2026-02-22]
            name = f"l_{i}.wav"
            tts.tts_to_file(text="рд╣рд╛ рд╣рд╛ рд╣рд╛ ", speaker_wav=ref, language="hi", file_path=name, speed=1.2)
            combined += AudioSegment.from_wav(name)
        elif part == "[cry]":
            # рд░реЛрдиреЗ рдХреЗ рднрд╛рд╡ рдХреЗ рд▓рд┐рдП рд╕рдиреНрдирд╛рдЯрд╛ рдФрд░ рдзреАрдореА рдЖрд╡рд╛реЫ [cite: 2026-02-22]
            combined += AudioSegment.silent(duration=500)
        else:
            name = f"part_{i}.wav"
            # рд╕реНрдкрд╖реНрдЯрддрд╛ рдХреЗ рд▓рд┐рдП рдЯреНрдпреВрдирд┐рдВрдЧ (repetition_penalty + temperature) [cite: 2026-02-22]
            tts.tts_to_file(text=part, speaker_wav=ref, language="hi", file_path=name, 
                            speed=speed_s, repetition_penalty=15.0, temperature=0.6, 
                            encoder_iterations=20) 
            
            seg = AudioSegment.from_wav(name)
            if use_silence:
                try: seg = effects.strip_silence(seg, silence_thresh=-45, padding=150)
                except: pass
            combined += seg
        torch.cuda.empty_cache(); gc.collect()

    if use_clean:
        combined = effects.normalize(combined)
        combined = combined.high_pass_filter(80) # рднрд╛рд░реА рдФрд░ рд╕рд╛реЮ рдЖрд╡рд╛реЫ [cite: 2026-02-21]
    
    # тЬЕ рел. рдлрд╛рдЗрд▓ рд╕реЗрд╡ - Shri Ram Nag.wav (LOCKED)
    final_path = "Shri Ram Nag.wav"
    combined.export(final_path, format="wav")
    return final_path

# ЁЯОи рджрд┐рд╡реНрдп UI - рд╕рднреА рдЯреВрд▓реНрд╕ рдФрд░ рдХрд░реНрд╕рд░ рдлрд┐рдХреНрд╕ рдХреЗ рд╕рд╛рде [cite: 2026-02-22]
js_func = "function insertTag(tag) { var t=document.querySelector('#script_box textarea'); var s=t.selectionStart; t.value=t.value.substring(0,s)+' '+tag+' '+t.value.substring(t.selectionEnd); t.focus(); return t.value; }"

with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange"), js=js_func) as demo:
    gr.Markdown("# ЁЯЪй рд╢рд┐рд╡ AI (Shiv AI) - 'рд╢реНрд░реА рд░рд╛рдо рдирд╛рдЧ' рд╕реНрдкрд╖реНрдЯ рд╡рд╛рдгреА рдкреНрд░реЛ")
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="рдЕрдкрдиреА рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ", lines=12, elem_id="script_box", placeholder="рдХрд░реНрд╕рд░ рд░рдЦрдХрд░ рдмрдЯрди рджрдмрд╛рдПрдВ...")
            with gr.Row():
                gr.Button("тП╕я╕П Pause").click(None, None, txt, js="() => insertTag('[pause]')")
                gr.Button("ЁЯТи Breath").click(None, None, txt, js="() => insertTag('[breath]')")
                gr.Button("ЁЯШК Laugh").click(None, None, txt, js="() => insertTag('[laugh]')")
                gr.Button("ЁЯШв Cry").click(None, None, txt, js="() => insertTag('[cry]')")
            
        with gr.Column(scale=1):
            git_voice = gr.Dropdown(choices=["aideva.wav", "Joanne.wav"], label="рд╡реЙрдпрд╕ рдЪреБрдиреЗрдВ", value="aideva.wav")
            manual = gr.Audio(label="рд╕реИрдВрдкрд▓ рдЕрдкрд▓реЛрдб", type="filepath")
            with gr.Accordion("тЪЩя╕П рд╕реЗрдЯрд┐рдВрдЧреНрд╕ (LOCKED)", open=True):
                spd = gr.Slider(0.8, 1.4, 1.0, label="рд░реЮреНрддрд╛рд░")
                ptc = gr.Slider(0.8, 1.1, 0.96, label="рдкрд┐рдЪ")
                cln = gr.Checkbox(label="AI рд╡реЙрдпрд╕ рдХреНрд▓реАрдирд░", value=True)
                sln = gr.Checkbox(label="рд╕рд╛рдЗрд▓реЗрдВрд╕ рд░рд┐рдореВрд╡рд░", value=True)
            btn = gr.Button("рджрд┐рд╡реНрдп рдЬрдирд░реЗрд╢рди рд╢реБрд░реВ рдХрд░реЗрдВ ЁЯЪА", variant="primary")
            
    out = gr.Audio(label="рдбрд╛рдЙрдирд▓реЛрдб: Shri Ram Nag.wav", type="filepath", autoplay=True)
    btn.click(generate_shiv_crystal_clear, [txt, manual, git_voice, spd, ptc, sln, cln], out)

demo.launch(share=True)
