import os
import torch
import gradio as gr
import shutil
from TTS.api import TTS
from huggingface_hub import hf_hub_download
from pydub import AudioSegment

# ЁЯЪй рдЖрдкрдХреЗ рдкреБрд░рд╛рдиреЗ рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдХреА рдлрд╛рдЗрд▓реЗрдВ [cite: 2026-02-16]
try:
    from text_engine import split_into_chunks
    from parallel_processor import combine_chunks
except ImportError:
    pass

# тЪб рдЯрд░реНрдмреЛ рдЗрдВрдЬрди рдФрд░ рд╣рдЧрд┐рдВрдЧ рдлреЗрд╕ рд╕реЗрдЯрдЕрдк [cite: 2026-01-06]
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ЁЯУе рд╣рдЧрд┐рдВрдЧ рдлреЗрд╕ рд╕реЗ рдЖрдкрдХрд╛ Ramai.pth рд▓реЛрдб рдХрд░рдирд╛
REPO_ID = "Shriramnag/My-Shriram-Voice" 
MODEL_FILE = "Ramai.pth"

print("ЁЯЪА рд╣рдЧрд┐рдВрдЧ рдлреЗрд╕ рд╕реЗ рдореЙрдбрд▓ рд▓реЛрдб рд╣реЛ рд░рд╣рд╛ рд╣реИ...")
model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILE)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

def apply_shriram_magic(file_path, bass_gain, amp_gain):
    """рдЖрд╡рд╛реЫ рдХреЛ рднрд╛рд░реА рдФрд░ рдкрд╛рд╡рд░рдлреБрд▓ рдмрдирд╛рдирд╛"""
    sound = AudioSegment.from_wav(file_path)
    sound = sound + amp_gain # рдПрдордкреНрд▓реАрдлрд╛рдпрд░ (Power)
    
    if bass_gain > 0:
        # рдЖрд╡рд╛реЫ рдХреЛ рдЧрд╣рд░рд╛ (Deep) рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдкрд┐рдЪ рдПрдбрдЬрд╕реНрдЯрдореЗрдВрдЯ
        new_sample_rate = int(sound.frame_rate * (1.0 - (bass_gain / 100)))
        sound = sound._spawn(sound.raw_data, overrides={'frame_rate': new_sample_rate})
        sound = sound.set_frame_rate(44100)
    
    final_path = "shriram_final_pro_v2.wav"
    sound.export(final_path, format="wav")
    return final_path

def generate_voice(text, voice_sample, speed, pitch, emotion, bass, amp, progress=gr.Progress()):
    if not text or not voice_sample:
        raise gr.Error("рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдФрд░ рд╡реЙрдЗрд╕ рд╕реИрдВрдкрд▓ реЫрд░реВрд░реА рд╣реИрдВред") 

    # ЁЯЪА рдЖрдкрдХрд╛ рдкреБрд░рд╛рдирд╛ рдЪрдВрдХ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рд▓реЙрдЬрд┐рдХ (Unchanged) [cite: 2026-02-16]
    output_folder = "outputs"
    if os.path.exists(output_folder): shutil.rmtree(output_folder)
    os.makedirs(output_folder, exist_ok=True)

    chunks = split_into_chunks(text) 
    chunk_files = []

    for i, chunk in enumerate(chunks):
        progress((i+1)/len(chunks), desc=f"ЁЯЪА рдЯрд░реНрдмреЛ рдХреНрд▓реЛрдирд┐рдВрдЧ: {i+1}/{len(chunks)}") 
        name = os.path.join(output_folder, f"chunk_{i}.wav")

        tts.tts_to_file(
            text=chunk, speaker_wav=voice_sample, language="hi", file_path=name,
            speed=speed, repetition_penalty=12.0, temperature=emotion,
            top_p=0.85, gpt_cond_len=3
        )
        chunk_files.append(name)

    combined_temp = "combined_temp.wav"
    combine_chunks(chunk_files, output_file=combined_temp)
    
    # тЬи рднрд╛рд░реА рд╡рдЬрди рдФрд░ рдкрд╛рд╡рд░ рдЬреЛреЬреЗрдВ
    return apply_shriram_magic(combined_temp, bass, amp)

# ЁЯОи рдЖрдкрдХрд╛ рд░реЙрдпрд▓ UI
with gr.Blocks(theme=gr.themes.Soft(primary_hue="orange"), title="рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА AI") as demo:
    gr.Markdown("# ЁЯОЩя╕П рд╢реНрд░реАрд░рд╛рдо рд╡рд╛рдгреА - рд╣рдЧрд┐рдВрдЧ рдлреЗрд╕ рдЯрд░реНрдмреЛ рдЗрдВрдЬрди")
    
    with gr.Row():
        with gr.Column(scale=2):
            txt = gr.Textbox(label="рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдкреЗрд╕реНрдЯ рдХрд░реЗрдВ", lines=12)
        with gr.Column(scale=1):
            ref = gr.Audio(label="рд╕реИрдВрдкрд▓ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ", type="filepath")
            with gr.Accordion("тЪЩя╕П рдкреБрд░рд╛рдиреЗ рд╕реНрд▓рд╛рдЗрдбрд░реНрд╕ (Locked)", open=True):
                speed_s = gr.Slider(label="Speed", minimum=0.5, maximum=1.5, value=1.0)
                pitch_s = gr.Slider(label="Deep Match", minimum=0.5, maximum=1.0, value=0.9)
            with gr.Accordion("ЁЯОн рднрд╛рд░реА рдЖрд╡рд╛реЫ рдФрд░ рдкрд╛рд╡рд░ (Bass/Amp)", open=True):
                emo_s = gr.Slider(label="рд╣реНрдпреВрдорди рдЯрдЪ (Emotion)", minimum=0.1, maximum=1.0, value=0.8)
                bass_s = gr.Slider(label="рднрд╛рд░реА рд╡рдЬрди (Deep Voice)", minimum=0, maximum=10, value=2)
                amp_s = gr.Slider(label="рдПрдордкреНрд▓реАрдлрд╛рдпрд░ (Power)", minimum=-5, maximum=15, value=0)
            btn = gr.Button("ЁЯЪА рдЯрд░реНрдмреЛ рдЬрдирд░реЗрдЯ рдХрд░реЗрдВ", variant="primary")
            
    out = gr.Audio(label="рдлрд╛рдЗрдирд▓ рдЖрдЙрдЯрдкреБрдЯ", type="filepath", autoplay=True)
    btn.click(generate_voice, [txt, ref, speed_s, pitch_s, emo_s, bass_s, amp_s], out)

if __name__ == "__main__":
    demo.launch(share=True, debug=True)
